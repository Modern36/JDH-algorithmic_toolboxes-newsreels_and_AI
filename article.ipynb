{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "title"
    ]
   },
   "source": [
    "# Algorithmic toolboxes for the study of the filmic past—on newsreels & AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    " ### Robert Aspenskog Contributor1LastName [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0009-0005-4720-3352) \n",
    "\n",
    "Department of Cultural Sciences, Linnaeus University \n",
    "\n",
    "Department of Cultural Sciences, Lund University\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "### Mathias Johansson [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0000-0002-3338-0551) \n",
    "Department of Arts and Cultural Sciences, Lund University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "### Johan Malmstedt [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0000-0001-5207-4296) \n",
    "\n",
    "GRIDH, University of Gothenburg \n",
    "\n",
    "metaLAB, Harvard University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "### Emil Stjernholm [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0000-0001-9871-5191) \n",
    "Department of Communication, Lund University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "### Pelle Snickars [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0000-0001-5122-1549) \n",
    "Department of Arts and Cultural Sciences, Lund University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "copyright"
    ]
   },
   "source": [
    "[![cc-by](https://licensebuttons.net/l/by/4.0/88x31.png)](https://creativecommons.org/licenses/by/4.0/) \n",
    "©<AUTHOR or ORGANIZATION / FUNDER>. Published by De Gruyter in cooperation with the University of Luxembourg Centre for Contemporary and Digital History. This is an Open Access article distributed under the terms of the [Creative Commons Attribution License CC-BY](https://creativecommons.org/licenses/by/4.0/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "cover"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"tags\": [\"figure-Gunnar-*\"],\n",
    "        \"object\": {\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"Gunnar Skoglund (1899–1983)—once hailed in the Swedish press \"\n",
    "                \"as a “speaking artist”—did hundreds of voice-over for the \"\n",
    "                \"national SF newsreel. At the time, his voice was arguably \"\n",
    "                \"the most familiar in Sweden. Skoglund was also a skilled \"\n",
    "                \"director, actor and producer of some thirty short films, \"\n",
    "                \"dating from the late 1920s to the 1950s.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "display(Image(\"./media/img1.png\", width=1000), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    " (optional) This article was orginally published (...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "keywords"
    ]
   },
   "source": [
    "FirstKeyword, SecondKeyword, AlwaysSeparatedByAComma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "abstract"
    ]
   },
   "source": [
    "Using a computational film studies framework, this article examines a major\n",
    "Swedish newsreel archive—the Journal Digital collection—deploying both signal\n",
    "archaeology, named entity recognition, and geocoding. We also apply a specific\n",
    "algorithmic toolbox on text extraction of intertitles, as well as a tweaked\n",
    "tool, SweScribe, based on automatic speech recognition, in order to both\n",
    "transcribe and timestamp speech from the collection’s sound films. Our basic\n",
    "idea is to construct a number of mid-sized datasets from the Journal Digital\n",
    "collection in different modalities, and proceed with an examination using\n",
    "various approaches. Consequently, our intention is to increase the scholarly\n",
    "capacity of media historical sources, while at the same time critically\n",
    "scrutinizing AI and algorithmic toolboxes for the study of the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "At the archive of Swedish Television (SVT) and Radio Sweden (SR) there are some\n",
    "thirty volumes of so-called speaker lists used for voice-over in the production\n",
    "of the national SF newsreel—Svensk Filmindustris Veckorevy (Svensk\n",
    "Filmindustri’s Weekly Review). During the 1960s, the film company Svensk\n",
    "Filmindustri (SF) sold its non-fiction film and newsreel archive to public\n",
    "service radio and tv. The making of newsreels, however, had begun already in\n",
    "1914, when SF started producing a weekly newsreel in a similar fashion and\n",
    "format as in other countries. These newsreels were nationally distributed in\n",
    "dozens of copies across Sweden; during the silent era they naturally included\n",
    "textual intertitles. From 1932 and onwards sound was added; the preserved\n",
    "voice-over scripts in the SVT and SR vaults hence range from 1932 until 1959.\n",
    "These lists were as detailed as plentiful; today each volume in the archive\n",
    "includes some 150 manuscripts, making the total number of speaker lists to\n",
    "approximately 5,000. In a literal sense they were production manuscripts,\n",
    "almost all contained handwritten edits, and small commentary. All likely they\n",
    "served as the final manuscript for the person who did the voice-over commentary\n",
    "in the film studio, describing the length in seconds when text should be\n",
    "spoken, while also indicating what type of shot the edited newsreel depicted\n",
    "during each particular sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-first-newsreel-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"The first episode in a SF-newsreel from March 1933 depicted \"\n",
    "                \"the Swedish frigate Vanadis, a naval training ship. \"\n",
    "                \"The commentary was read by Gunnar Skoglund, and as is \"\n",
    "                \"evident from the preserved speaker list, it was meticulous, \"\n",
    "                \"customized in seconds, and almost identical to what was \"\n",
    "                \"heard in the film. In English translation Skoglund rapidly \"\n",
    "                \"announced: “Since the beginning of the 20th century, the \"\n",
    "                \"venerable frigate Vanadis has been anchored at Skeppsholmen \"\n",
    "                \"in Stockholm as a lodging and training ship. \"\n",
    "                \"In its disrigged hull, two generations of sailors have slept \"\n",
    "                \"the warrior’s heavy and well-deserved sleep in hammocks. \"\n",
    "                \"Lying in a bunk it is called in sailor’s language, but it is \"\n",
    "                \"not quite the same as sleeping in a bed at home. \"\n",
    "                \"If nothing else, the alarm clock is a little louder here”— \"\n",
    "                \"trumpet immediately!\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "display(Image(\"./media/img2.png\", width=1000), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "For digital media historians, trying to analyse speaker lists from the SF\n",
    "archive as a textual dataset poses challenges. If one, for example, uploads an\n",
    "archival sample of a speaker lists to an AI-powered engine such as Perplexity,\n",
    "with the prompt to OCR a particular section, the result is not particularly\n",
    "impressive. The AI-model does a fair job with all typed Swedish text, but fails\n",
    "with handwritten notes as well as words that have been manually crossed out.\n",
    "Occasionally, Swedish words and letters even turn into Cyrillic script: “8 sek.\n",
    "Strömmen. Alltsedan mitte av 1890-talet karxxіях кирракX Momenxxxxsixxxkxxmxx”.\n",
    "Trying to work with the SF speaker lists in digitised form is hence scholarly\n",
    "difficult. These lists exhibit many of the common traits that archival\n",
    "documents often encompass; combined typed and handwritten text with corrections\n",
    "often hinders OCR, and structuring of data in correct ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "1pjw9": [
       {
        "id": "22783102/UK5SM8C2",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "AI hallucination of a Swedish voice-over into Russian can of course also be\n",
    "seen as a token of how large language models generate information that is both\n",
    "historically inaccurate—and even fabricated. By now it is well known among\n",
    "historians that LLM’s often hallucinate about the past, particularly when more\n",
    "specific questions are posed. While it is true that generative AI does give apt\n",
    "textual answers, such models have repeatedly been critiqued when it comes to\n",
    "producing historical images. Fabian Offert has stressed that models such as\n",
    "CLIP or DALL-E find themselves in ”a triple bind: they suffer from syntactic\n",
    "invariability in the case of generally historical prompts, semantic arbitrarity\n",
    "in the case of specifically historical prompts, and superficial, corporate\n",
    "censorship that affects both” <cite id=\"1pjw9\"><a href=\"#zotero%7C22783102%2FUK5SM8C2\">(Offert, 2023)</a></cite>. The latter is,\n",
    "of course, particularly problematic. Nearly all forms of generative AI are\n",
    "circumscribed by commercial constraints; encoded values are neither epistemic\n",
    "nor scholarly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "568sd": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Despite these AI shortcomings regarding the past, in this article we aim to\n",
    "analyse the SF-archive—today usually referred to as the Journal Digital\n",
    "collection—with a diverse set of algorithmic tools. Given our initial\n",
    "discussion, we have however refrained from digitising textual sources (such as\n",
    "the preserved SF speaker lists), and instead focused on the audiovisual\n",
    "material per se. Using a computational film studies framework <cite\n",
    "id=\"568sd\"><a href=\"#zotero%7C22783102%2FH4XMMWYS\">(Oiva et al.,\n",
    "2024)</a></cite>, this article hence examines the Journal Digital collection\n",
    "deploying both signal archaeology, named entity recognition and geocoding. We\n",
    "will also apply a specific algorithmic toolbox, developed for this article, on\n",
    "text extraction of intertitles from silent newsreels—the application is called\n",
    "stum—as well as using a tweaked tool, SweScribe, based on automatic speech\n",
    "recognition, in order to both transcribe, and timestamp speech from the\n",
    "collection’s sound films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "copyright"
    ]
   },
   "source": [
    "## Start of placeholders.\n",
    "TODO: Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "cover"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(\"./media/placeholder.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "disclaimer"
    ]
   },
   "source": [
    " (optional) This article was orginally published (...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "keywords"
    ]
   },
   "source": [
    "FirstKeyword, SecondKeyword, AlwaysSeparatedByAComma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "This is a hermeneutic paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "jdh": {
     "module": "object",
     "object": {
      "source": [
       "table 1: label table 1"
      ]
     }
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "table-1"
    ]
   },
   "source": [
    "Editor|1641|1798|1916\n",
    "---|---|---|---\n",
    "Senan|0.55|0.4|0.3\n",
    "Henry|0.71|0.5|0.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hidden"
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check your Python version\n",
    "from platform import python_version\n",
    "python_version()\n",
    "\n",
    "#!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pandas package needs to be added to the requirements.txt 's file\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from itertools import pairwise\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import time\n",
    "import threading\n",
    "import os\n",
    "from pathlib import Path\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Isort, check versions, add to requirements.txt\n",
    "root = Path('.')\n",
    "data = root / 'script'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/lux-org/lux-datasets/master/data/college.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## End of placeholders.\n",
    "TODO: Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the bare minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hermeneutics header about video quality.\n",
    "... showing resolution and dpi from a frame and the previous image?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"tags\": [\"video-composition-*\",],\n",
    "        \"object\": {\n",
    "            \"type\":\"video\",\n",
    "            \"source\": [\n",
    "                \"It is indeed difficult to visualise a dataset with thousands \"\n",
    "                \"of nonfiction films, still a small quick and dirty \"\n",
    "                \"compilation of 28 silent films (from the 1920s) gives an \"\n",
    "                \"impression of the vivid depiction of Swedish society—and \"\n",
    "                \"modernity—that the SF-archive encompasses.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "display(Video(\"./media/vid1.mp4\", width=1000), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "guc1d": [],
      "l41c8": [
       {
        "id": "22783102/7HB6GAHN",
        "source": "zotero"
       }
      ],
      "v6zpe": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Our work is rooted in the research project Modern Times 1936, that explores\n",
    "what software sees, hears and perceives when technologies for pattern\n",
    "recognition are applied to media historical sources. Within this research\n",
    "project we have prior been interested in the the historical gaze of generative\n",
    "AI <cite id=\"l41c8\"><a href=\"#zotero%7C22783102%2F7HB6GAHN\">(Stjernholm et al., 2025)</a></cite>, algorithmic scaling of early cinema on YouTube <cite\n",
    "id=\"guc1d\"><a href=\"#zotero%7C22783102%2FTV37XT5P\">(Stjernholm &#38; Snickars,\n",
    "2024)</a></cite>, and techniques for assessing photorealism in synthetic images\n",
    "<cite id=\"v6zpe\"><a href=\"#zotero%7C22783102%2FVL4UHIWF\">(Eriksson,\n",
    "2024)</a></cite>. If Charlie Chaplin once in Modern Times (1936) struggled to\n",
    "comprehend an industrialised world with giant machines, a common denominator in\n",
    "our research project has been to explore how computational methods can help us\n",
    "understand modernity in new ways. In this article, the idea is hence to\n",
    "construct a number of mid-sized datasets from the Journal Digital collection in\n",
    "different modalities, and proceed with an examination using various\n",
    "computational approaches. Consequently, our intention is to increase the\n",
    "scholarly capacity of media historical sources, while at the same time\n",
    "critically scrutinizing AI and algorithmic toolboxes for the study of the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-SF-facilities-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"The Swedish SF film company had its production facilities \"\n",
    "                \"with studio and film laboratory located in the so called \"\n",
    "                \"Film-City (Filmstaden) in the suburb of Råsunda \"\n",
    "                \"(north of Stockholm), from 1920 until 1969. As is evident \"\n",
    "                \"from these late 1920s and 1930s photographs, the production \"\n",
    "                \"of newsreels was a practical craft; it involved editing, \"\n",
    "                \"cleaning, and copying film, as well as synchronising added \"\n",
    "                \"sound. The film itself was nitrate-based celluloid, known \"\n",
    "                \"both for its high image quality—and dangerous flammability. \"\n",
    "                \"Illustrations from the Swedish Film Institute and the \"\n",
    "                \"Swedish National Museum of Science and Technology. \"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "display(Image(\"./media/img3.png\", width=600), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biography of a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "09k1h": [],
      "2paaf": [],
      "vw0o9": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "During the late 1950s, the film manuscript writer Gardar Sahlberg (1908–1983)\n",
    "started to take an increased interest in the film archive at Svensk\n",
    "Filmindustri (SF). At the time, however, the company archive of nitrate films,\n",
    "such as newsreels and short films, was in dire need to be restored (and\n",
    "preserved). Most of the oldest footage was filmed by cinematographers from\n",
    "Swedish Biograph, a company that in 1919 merged into SF <cite id=\"vw0o9\"><a\n",
    "href=\"#zotero%7C22783102%2F6APYGVMY\">(Olsson, 2022)</a></cite>. From the\n",
    "beginning of the 1920s until the 1960s, SF had been the leading producer of\n",
    "newsreels, educational cinema, and other types of useful films, distributed in\n",
    "both theatrical and non-theatrical venues <cite id=\"2paaf\"><a\n",
    "href=\"#zotero%7C22783102%2FBQLCIUEW\">(Stjernholm &#38; Florin Persson,\n",
    "2019)</a></cite>. As a way to finance a reconstruction and improvement of the\n",
    "SF archive, Sahlberg and SF decided to produce historical compilation films\n",
    "based on the same old film material. In 1961, for example, the documentary När\n",
    "seklet var ungt (When the century was young) had its premiere. Critics endorsed\n",
    "the film—but audiences did not. Instead, SF started negotiations with Radio\n",
    "Sweden (SR), which at the time was also responsible for national public service\n",
    "television. During the winter of 1964, it was announced that SR had acquired\n",
    "the whole newsreel archive from SF; one million meters of film dating from 1897\n",
    "to 1960 was purchased <cite id=\"09k1h\"><a\n",
    "href=\"#zotero%7C22783102%2FBNUCIK7T\">(Snickars, 2024)</a></cite>. The deal was\n",
    "explosive, not only because of the number of preserved nitrate prints; the\n",
    "SF-archive would now find a novel audience in another medium: television."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-seklet-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"The compilation film, När seklet var ungt \"\n",
    "                \"(When the century was young) from 1961, was \"\n",
    "                \"based on the oldest nonfiction films and \"\n",
    "                \"newsreels within the SF-archive. In February \"\n",
    "                \"1962, the director Gardar Sahlberg stated in \"\n",
    "                \"a letter to the national archivist in Sweden, \"\n",
    "                \"that the intention of the film was to \"\n",
    "                \"show “the qualitatively impressive archival film material” \"\n",
    "                \"to a culturally interested audience. \"\n",
    "                \"At SF we had the belief, he admitted, \"\n",
    "                \"that curiosity of this type of older films \"\n",
    "                \"would be so great “that the money received \"\n",
    "                \"from the box office would make it possible \"\n",
    "                \"to go ahead, and finance the renewal of \"\n",
    "                \"the [SF-]archive”. But unfortunately that \"\n",
    "                \"was not the case—despite excellent reviews. \"\n",
    "                \"When the film was shown \"\n",
    "                \"“in a few places in the countryside, there was no audience,” \"\n",
    "               'he sadly concluded '\n",
    "               '<cite id=\"8l0z1\"><a href=\"#zotero%7C22783102%2FPECABWGW\">(Sahlberg, 1962)</a></cite>'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "display(Image(\"./media/img4.png\", width=500), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "nx09j": [],
      "ziu8k": []
     }
    }
   },
   "source": [
    "As part of the deal, Sahlberg and a few colleagues at SF were hired by SR to\n",
    "work with safeguarding the SF-archive. During the 1960s and 1970s, the archive\n",
    "was preserved, duplicated, catalogued, and subsequently re-used in numerous\n",
    "television programs. In fact, SR made a remarkable cultural-historical effort\n",
    "in saving this film archive. From the old nitrate prints, Sahlberg had three\n",
    "different film materials made: a master copy on 35 mm (for preservation), a\n",
    "duplicate negative on 35 mm to obtain new copies, and a 16 mm display copy for\n",
    "program producers at SR. Sahlberg also took personal responsibility to\n",
    "catalogue the entire SF-archive, manual work he basically did on his own.\n",
    "Notably, all films from SF were catalogued under a specific SF-number; SF2001\n",
    "for example was the oldest film in the archive, dating from 1897. Since SR took\n",
    "excellent care of these films, the company was able to acquire other film\n",
    "collections as well. Some 400 films were purchased from Kinocentralen in the\n",
    "mid 1960s, a company that had produced short and industrial films from the\n",
    "early 1920s. Other similar films were donated to SR from, for example, the\n",
    "Swedish Film Library (Filmhistoriska Samlingarna), the Salvation Army Sweden,\n",
    "the Stockholm City Museum, and the film archive at the Swedish State Railways\n",
    "(SJ)—the latter collection contained almost two hundred nonfiction films\n",
    "produced by SJ between 1920 and 1960. SR also bought the newsreel Nuet (Now)\n",
    "produced by the film company Nordisk Tonefilm during a few years in the mid\n",
    "1950s <cite id=\"nx09j\"><a href=\"#zotero%7C22783102%2FDSU6R48K\">(Asp,\n",
    "2014)</a></cite>. Finally, in 1969 SR also decided to acquire all short films\n",
    "produced by SF, a deal that made the entire collection at SR amount to more\n",
    "than five thousand films. As a consequence, the initial SF-archive came to\n",
    "contain a range of different types of documentary film, with different\n",
    "provenances. It should be noted, however, that the rationale behind all these\n",
    "film acquisitions was the potential usage of old films in new tv-programs.\n",
    "Still, SR was also interested in developing a sales organisation for\n",
    "tv-programs, with film rights as a prospective revenue stream. An interesting\n",
    "aspect of the initial purchase of the SF-archive hence concerned what type of\n",
    "rights (to old footage) that SF actually sold to SR, since the archive also\n",
    "contained films of foreign origin (such as Pathé and Gaumont). In a memo from\n",
    "1964, the head of the film archive at SR therefore urged a certain degree of\n",
    "caution when it came to the reuse of foreign films <cite id=\"ziu8k\"><a\n",
    "href=\"#zotero%7C22783102%2FDVKUX2N4\">(Norrlander, 1964)</a></cite>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"tags\": [\"video-composition2-*\",],\n",
    "        \"object\": {\n",
    "            \"type\":\"video\",\n",
    "            \"source\": [\n",
    "                \"The film collection at SR grew steadily during the 1960s—and \"\n",
    "                \"it was indeed heterogenous. The collection included early \"\n",
    "                \"cinema, silent newsreels from Swedish Biograph, Svensk \"\n",
    "                \"Filmindustris Veckorevy, films from the Swedish State \"\n",
    "                \"Railways (SJ) and their film archive, short films from \"\n",
    "                \"Kinocentralen, and the 1950s newsreel Nuet, produced by \"\n",
    "                \"Nordisk Tonefilm.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "display(Video(\"./media/vid2.mp4\", width=500), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "7cqtj": [],
      "bsd9e": [],
      "ujcdl": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "From the mid 1960s, Swedish public service television appropriated the films\n",
    "that Sahlberg and his colleagues had preserved, and catalogued. Footage from\n",
    "the SF-archive and the other film collections at SR was reused in thousands of\n",
    "tv programs <cite id=\"ujcdl\"><a href=\"#zotero%7C22783102%2F24HEASLG\">(Eriksson\n",
    "et al., 2024)</a></cite>. In many ways these moving images shaped the ways that\n",
    "Swedes perceived their past <cite id=\"7cqtj\"><a\n",
    "href=\"#zotero%7C22783102%2F2RDITF4M\">(Eriksson et al., 2022)</a></cite>. In the\n",
    "1980s, the first steps towards digitising the catalogue of films and metadata\n",
    "were taken. Interestingly, the motivation for both microfilming the catalogue,\n",
    "and developing a rudimentary database of information about the content of old\n",
    "newsreels, were financial. When the new head of the TV archive (as it was now\n",
    "called), Birgitta Lagnell, was interviewed in the mid 1980s, her major quest\n",
    "was how to monetise the film archive: ”She will make the gold mine of\n",
    "television profitable”, headlines stated <cite id=\"bsd9e\"><a\n",
    "href=\"#zotero%7C22783102%2FDW4S37Y5\">(Bergman, 1986)</a></cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "wfa1f": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Ten years later, an increased academic interest in the SF-archive resulted in\n",
    "an externally funded research project with the aim to make the old film\n",
    "collections more accessible. As a result, the department of cinema studies at\n",
    "Stockholm University started a collaboration with the TV archive, granting\n",
    "access to scholars and PhD students interested in the SF-archive. One of us\n",
    "(Snickars) started his PhD training in cinema studies in 1995 by examining 16\n",
    "mm prints from the SF-archive at a Steenbeck editing desk located in the vaults\n",
    "of the TV archive. In parallel, and on the agenda at the time, Swedish public\n",
    "service television began developing digital technology for terrestrial\n",
    "television. A governmental report, SOU 1996:25—From mass media to multi media:\n",
    "how to digitise Swedish television—laid the groundwork, and described in detail\n",
    "the technical requirements. Since the digitisation of the SF-archive was\n",
    "foremost media archival work, the TV archive contacted the publicly funded\n",
    "Swedish National Archive of Recorded Sound and Moving Images (ALB) with a\n",
    "request to scan the SF-archive to video—with the prospective to later transfer\n",
    "content to digital tape <cite id=\"wfa1f\"><a\n",
    "href=\"#zotero%7C22783102%2F928EZRZ4\">(ALB, 1996)</a></cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "ivltg": [],
      "j8r7k": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "During the summer of 1997, ALB started scanning; the deal was to transfer five\n",
    "hundred nonfiction films every year <cite id=\"ivltg\"><a\n",
    "href=\"#zotero%7C22783102%2FR86YMEXD\">(ALB, 1997)</a></cite>. Additional\n",
    "external funding was secured, and ALB also decided to transfer all catalogue\n",
    "information to machine readable formats. ALB had been inaugurated in the late\n",
    "1970s, due to an extension in the Swedish deposit law that came to include\n",
    "audiovisual material as well. ALB was in many ways a video archive in the\n",
    "service of academic research; public service broadcasts were stored on magnetic\n",
    "tape. Yet, in the mid 1990s it became all too apparent that video and tape\n",
    "recordings would not sustain content for longer periods of time. In digital\n",
    "format, however, it was likely that the same content could be preserved—for\n",
    "ALB, the digitisation of the SF-archive hence developed into a case study of\n",
    "how to proceed with such a major technical, and media archival transition. In a\n",
    "description (for an application) from 1998, The digital newsreel archive, it\n",
    "was stated that ALB was now planning “to digitise all scanned video tapes\n",
    "\\[from the SF-archive\\]. The digitised recordings will then be stored \\[on\\]\n",
    "discs in an automated archive”. Converted catalog information would also be\n",
    "linked to each film. “This will allow the user to perform catalog searches, and\n",
    "also view the requested film directly online on a computer, which would\n",
    "effectively streamline research usage” <cite id=\"j8r7k\"><a\n",
    "href=\"#zotero%7C22783102%2FM63TBZ7V\">(ALB, 1998)</a></cite>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-ALB-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"In 2003, the Swedish National Archive of Recorded Sound and \"\n",
    "                \"Moving Images (formerly ALB) launched Journal Digital—a \"\n",
    "                \"collection with more than 5,000 digitised films and linked \"\n",
    "                \"metadata, accessible through a user-friendly interface. \"\n",
    "                \"At the same time, one percent of the films from Journal \"\n",
    "                \"Digital were also made available online on the web, a site \"\n",
    "                \"that rapidly became popular among (foremost elderly) Swedes. \"\n",
    "                \"Today, twenty years later, at the portal filmarkivet.se—a \"\n",
    "                \"joint venture between the National Library of Sweden and the \"\n",
    "                \"Swedish Film Institute also—some three hundred SF-newsreels \"\n",
    "                \"are openly available for anyone to watch.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "display(Image(\"./media/img5.png\", width=800), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "nnebq": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The digitisation work proceeded in the coming years—albeit slowly. At a board\n",
    "meeting in late 1999, the head of ALB, Sven Allerstrand, had to confess that\n",
    "“unfortunately, as resources are lacking for an R&D function within ALB,\n",
    "development work \\[with the SF-archive\\] is progressing very slowly. Resources\n",
    "must be taken from ordinary operations, which has a negative impact on the\n",
    "overall result.” However, Allerstrand stated, at our media archive we are still\n",
    "“convinced that the only possible solution to ensure the long-term preservation\n",
    "of ALB’s material is automated processing in a digital mass storage system”\n",
    "<cite id=\"nnebq\"><a href=\"#zotero%7C22783102%2FBXDUCBBT\">(ALB,\n",
    "1999)</a></cite>. A year later, ALB finally secured funding from the\n",
    "government, and the transfer of the SF-archive into digital format proceeded\n",
    "with a more rapid pace. In 2002, all newsreels and short films had finally been\n",
    "digitised. However, since the film collection included not only films from\n",
    "SF—but also films from Kinocentralen, the Swedish State Railways, and newsreels\n",
    "from Nordisk Tonefilm—ALB decided to change the name of the digitised\n",
    "collection to Journal Digital. A new search interface for the collection,\n",
    "publicly accessible on computers at ALB, was developed, as well as a web site\n",
    "with one percent of the collection online (through permission from SVT). In\n",
    "all, Journal Digital gave access to 4,348 newsreels and short films from Svensk\n",
    "Filmindustri, 421 nonfiction films from Kinocentralen, 267 Nuet-newsreels from\n",
    "Nordisk Tonefilm, and 170 SJ-documentary films from the Swedish State\n",
    "Railways—in all 5,206 films dating from 1896 to the mid 1960s. Consequently,\n",
    "that is the amount of films that our dataset—the Journal Digital collection—is\n",
    "based upon. It should be stressed, however, that in the following we will often\n",
    "write about the analyses of newsreels, since they make up the major part of our\n",
    "dataset. Yet, we are aware that our examined film material also contains other\n",
    "genres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-box-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"Via the content management system Box, Swedish researchers \"\n",
    "                \"can today remotely access the audiovisual collections at the \"\n",
    "                \"National Library of Sweden. While sound recordings are fine \"\n",
    "                \"and acceptable, this is hardly the case for film or \"\n",
    "                \"television content—which is displayed in low resolution \"\n",
    "                \"formats, 704 x 576 pixels, in a small square on the screen \"\n",
    "                \"measuring nine times seven centimetres. \"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "display(Image(\"./media/img6.png\", width=800), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Formats tend to stick, and remain the same: when the Swedish National Archive\n",
    "of Recorded Sound and Moving Images (ALB)—in the year 2000 digitised the\n",
    "SF-archive, all films were converted into MPEG-2-format, a digital video and\n",
    "audio compression standard developed during the 1990s by the Moving Picture\n",
    "Experts Group (MPEG). The MPEG-2-versions were preserved on digital tape at\n",
    "ALB. From these preservation files, another video converter compressed films\n",
    "into a browse copy in MPEG-1-format, a lossy compression format with files\n",
    "stored on a hard drive for instant access via an interface. 25 years ago,\n",
    "MPEG-1 was a standard resolution for compressed video online. Yet, this is\n",
    "obviously not the case any more. If film archivist Gardar Sahlberg during the\n",
    "1960s made sure to preserve the SF-archive on both a master copy on 35 mm, a\n",
    "duplicate negative on 35 mm, and a 16 mm display copy, this is far from how\n",
    "researchers today are confronted with the SF-archive in the digital domain.\n",
    "Decisions taken back then still linger; researchers working with audiovisual\n",
    "materials today must still be satisfied with late 1990s low resolution copies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"tags\": [\"video-filmarkivet-*\",],\n",
    "        \"object\": {\n",
    "            \"type\":\"video\",\n",
    "            \"source\": [\n",
    "                \"Proper filmic heritage is naturally dependent on digital \"\n",
    "                \"quality; both sequences display the Stockholm exhibition in \"\n",
    "                \"1897, shot by a Lumière cinematographer (SF2001). \"\n",
    "                \"The version to the right is low resolution with pixels \"\n",
    "                \"clearly visible if the frame is enlarged—the speed is also \"\n",
    "                \"not adjusted. Sadly, this is the version that academic \"\n",
    "                \"researchers are confronted with in the Box interface at the \"\n",
    "                \"National Library of Sweden. In the version to the \"\n",
    "                \"left—visible in the public interface filmarkivet.se—speed is \"\n",
    "                \"adjusted, and the sequence is displayed in MPEG-2, a still \"\n",
    "                \"acceptable digital resolution.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "display(Video(\"./media/vid2.mp4\", width=500), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "zmeiv": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Decisions made two decades ago still hold sway. Consequently, in this article\n",
    "we have been working with low resolution (MPEG-1) copies from Journal Digital.\n",
    "As stated, the National Library of Sweden and the Swedish Film Institute also\n",
    "gives online access to some three hundred SF-newsreels in high resolution,\n",
    "MPEG-2-versions, at the portal filmarkivet.se—thus, occasionally we will\n",
    "illustrate our arguments with these film versions as well. Then again, there is\n",
    "a sharp contrast between the highly curated selection of restored\n",
    "high-resolution newsreels available through filmarkivet.se, and the low-quality\n",
    "digitisation of a vast majority of the SF newsreel archive. In addition,\n",
    "filmarkivet.se provides limited metadata, little contextualization using film\n",
    "historical sources, and no possibility to analyze the content at hand as data,\n",
    "effectively limiting the scholarly utility of the site <cite id=\"zmeiv\"><a\n",
    "href=\"#zotero%7C22783102%2F583554VC\">(Snickars 2015: 65)</a></cite>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load audio stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Signal archeology of the audiovisual past"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "u4gve": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Annotating content within 5,205 (TODO) nonfiction films is already a demanding\n",
    "task, but doing so with precision across both the sonic and visual domains\n",
    "requires even greater care and effort. Previous research has emphasized the\n",
    "time-consuming nature of audiovisual annotation <cite id=\"u4gve\"><a\n",
    "href=\"#zotero%7C22783102%2FWHSQVQAB\">(Guyot et al., 2019)</a></cite>.\n",
    "Nevertheless, to fully understand how these films are structured, both audio\n",
    "and visuals must be taken into consideration. Not only do image and sound play\n",
    "crucial roles within newsreels—naturally, after the introduction of sound in\n",
    "the early 1930s—but the genre also provides a valuable window into the\n",
    "historical formation of specific ways of juxtaposing these modalities within\n",
    "the Journal Digital collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "9ahou": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Importantly, approaching this film collection through an archaeology of the\n",
    "audiovisual signal invites a shift in perspective: from meaning to trace, from\n",
    "representation to inscription <cite id=\"9ahou\"><a\n",
    "href=\"#zotero%7C22783102%2FK4N8PIGZ\">(Malmstedt, 2025)</a></cite>. Each film\n",
    "can be understood as a layered field of signals that bears the marks of its\n",
    "technological circumstances, institutional routines, and cultural habits. Sound\n",
    "and image are, then, less regarded as vehicles of meaning, but rather\n",
    "historical artefacts that carry within their textures and fluctuations the\n",
    "sedimented practices of production and aesthetics. Accordingly, the initial\n",
    "experiments conducted on this dataset account for both sound and image,\n",
    "complementing human interpretation with automated annotations. This approach\n",
    "enables the generation of first-level segmentations for each modality, allowing\n",
    "for both separate and integrated navigation within large, untagged archival\n",
    "collections. It also establishes a foundation for comparative analysis of the\n",
    "relationship between the visual and auditory modalities, to be explored in the\n",
    "following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "To analyse this aspect of audiovisual communication, we employ computational\n",
    "methods that can register both the visual and sonic dimensions of newsreels.\n",
    "Specifically, we use transformer-based models such as Moondream, a\n",
    "vision-language model for object detection and vision tasks (Korrapati 2025),\n",
    "and an AST (Audio Spectrogram Transformer, Gong et al. 2021). Each model\n",
    "processes its respective sensory channel independently. Yet their embeddings\n",
    "can be aligned to enable cross-modal comparison. To illustrate this workflow,\n",
    "the following film segment has been annotated in both the audio and visual\n",
    "domains. Both models were used in their publicly available, pre-trained forms,\n",
    "which have demonstrated high general accuracy across a wide range of\n",
    "audiovisual tasks. Moondream, a transformer-based vision-language model, is\n",
    "designed for lightweight image understanding and captioning, enabling efficient\n",
    "object detection and scene parsing even on modest computational resources.\n",
    "However, we made several adjustments to tailor their performance to the\n",
    "specific requirements of historical newsreel material. For the visual analysis,\n",
    "we limited the number of detected objects in each frame to emphasize overall\n",
    "compositional and semantic features rather than exhaustive enumeration. Without\n",
    "this constraint, the model tended to generate redundant detections, for\n",
    "instance, identifying every instance of a person separately, which led to\n",
    "overly cluttered outputs. In the audio domain, we refined the results by\n",
    "filtering out misleading detections, such as static noise being misclassified\n",
    "as environmental sounds like rain. These calibrations allowed us to focus on\n",
    "the broader audiovisual texture of the material rather than on granular or\n",
    "noisy details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Traces of sonic experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To understand how content is distributed, the first thing to consider is the\n",
    "nature of the dataset itself. The SF-archive—and the subsequent Journal Digital\n",
    "collection—varies widely in scope and condition; the latter have during decades\n",
    "been conditioned by differences in film production, and later by dissimilar and\n",
    "uneven processes of preservation. Some nitrate prints have hence only survived\n",
    "in partial form, and (after the introduction of sound) many films still lack a\n",
    "complete soundtrack, usually because the audio has deteriorated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Figure\n",
    "audio_files_year = pd.read_csv(data / 'year_audio_files.tsv', sep='\\t').set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-audio_bars-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"The graph shows the overall distribution of audiovisual films \"\n",
    "                \"in the Journal Digital collection—with the digital emphasis \"\n",
    "                \"on files with sound As is evident, the distribution of files \"\n",
    "                \"is uneven, with a gradual increase during the 1930s.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_audio_bars():\n",
    "    fig =    px.bar(\n",
    "        audio_files_year,\n",
    "        y='audio',\n",
    "        title='Files with Useful Sound per Year (≥1930)')\n",
    "\n",
    "    fig.update_layout(\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"# of files with useful audio\",\n",
    "    xaxis=dict(\n",
    "        tickmode='linear',\n",
    "        tick0=1930,\n",
    "        dtick=10\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickmode='linear',\n",
    "        tick0=0,\n",
    "        dtick=10\n",
    "    )\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "display(\n",
    "    get_audio_bars(),\n",
    "metadata=metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "kr6es": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Tracing and tracking sound, the pattern above is expected: early in the 1930s,\n",
    "sound production of newsreels was limited by technical constraints and\n",
    "substantial costs. However, the data also offers a revealing media-historical\n",
    "insight into the gradual incorporation of sound into the newsreel format.\n",
    "Whereas the arrival of sound in cinema is often portrayed as a sudden and\n",
    "decisive transformation, usually pinpointing the talkie musical drama, The Jazz\n",
    "Singer (1927)—featuring six songs performed by Al Jolson—evidence from the\n",
    "Journal Digital collection indicate a more gradual and slower media migration,\n",
    "that is a slightly uneven process of sound integration <cite id=\"kr6es\"><a\n",
    "href=\"#zotero%7C22783102%2FTEPVQNE3\">(Beck, 2011)</a></cite>. Furthermore, the\n",
    "second half of the graph above shows a gradual decline. At first glance, this\n",
    "might seem surprising, but it is more likely a reflection of the structure of\n",
    "the film collection than of an actual historical trend. If one instead plots\n",
    "the proportion of films containing sound for each year, a more consistent\n",
    "pattern of integration appears, evident in the graph below. It also provides a\n",
    "clearer foundation for our following analysis, where we examine how image and\n",
    "sound interact across different phases of newsreel development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_files_year['share'] = audio_files_year['audio'] / audio_files_year['files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-audio_shares-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"Departing from newsreels with sound in the Journal Digital \"\n",
    "                \"Corpus, the graph shows the share of digital film files with \"\n",
    "                \"sound from 1930 until 1966. The drop in 1963 is the result of \"\n",
    "                \"SF-newsreel production coming to a complete end.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_audio_line():\n",
    "    fig =    px.line(\n",
    "        audio_files_year,\n",
    "        y='share',\n",
    "        title='Share of Files with Useful Sound per Year (≥1930)')\n",
    "\n",
    "    fig.update_layout(\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"# of files with useful audio\",\n",
    "    xaxis=dict(\n",
    "        tickmode='linear',\n",
    "        tick0=1930,\n",
    "        dtick=10\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickmode='linear',\n",
    "        tick0=0,\n",
    "        dtick=10\n",
    "    )\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "display(\n",
    "    get_audio_line(),\n",
    "metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "eqhsq": [],
      "gu35x": [],
      "reghd": [],
      "u2cy7": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "One observation to be made, is that the graph makes the process of audiovisual\n",
    "integration in newsreel production appear almost linear, a steady movement\n",
    "toward the normalization of sound. But it is also striking to observe that\n",
    "silent films continued to appear well into the 1940s. The data therefore resist\n",
    "any neat periodisation. What can be seen instead is a slow and uneven adoption\n",
    "that depends as much on institutional practice and local conditions, as on\n",
    "technological possibilities. It is worth keeping in mind, and a reminiscence\n",
    "that patterns one might observe later are shaped by underlying imbalances in\n",
    "the film archive itself. But the gradual nature of sound transition is\n",
    "interesting for another reason as well. It suggests that the Journal Digital\n",
    "collection does not simply document the use of sound, but also the process\n",
    "through which sound was being tested, adjusted, and creatively incorporated\n",
    "into the newsreel format. In other words, films capture a moment of\n",
    "experimentation, starting in the early 1930s when the vocabulary of sound in\n",
    "nonfiction film production was still being invented, including the documented\n",
    "ambivalence to the invention of audio supplementation within moving images.\n",
    "When sound was finally incorporated, film critics such as Béla Balázs or Rudolf\n",
    "Arnheim, and filmmakers such as Sergei Eisenstein and Vsevolod Pudovin,\n",
    "lamented that it destroyed the purity of cinematic realism (<cite id=\"reghd\"><a\n",
    "href=\"#zotero%7C22783102%2FNEKVNJJD\">Arnheim, 1957</a></cite>, <cite\n",
    "id=\"eqhsq\"><a href=\"#zotero%7C22783102%2FPCBNCFMD\">Eisenstein et al.,\n",
    "1994</a></cite>, <cite id=\"u2cy7\"><a\n",
    "href=\"#zotero%7C22783102%2F2IBV4AM6\">Balázs, 2010</a></cite>, <cite\n",
    "id=\"gu35x\"><a href=\"#zotero%7C22783102%2FUVAHYVZ2\">Balázs, 2017</a></cite>).\n",
    "While others celebrated the shift as a deepening of the medium’s evidential\n",
    "power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO Figure `28` goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When newsreels during the 1930s started to include sound—what could be heard in\n",
    "Swedish cinemas? That is, what kind of specific sounds on a general level can\n",
    "be detected in the Journal Digital collection by way of an aural, computational\n",
    "analyses? As is evident from the graph above, the majority of the sound\n",
    "consisted of speech and music. This is perhaps not entirely unexpected, and can\n",
    "be understood as an extension of the role once played by intertitles, which\n",
    "previously carried much of the newsreel’s informational value—an issue we will\n",
    "return to. There also appears to be a slight trend toward increased use of\n",
    "music over time. All of this holds true up until the final years represented in\n",
    "the dataset. However, we should be mindful of the distribution of data in this\n",
    "period, where the smaller number of film files means that percentages may be\n",
    "skewed (by only a few examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "mawwp": [],
      "rerwk": []
     }
    }
   },
   "source": [
    "If speech and music are obvious categories that a sound analysis of the entire\n",
    "Journal Digital collection would detect, the third category (Other) is of more\n",
    "interest. It encompasses both sound effects and diegetic elements, as well as\n",
    "how they relate to actual imagery (Chion 1994). Listing the main types of\n",
    "sounds in this category immediately gives some sense of their function. A large\n",
    "number of detections are, for example, labeled as bursts or explosions. They\n",
    "should not, however, be taken as evidence of a particularly violent film\n",
    "corpus. In many cases, these are false positives: early optical audio\n",
    "recordings simply contain too much noise, and the AST model tends to interpret\n",
    "such random distortions as explosions. In fact, even to the human ear, the\n",
    "newsreel soundtracks are often so rough that it is difficult to tell whether a\n",
    "noise belongs to a recorded scene, or if it is simply an artifact of the medium\n",
    "itself. Beyond these, the data also show frequent detections of animals, cars,\n",
    "and other vehicles. A fascination for hearing modernity, and bringing the\n",
    "sounds of the streets to cinema audiences, was apparent in the early reception\n",
    "of the sound film technology. A Stockholm film critic in 1928, upon reviewing\n",
    "the emergent sound-infused newsreels (from Denmark), exclaimed: “The cars\n",
    "screeched, the horses’ hooves rattled—and far off in the distance the guard\n",
    "parade approached. There came the first real reminder of where sound film has\n",
    "its greatest significance: in the newsreels” (Dagens Nyheter 1928). In fact,\n",
    "vehicle sounds appear especially often in our dataset, accounting for around\n",
    "eleven percent of all entries in the Other category. This prevalence may merit\n",
    "closer attention. The sound of a vehicle in the 1930s would have carried very\n",
    "different connotations than it does today <cite id=\"rerwk\"><a\n",
    "href=\"#zotero%7C22783102%2F6AUNIX6I\">(Brownell, 1972)</a></cite>. It was less\n",
    "an everyday background noise—and more a distinctive signal of modernity. ”What\n",
    "they heard was a new kind of sound that was the product of modern technology”\n",
    "<cite id=\"mawwp\"><a href=\"#zotero%7C22783102%2FURY9RMYJ\">(Thompson,\n",
    "2004)</a></cite>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO Figure `29` goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to discover how sounds of modernity are manifested in the Journal\n",
    "Digital collection, is to take a closer look at how vehicle sounds are paired\n",
    "with particular types of images. Interestingly, none of the detected vehicle\n",
    "sounds correspond directly to images of cars. Instead, they tend to appear\n",
    "alongside signs of outdoor or on-location filming: buildings, stretches of sky,\n",
    "grass, and trees all coincide with the presence of vehicle sounds. To some\n",
    "extent, this may be an artifact of the analysis, since the model occasionally\n",
    "identifies vehicle sounds in scenes where no vehicles are visible. Yet, the\n",
    "pattern is revealing, and also demonstrates a surprisingly sophisticated way of\n",
    "representing sound. Rather than merely mirroring what is seen, the soundtrack\n",
    "adds another layer of meaning. Vehicle sounds are often paired with other kinds\n",
    "of visual information, suggesting that sound was used to evoke atmosphere,\n",
    "location, or a sense of movement rather than simply adding an ordinary sound\n",
    "track. This raises the question how sound and image were actually attached,\n",
    "both practically and conceptually, within newsreels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "To explore the relationship between sound and image in the Journal Digital\n",
    "collection, the following graph presents a method designed to track recurring\n",
    "pairings between audiovisual elements. This method extracts co-occurring audio\n",
    "and visual label pairs from films and summarises their temporal association\n",
    "across years. Visual labels are read at frame times, merged within a short\n",
    "window around each timestamp, and cleaned to remove placeholders, numbers,\n",
    "generic words, and banned categories. Audio categories come either from time\n",
    "aligned probability scores or—when class names are unreliable—from a stored\n",
    "list of top labels; both paths are converted into simple word tokens after the\n",
    "same cleaning. At each timestamp the present audio tokens and visual tokens\n",
    "form pairs that are tracked as segments with start time, end time, and\n",
    "duration; very short segments are dropped, and files dominated by silence are\n",
    "skipped early. Segments are then matched to a year using a name to year table,\n",
    "then aggregated to compute total seconds and the number of distinct videos for\n",
    "each pair, with a minimum total duration filter. Results are written to CSV\n",
    "files including all pairs, per year summaries, and a ranked shortlist that\n",
    "enforces per audio and per visual caps, along with a global limit so no single\n",
    "label dominates. For the shortlisted pairs the code also exports per year\n",
    "totals and percentages of each year’s total duration to support plotting and\n",
    "later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO Figure `30` goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Exploring the relationship between sound and image, some displayed correlations\n",
    "point toward the emergence of a few specific patterns. A number of these are\n",
    "straightforward and expected, such as artillery paired with gunfire, or\n",
    "applause with crowds, or fire with scenes of gathering people. Others make\n",
    "sense only partially, like the pairing of speedboats and airplanes, which\n",
    "likely results from a misrecognition of similar sound textures. Then there are\n",
    "combinations that are more puzzling, such as the frequent link between a bell\n",
    "sound and the appearance of a flag. Overall, there seems to be a recurring\n",
    "tendency for certain cross-domain associations to appear at specific moments in\n",
    "time, rather than evenly across the dataset. It is also clear that the highest\n",
    "occurrences are those paired with vehicle. Looking at the broader temporal\n",
    "graph, some co-occurrences peak quite distinctly in the early 1940s. This\n",
    "cannot simply be explained by the general volume of material from that period,\n",
    "since the overall number of films was then beginning to decline. Instead, it\n",
    "suggests an evolving approach to diegetic strategy—one that rises and recedes\n",
    "rather than progressing in a straight line. To explore this issue further, we\n",
    "manually examined the most frequent pairings identified across both sound and\n",
    "image domains. From these observations we compiled a list of potential diegetic\n",
    "connections. A rise in the use of sound was then observed, yet it is not clear\n",
    "that a distinctly diegetic style ever became dominant. Sound and image appear\n",
    "instead in the Journal Digital collection to function as largely independent\n",
    "channels of information. This separation was likely shaped by practical\n",
    "limitations, especially the uneven quality of early audio recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO Figure `31` goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "cacs6": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In 1947, Stellan Dahlstedt (1910–1991), published an article about the sound\n",
    "studios at Svensk Filmindustri. Sound recording on film is hardly “the easiest\n",
    "procedure in filmmaking, as more than one director or producer is willing to\n",
    "attest”. During recording, it was often not possible to achieve the sound\n",
    "effects needed, Dahlstedt continued. In particular, it was difficult to “adjust\n",
    "the strength and character of the different sounds during live recording.\n",
    "Therefore, each sound is recorded separately as much as possible and mixed\n",
    "during replay”. It was no secret that such a practice increased the amount of\n",
    "film stock used. Still, it saved time because there was “no need to experiment\n",
    "with different sound effects during filming. It is the studio time that is the\n",
    "most expensive part of a film recording” <cite id=\"cacs6\"><a\n",
    "href=\"#zotero%7C22783102%2FFDPKQ7P8\">(Dahlstedt, 1947)</a></cite>. As director\n",
    "of film technology at SF, Dahlstedt knew what he was talking about—even if he\n",
    "was all likely writing about feature film production rather than newsreels.\n",
    "Then again, his statement to avoid experimenting with sound effects during\n",
    "filming, has relevance for our audio analyses. On-location sound in newsreel\n",
    "production seems to have been both fashionable and valued during the period,\n",
    "but also technically demanding. Most sounds were added during post-production,\n",
    "especially voice-over narration, but our analyses cannot really confirm the\n",
    "relation between diegetic and non-diegetic sound, at least not in a scholarly\n",
    "decent way. What is lacking within our signal archaeology set-up is the ability\n",
    "to align sound features more directly with visual content, as is today done in\n",
    "several other multimodal learning approaches. If newsreels did not consistently\n",
    "rely on synchronized or diegetic sound, it would be misleading for\n",
    "computational models to assume that a visible object should always have an\n",
    "audible counterpart. One way forward would be to integrate an adjacent layer of\n",
    "information—the textual. Intertitles, commentary, and other written elements\n",
    "often mediated the relationship between sound and image, and their gradual\n",
    "incorporation into the audiovisual mix hence deserves closer attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-blueprint-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \" At the Swedish SF company in the Film-City, north of \"\n",
    "                \"Stockholm, a new sound laboratory was inaugurated in the \"\n",
    "                \"late 1940s. It included a sound central (Ljudcentralen), an \"\n",
    "                \"echo-chamber (Ekorum) and a muting room (Dämpat rum). On the \"\n",
    "                \"second floor there was also a mixing room, and a specific \"\n",
    "                \"newsreel facility.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "display(Image(\"./media/img7.png\", width=800), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Exploring newsreel intertitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "ndzpp": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "While signal archaeology renders some insight into the audio dimensions of the\n",
    "Journal Digital collection, such a dataset by definition excludes early\n",
    "(silent) cinema. Yet non-visual data can also be gleaned from the latter by\n",
    "focusing on so-called intertitles. After 1900 they were inserted between scenes\n",
    "to provide important details about location, time or setting after a scene\n",
    "shift. With films growing longer, the use of intertitles also expanded. From\n",
    "1910 until the advent of sound cinema, intertitles became common practice in\n",
    "the film industry with its own conventions and codes. For examples, intertitles\n",
    "came to incorporate extended textual passages that filled the screen,\n",
    "typographic differentiation to mark hierarchies between narrator and dialogue,\n",
    "and ornamental as well as stylistic devices that underscored the intertitles\n",
    "aesthetic function within the cinematic experience <cite id=\"ndzpp\"><a\n",
    "href=\"#zotero%7C22783102%2F8P2FL3R2\">(Dupré La Tour 2005: 473)</a></cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "bzmpk": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "When multi-reel feature films started to emerge, the intertitles provided a\n",
    "crucial function offering information necessary to condense the story or\n",
    "provide dialogue <cite id=\"bzmpk\"><a\n",
    "href=\"#zotero%7C22783102%2F8BSVNXZQ\">(Chaume, 2020: 106)</a></cite>. In\n",
    "newsreels, meanwhile, the intertitles functioned to structure the visual\n",
    "storyline, provide factual information about time, settings and portrayed\n",
    "individuals, and offer commentary guiding audience reactions. With the\n",
    "introduction of sound, the use of intertitles certainly changed, and the\n",
    "introduction of voice-over commentary made the intertitles shorter.\n",
    "Nevertheless, this overlooked and in previous digital historical research\n",
    "neglected audiovisual artefact includes a lot of textual information. In fact,\n",
    "the Journal Digital collection contains almost fifty thousand intertitles; they\n",
    "appear in more than 4,300 nonfiction films. Emphasis in this section will be\n",
    "placed on contextualizing the newsreel Svensk Filmindustris Veckorevy (Svensk\n",
    "Filmindustri’s Weekly Review) and the Journal Digital corpus, describing the\n",
    "transcription pipeline, and exploring the collection using Voyant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-military-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"Within the Journal Digital collection there are a number of \"\n",
    "                \"foreign nonfiction films, such as this unidentified short \"\n",
    "                \"film fragment from the mid 1910s, produced by Universal \"\n",
    "                \"Screen Magazine, with more than ten intertitles in less than \"\n",
    "                \"two minutes—albeit with short military orders!\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "display(Image(\"./media/img8.png\", width=800), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "8lcdf": [],
      "nm7s1": [],
      "v3shd": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Though previous research on newsreel intertitles is limited, there is a\n",
    "noticeable tension regarding how the editorial comments should be interpreted\n",
    "as a historical record. Some scholars argue that newsreel intertitles were\n",
    "primarily descriptive and that it was only with the invention of sound\n",
    "commentary that newsreels actually became a news medium proper. Nicolas Pronay,\n",
    "for example, argues that the “range of social and political information which\n",
    "could be conveyed by pictures and monosyllabic captions alone, was obviously\n",
    "too restricted. The change-over to sound-film ... enabled them to cover any\n",
    "subject which was news-worthy irrespective of whether it was pictorial in\n",
    "nature” <cite id=\"8lcdf\"><a href=\"#zotero%7C22783102%2FNTI97CTV\">(Pronay, 1971:\n",
    "412)</a></cite>. Similarly, Nicholas Reeves, writing on the topic of British\n",
    "film propaganda during World War I, contends that the “dominant approach of the\n",
    "newsreels’ editorial comment as carried by the titles was factual and\n",
    "restrained” <cite id=\"nm7s1\"><a href=\"#zotero%7C22783102%2FWQEJMM77\">(Reeves,\n",
    "1986: 199–200)</a></cite>. From this perspective, the textual information in\n",
    "early cinema had a limited rhetorical function, due to both media technological\n",
    "conditions and established genre conventions. Recent scholarship, however, have\n",
    "argued that long before sound, newsreels included intertitles that “served to\n",
    "explain and ideologically tint the footage sandwiched between them” <cite\n",
    "id=\"v3shd\"><a href=\"#zotero%7C22783102%2FHDPCSX8E\">(Scott, 2024:\n",
    "34)</a></cite>. Hence, the rhetoric in the newsreel intertitles guided viewers’\n",
    "opinions in advance of what appeared on screen—prior to the introduction of\n",
    "sound.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "9vrve": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If the audio dataset of the Journal Digital collection gives us (at least some)\n",
    "insights about Swedish modernity, we argue that a dataset of some fifty\n",
    "thousand intertitles have a similar potential to provide commentary on Swedish\n",
    "society, touching on a wide variety of cultural, technological, and societal\n",
    "issues. Since intertitles were inserted into newsreeels—one textual prompt at\n",
    "the time—the amount of words is not mind-boggling. Nevertheless, our dataset\n",
    "still contains some 300,000 words. A key challenge when exploring these\n",
    "newsreel intertitles using digital methods is the frequent occurrence of\n",
    "mirrored flash intertitles. In film distribution and archiving, so-called flash\n",
    "intertitles served a distinct purpose. Notably, flash intertitles do not appear\n",
    "long enough for them to be readable. Rather they originally served as position\n",
    "markers on the negative, which in this context were used as a master copy for\n",
    "producing new prints, and hence pointing out exactly where to insert\n",
    "intertitles when producing a positive. Besides pointing out the position of the\n",
    "intertitles, the flash intertitles could also highlight the intended textual\n",
    "and visual design. Further, this practice has been commonplace in film\n",
    "distribution and archiving primarily to “save on expensive film material” <cite\n",
    "id=\"9vrve\"><a href=\"#zotero%7C22783102%2FJQZ27MNN\">(Dobringer et al., 2013:\n",
    "130)</a></cite>. Then again, to many film historians mirrored flash intertitles\n",
    "have always been a nuisance, not the least since some formats for moving images\n",
    "make it totally impossible to read them—on video it is hopeless, yet in an\n",
    "editing table they can be read, and now also in digital format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-military-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"It is almost impossible to read the low resolution, and \"\n",
    "                \"mirrored flash intertitle, from SF’s Weekly Review \"\n",
    "                \"(15 April 1929)—a day when prince Fredrik from Denmark \"\n",
    "                \"arrived by train. The intertitle for the skiing competition \"\n",
    "                \"in Oslo at Holmenkolmen is easier to understand \"\n",
    "                \"(at least, if you speak Swedish), taken from, SF’s Weekly \"\n",
    "                \"Review (26 February 1921). Mirrored flash intertitles are \"\n",
    "                \"today still default for film historians using the Journal \"\n",
    "                \"Digital collection at the National Library of Sweden; at \"\n",
    "                \"filmarkivet.se, however, restored and high resolution \"\n",
    "                \"intertitle meets the viewer.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "display(Image(\"./media/img9.png\", width=800), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "hqu0v": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "There is little previous research on newsreel intertitles using digital\n",
    "methods. A notable exemption is a study on the Jean Desmet collection\n",
    "(1907–16), housed by the EYE Film Museum in the Netherlands. The authors show\n",
    "the usefulness of deep learning methods to detect intertitles in audiovisual\n",
    "corpora as markers of narrative structure <cite id=\"hqu0v\"><a\n",
    "href=\"#zotero%7C22783102%2FPUAS8ZHL\">(Bhargav et al., 2019)</a></cite>. While\n",
    "Bhargav and colleagues demonstrate the technical feasibility of using deep\n",
    "learning to detect and analyse intertitles in early cinema, our study expands\n",
    "the approach by developing a multimodal transcription pipeline for a much\n",
    "larger corpus of Swedish newsreels spanning five decades. As briefly described\n",
    "in our introduction, we developed a custom transcription tool tool, `stum`, \n",
    "and deployed it to \n",
    "create individual .srt files for the 4,333(`TODO: confirm count`) film with intertitles. The exact\n",
    "amount of texts totaled 302,342(`TODO: confirm count`) words. Notably, the intertitles have a lower\n",
    "capacity for encoding text than a voice narrator, but still remains a vital\n",
    "source of information about the content of the films. Moreover, beside metadata\n",
    "about films, it is the only way to cover what the newsreels were actually\n",
    "about. It should be stressed, however, that given the major amount of catalogue\n",
    "work that Gardar Sahlberg (and other staff at SVT/SR) did during the 1960s and\n",
    "1970s, the metadata for most films within the SF-archive is affluent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "ig4sa": [],
      "ujid1": [],
      "v61pc": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "stum leverages pre-existing algorithms/models to create a pipeline suitable for this video collection: specifically, it uses OpenCV2 <cite id=\"v61pc\"><a href=\"#zotero%7C22783102%2FMFU9DVN9\">(Bradski, 2000)</a></cite> and TesseractOCR <cite id=\"ujid1\"><a href=\"#zotero%7C22783102%2FAZ3BT53M\">(Smith, 2007)</a></cite> to detect intertitles and extract their textual contents. OCR quality of all the tested intertitles is excellent—the highest Character Error Rate we have encountered is below seven percent. The main problem to solve was intertitle detection. Since flash intertitles usually only comprise a single frame we needed to extract every single frame of each film. Afterwards, stum would group these frames on low levels of changes in pixels. Similar frames were treated as a single scene or segment, from which we use the middle frame for intertitle detection. In general, intertitles within the Journal Digital collection are typically white, but there is also a significant portion with a dark background, and a further portion where the intertitle is superimposed on the film. We hence decided to focus on the former, and use a combination of calculating the relative size of the largest contour (black or white) and an EAST model for detecting characters <cite id=\"ig4sa\"><a href=\"#zotero%7C22783102%2FDBCYMUBB\">(Zhou et al., 2017)</a></cite>.  Frames that were deemed relevant by both these approaches were then passed through an OCR engine—stored both as a mirrored and nonmirrored intertitle. The resulting text output was then combined with the timestamp calculated from the intertitle’s sequence’s of frames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "// skotks terrier https://modern36.github.io/jdc_reader/#q=skottsk+terrier&fuzzy=1&video=sf%2F1928%2FSF604A.1.mpg\n",
    "// https://github.com/Modern36/journal_digital_corpus/blob/main/corpus/intertitle/sf/1928/SF604A.1.mpg.srt#L25-L28\n",
    "\n",
    "\n",
    "\n",
    "In the following cell we initiate a small video player that loads the sequance\n",
    "of .png files (frames 14540-14564 from 'SF604A.1.mpg').\n",
    "It has controls for playback speed, pausing, looping, as scrubber for selecting\n",
    "a specific frame an option to pause for 2 seconds at a specific frame.\n",
    "It defaults to the original playback speed of the video file (25fps) and pauses\n",
    "at the mirrored flash-intertitle frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load intertitle stuff TODO: replace with library once the PRs have gone through.\n",
    "!wget https://zenodo.org/records/15596192/files/Modern36/journal_digital_corpus-2025.06.04.zip --nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_second = Path('.') / 'media' / 'one_second'\n",
    "terrier_dir = Path('.') / 'media' / 'terrier_frames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PNGSequencePlayer:\n",
    "    def __init__(self, file_paths, fps=24):\n",
    "        \"\"\"\n",
    "        file_paths: A list of string paths to the .png files (sorted).\n",
    "        fps: Default playback speed.\n",
    "        \"\"\"\n",
    "        # 1. Pre-load all PNG bytes into memory for zero-latency playback\n",
    "        self.frames_data = []\n",
    "        try:\n",
    "            for p in file_paths:\n",
    "                with open(p, 'rb') as f:\n",
    "                    self.frames_data.append(f.read())\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading files: {e}\")\n",
    "            return\n",
    "\n",
    "        self.n_frames = len(self.frames_data)\n",
    "        self.is_paused_event = False\n",
    "\n",
    "        # --- UI Components ---\n",
    "\n",
    "        # We tell the widget these are PNGs\n",
    "        self.image_widget = widgets.Image(\n",
    "            value=self.frames_data[0],\n",
    "            format='png',\n",
    "            layout=widgets.Layout(width='auto', max_width='250px')\n",
    "        )\n",
    "\n",
    "        # Animation Controller\n",
    "        self.play_widget = widgets.Play(\n",
    "            value=0, min=0, max=self.n_frames - 1,\n",
    "            step=1, interval=int(1000/fps),\n",
    "            description=\"Press play\", repeat=False\n",
    "        )\n",
    "\n",
    "        # Scrubber\n",
    "        self.slider = widgets.IntSlider(\n",
    "            value=0, min=0, max=self.n_frames - 1, description=\"Frame\"\n",
    "        )\n",
    "\n",
    "        # Controls\n",
    "        self.fps_input = widgets.BoundedIntText(\n",
    "            value=fps, min=1, max=120, step=1, description='FPS:',\n",
    "            layout=widgets.Layout(width='140px')\n",
    "        )\n",
    "\n",
    "        self.loop_box = widgets.Checkbox(value=False, description=\"Loop\")\n",
    "\n",
    "        # Pause Logic UI\n",
    "        self.pause_enable = widgets.Checkbox(value=True, description=\"Wait 2s @ Frame:\")\n",
    "        self.pause_idx = widgets.BoundedIntText(\n",
    "            value=12, min=0, max=self.n_frames-1, description='',\n",
    "            layout=widgets.Layout(width='60px')\n",
    "        )\n",
    "\n",
    "        # --- Logic Wiring ---\n",
    "\n",
    "        widgets.jslink((self.play_widget, 'value'), (self.slider, 'value'))\n",
    "\n",
    "        self.slider.observe(self.on_frame_change, names='value')\n",
    "        self.fps_input.observe(self.update_speed, names='value')\n",
    "        self.loop_box.observe(self.update_loop, names='value')\n",
    "\n",
    "        # --- Layout ---\n",
    "\n",
    "        # Group the specific pause controls\n",
    "        pause_group = widgets.HBox([self.pause_enable, self.pause_idx])\n",
    "\n",
    "        controls = widgets.VBox([\n",
    "            widgets.HBox([self.play_widget, self.slider]),\n",
    "            widgets.HBox([self.fps_input, self.loop_box, pause_group])\n",
    "        ])\n",
    "\n",
    "        self.ui = widgets.VBox([self.image_widget, controls])\n",
    "\n",
    "    def on_frame_change(self, change):\n",
    "        frame_idx = change['new']\n",
    "\n",
    "        # DIRECT BYTE SWAP - Extremely fast\n",
    "        self.image_widget.value = self.frames_data[frame_idx]\n",
    "\n",
    "        # Check for \"Magic Pause\"\n",
    "        if (self.play_widget.playing and\n",
    "            self.pause_enable.value and\n",
    "            frame_idx == self.pause_idx.value and\n",
    "            not self.is_paused_event):\n",
    "\n",
    "            self.trigger_pause()\n",
    "\n",
    "    def trigger_pause(self):\n",
    "        \"\"\"Stops animation, waits 2s in background thread, resumes.\"\"\"\n",
    "        self.is_paused_event = True\n",
    "        self.play_widget.playing = False # Stop\n",
    "\n",
    "        def resume_worker():\n",
    "            time.sleep(2)\n",
    "            self.play_widget.playing = True # Resume\n",
    "            # Tiny buffer to ensure we don't re-trigger on the same millisecond\n",
    "            time.sleep(0.2)\n",
    "            self.is_paused_event = False\n",
    "\n",
    "        threading.Thread(target=resume_worker).start()\n",
    "\n",
    "    def update_speed(self, change):\n",
    "        if change['new'] > 0:\n",
    "            self.play_widget.interval = int(1000 / change['new'])\n",
    "\n",
    "    def update_loop(self, change):\n",
    "        self.play_widget.repeat = change['new']\n",
    "\n",
    "    def show(self):\n",
    "        display(self.ui)\n",
    "terrier = PNGSequencePlayer(sorted(one_second.glob('*.png')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"tags\": [\"video-filmarkivet-*\",],\n",
    "        \"object\": {\n",
    "            \"type\":\"video\",\n",
    "            \"source\": [\n",
    "                \"Blink and you will miss it. We have cut 25 frames, equivalent to 1 second of playtime, from `SF604A.1.mpg` which showcases several of the technical obstacles of working with this this archival footage: 1) the videocompression is very lossy, leading to many blocky artefacts; 2) the flash intertitle is only fully visible in a single frame (frame 12) -- making it not only impossible for a viewer to read it -- but also very likely that they will miss it entirely;  3) the intertitle is left-right mirrored, making it more difficult to read -- especially for an OCR software.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "display(terrier.show(), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Due to the prevalence of `flash intertitles` we need to process every single\n",
    "frame. However, running every single frame through an intertitle-filter and\n",
    "subsequent  OCR engine is very inefficient.\n",
    "We therefore start by grouping the frames by sqeuential similarity -- that is\n",
    "we group similar images together, and only pass the middle image through\n",
    "the two step intertitle-filter before passing them through the OCR engine.\n",
    "\n",
    "The default threshold of `stum` to declare two intertitles 'different' enough\n",
    "is a Mean Square Error of 10,000. This is a completely arbitrary number\n",
    "that seems to work well for journal digital -- but might need to be updated\n",
    "before it can be successfully applied to other collections.\n",
    "\n",
    "TODO: add reference to original file for the MSE stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Mean Square Error -- TODO\n",
    "\n",
    "MSE_THRESHOLD = 10_000\n",
    "\n",
    "def mse(im1, im2):\n",
    "    err = np.sum((im1.astype(\"float\") - im2.astype(\"float\")) ** 2)\n",
    "    err /= float(im1.shape[0] * im1.shape[1])\n",
    "    return err\n",
    "\n",
    "def detect_scene_change(im1, im2):\n",
    "    score = mse(im1, im2)\n",
    "    return score > MSE_THRESHOLD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Here we load a short selection of prepared .png images and pass them\n",
    "through the MSE threshold test to show how it is able to detect\n",
    "the scene -> intertitle changes.\n",
    "\n",
    "media/terrier_frames/frame_14550.png\n",
    "ends one scene\n",
    "\n",
    "media/terrier_frames/frame_14551.png media/terrier_frames/frame_14552.png False\n",
    "Are a 'scene'\n",
    "\n",
    "media/terrier_frames/frame_14553.png\n",
    "is on its own\n",
    "\n",
    "media/terrier_frames/frame_14554.png\n",
    "starts a new scene\n",
    "\n",
    "\n",
    "`stum` then uses the _middle_ image of each grouping as the example image --\n",
    "avoiding passing every single image throught the filters:\n",
    "\n",
    "1. contours\n",
    "2. EAST Text detection\n",
    "3. Tesseract OCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = sorted(one_second.glob('frame_1455[0-4].png'))\n",
    "for path1, path2 in pairwise(images):\n",
    "    im1 = cv2.imread(str(path1))\n",
    "    im2 = cv2.imread(str(path2))\n",
    "    print(path1, path2, detect_scene_change(im1, im2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Below is an excerpt from # Contours `stum/src/stum/contours.py` as of (date TODO)\n",
    "showing `stums`s `contour filter`:\n",
    "It converts the incoming image to grayscale -- reducing the number of colour channels from three to a single channel.\n",
    "All our input images are already grayscale, but they are not all a single colour-channel -- this step is therefore necessecary to homogenize the images\n",
    "for the upcoming processing.\n",
    "\n",
    "The contours filter step converts the grayscale images to binary --\n",
    "converting the values of teach pixel from the range(0, 255) to being\n",
    "a 0 (black) or 1 (white).\n",
    "\n",
    "It then checks for the largest white contour in the image and calculates its size\n",
    "relative to the entire image. If the size of the contour is larger than the\n",
    "threshold (default set to 0.9) the function flags it as a potential intertitle\n",
    "frame. If the frams was not flagged as an intertitle, there is a chance that\n",
    "the frame is an intertitle with white text and black background, and the image\n",
    "is therefore inverted and checked again.\n",
    "\n",
    "All the heavy lifting in the image-processing is handled by OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Contours `stum/src/stum/contours.py`\n",
    "\n",
    "\n",
    "def largest_contour(binary_image: cv2.typing.MatLike):\n",
    "    \"\"\"Returns the relative area of the largest contour of the image\"\"\"\n",
    "    contours = cv2.findContours(\n",
    "        binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )[0]\n",
    "    largest = cv2.contourArea(max(contours, key=cv2.contourArea))\n",
    "\n",
    "    width, height = binary_image.shape\n",
    "    total_area = width * height\n",
    "    relative_area = largest / total_area\n",
    "\n",
    "    return relative_area\n",
    "\n",
    "def contour_filter(image: cv2.typing.MatLike, threshold=0.9) -> bool:\n",
    "    \"\"\"Check if image has one large contour\n",
    "\n",
    "    If the largest contour is smaller than the complement to the threshold,\n",
    "    it also calculates the largest contour of the inverted image. This is a\n",
    "    way to check for images with dark backgrounds and white text.\n",
    "\n",
    "    Parameters\n",
    "        image: cv2 image to check\n",
    "        threshold: threshold to check contour area against, default is 90%\n",
    "\n",
    "    Returns\n",
    "        True if image has one contour larger than given threshold\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    binary = cv2.threshold(\n",
    "        gray, 100, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV\n",
    "    )[1]\n",
    "\n",
    "    relative_area = largest_contour(binary)\n",
    "\n",
    "    if (1 - relative_area) > threshold:\n",
    "        inverted = cv2.bitwise_not(binary)\n",
    "\n",
    "        inverteds_largest_area = largest_contour(inverted)\n",
    "\n",
    "        relative_area = max(relative_area, inverteds_largest_area)\n",
    "\n",
    "    return relative_area > threshold"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Do not run\n",
    "# East `stum/src/stum/east.py`\n",
    "# TODO: Load the model\n",
    "\"\"\"\n",
    "The EAST model/algorithm {add ref}\n",
    "is a lightweight technique for detecting letters in images.\n",
    "In our experiments it has shown to be more reliable than tesseract in\n",
    "detecting whether an image has text in it -- and we therefore use it as\n",
    "an in-between step to filter out monotone images without text before they\n",
    "are sent to the OCR engine -- which is the last and slowest part of the\n",
    "pipeline.\n",
    "\n",
    "\n",
    "In the final step of the pipeline the largest contour is extracted form the\n",
    "frame -- and\n",
    "\n",
    "And this cropped part if the image is passed through the OCR engine twice:\n",
    "once in its original form and once more in its mirrored form -- keeping the\n",
    "text output that contains the fewest special characters.\n",
    "\n",
    "The pipeline then merges adjacent (think frames) groups with text and use the\n",
    "numbering on the frames to calculate the timestamps (with a default 25fps)\n",
    "for the .srt files.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "model_loc = (\n",
    "    Path('.').parents[2] / \"models\" / \"frozen_east_text_detection.pb\"\n",
    ")\n",
    "\n",
    "east_net = cv2.dnn.readNet(str(model_loc))\n",
    "\n",
    "layerNames = [\"feature_fusion/Conv_7/Sigmoid\", \"feature_fusion/concat_3\"]\n",
    "\n",
    "\n",
    "def east_filter(image: cv2.typing.MatLike) -> bool:\n",
    "    \"\"\"\n",
    "    This function filters an image using the EAST text detection model.\n",
    "\n",
    "    Parameters:\n",
    "    - image (cv2.typing\tMatLike): The input image to be filtered.\n",
    "\n",
    "    Returns:\n",
    "    - A boolean indicating whether the image contains any detected text or not.\n",
    "    \"\"\"\n",
    "\n",
    "    image_height, image_width = image.shape[:2]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        image,\n",
    "        1.0,\n",
    "        (image_width, image_height),\n",
    "        (123.68, 116.78, 103.94),\n",
    "        swapRB=True,\n",
    "        crop=False,\n",
    "    )\n",
    "\n",
    "    east_net.setInput(blob)\n",
    "    scores, _ = east_net.forward(layerNames)\n",
    "\n",
    "    num_scores = scores.shape[2]\n",
    "\n",
    "    score_data = [scores[0, 0, i] for i in range(num_scores)]\n",
    "\n",
    "    max_score = max([max(row) for row in score_data])\n",
    "    return max_score > 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Moving on the the next part of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "8ndtc": [],
      "gm0zt": [],
      "zpe4r": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Quantitative and computational approaches to film history have a longer history than is often assumed. Indeed, experiments with quantification and data visualization date back to the 1960s and 1970s, when scholars such as Barry Salt began measuring average shot lengths <cite id=\"gm0zt\"><a href=\"#zotero%7C22783102%2FGVASD2H8\">(Gaines, 2024: 22)</a></cite>. Similarly, in the mid-2000s, the large-scale Cinemetrics database for statistical film style analysis was launched <cite id=\"gm0zt\"><a href=\"#zotero%7C22783102%2FGVASD2H8\">(Gaines, 2024: 22)</a></cite>. These early initiatives foreshadowed the current wave of digital film history, which tends to combine distant and close viewing <cite id=\"zpe4r\"><a href=\"#zotero%7C22783102%2F3TIXWE3B\">(Dang et al., 2024)</a></cite>. Our emphasis in the following lies on using the application Voyant to explore what role intertitles had in newsreels over time, as well as exploring (the now searchable) newsreel intertitles focusing on the theme of modernity. With regard to Swedish film history, scholars have noted that the introduction of sound soon had a significant impact on the newsreel genre. In December 1929, the film Say it with music (directed by Edvin Adolphson and Julius Jaenzon) was advertised as the first Swedish sound film \n",
    "<cite id=\"8ndtc\"><a href=\"#zotero%7C22783102%2F94IX6F2L\">(Furhammar, 2003: 129)</a></cite>. Shortly thereafter, in April 1930, the first newsreel with authentic sound was released featuring the Guard Parade in Stockholm \n",
    "<cite id=\"8ndtc\"><a href=\"#zotero%7C22783102%2F94IX6F2L\">(Furhammar, 2003: 149)</a></cite>. However, due to the fact that the sound equipment was still difficult to handle, newsreels initially featured voice-over commentary with “brisk and witty texts” \n",
    "<cite id=\"8ndtc\"><a href=\"#zotero%7C22783102%2F94IX6F2L\">(Furhammar, 2003: 149)</a></cite>. Having extracted all intertitles from the Journal Digital collection it is possible to detect how the narrative usage of intertitles changed over time. While newsreels quickly became a sound medium -- a “medium of the voice” \n",
    "<cite id=\"8ndtc\"><a href=\"#zotero%7C22783102%2F94IX6F2L\">(Furhammar, 2003: 149)</a></cite> -- a quantitative analysis reveals that the reliance on intertitles persisted longer than one might have imagined. The period from the mid 1910s to the early 1930s stands out as the period when most words per intertitle were used, which is hardly surprising given that films were then silent. More surprising is the fact that it was not until the late 1930s that the number of words per intertitle was reduced to the same levels as prior to the introduction of sound. Similarly, the total number of words in the intertitles grew in the 1920s, and then subsided toward the end of the 1930s. In addition—and worth stressing—is that intertitles remained in use throughout the whole newsreel era, up until the advent of television around 1960. In this sense, intertitles continued to play a narrative role also after newsreels became a “medium of the voice”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO: Update to use the native `Corpus` object loading the intertitles.\n",
    "\n",
    "In preparation for the distant reading of the intertitles we extract the\n",
    "subdirectory holding the .srt fioes from the downloaded\n",
    ".zip file of the Journal Digital Corpus.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "corpus_path = Path('.') / 'corpus'\n",
    "\n",
    "if not corpus_path.exists():\n",
    "    with zipfile.ZipFile('journal_digital_corpus-2025.06.04.zip') as zip_f:\n",
    "        corpus_name = [_ for _ in zip_f.namelist() if '/corpus/' in _]\n",
    "        print(corpus_name)\n",
    "        for target in  corpus_name:\n",
    "            zip_f.extract(target, 'tmp')\n",
    "        !mv tmp/Modern36-journal_digital_corpus-c1e6cdf/corpus corpus/\n",
    "        !rmdir tmp/*\n",
    "        !rmdir tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Refactor to use journal_digita.Corpus\n",
    "\"\"\"\n",
    "def load_intertitles():\n",
    "    for srt in corpus_path.glob('intertitle/sf/**/*.srt'):\n",
    "        year = srt.parent.name\n",
    "        if not year.isdigit():\n",
    "            continue\n",
    "        year = int(year)\n",
    "        if year < 1900:\n",
    "            continue\n",
    "        with open(srt, 'r', encoding='utf8') as f:\n",
    "            content = f.read()\n",
    "        intertitles =  [line  for i, line in enumerate(content.split('\\n')) if i % 4 == 2]\n",
    "        words = len([word for intertitle in intertitles for word in intertitle.split()])\n",
    "        words_per_intertitle = words / len(intertitles)\n",
    "\n",
    "        yield {\n",
    "            'file' : srt.name,\n",
    "            'year': year,\n",
    "            'num_intertitles' : len(intertitles),\n",
    "            'num_words' : words,\n",
    "            'words_per_intertitle': words_per_intertitle\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(load_intertitles())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bootstrapping confidence interval for visualization.\n",
    "\"\"\"\n",
    "def bootstrap_confidence_interval(data, n_bootstrap=1000, ci=95):\n",
    "    \"\"\"\n",
    "    Calculates the mean and bootstrapped confidence interval for a dataset.\n",
    "    \"\"\"\n",
    "    bootstrap_means = np.zeros(n_bootstrap)\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "        # Create a resample of the data (sampling with replacement)\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "    # Calculate the lower and upper bounds of the confidence interval\n",
    "    lower_bound = np.percentile(bootstrap_means, (100 - ci) / 2)\n",
    "    upper_bound = np.percentile(bootstrap_means, 100 - (100 - ci) / 2)\n",
    "\n",
    "    # Return the statistics in a pandas Series for easy aggregation\n",
    "    return pd.Series({\n",
    "        'mean': np.mean(data),\n",
    "        'ci_lower': lower_bound,\n",
    "        'ci_upper': upper_bound\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Fix X label, Y label and remove Legend\n",
    "def plot_with_ci(col, title):\n",
    "    summary_df = df.groupby('year')[col].apply(bootstrap_confidence_interval).unstack().reset_index()\n",
    "\n",
    "\n",
    "    # Create the figure with continuous error bands\n",
    "    fig = go.Figure([\n",
    "        # The mean line\n",
    "        go.Scatter(\n",
    "            x=summary_df['year'],\n",
    "            y=summary_df['mean'],\n",
    "            line=dict(color='rgb(0,100,80)'),\n",
    "            mode='lines',\n",
    "            name='Mean'\n",
    "        ),\n",
    "        # The confidence interval error band\n",
    "        go.Scatter(\n",
    "            x=np.concatenate([summary_df['year'], summary_df['year'][::-1]]), # x, then x reversed\n",
    "            y=np.concatenate([summary_df['ci_upper'], summary_df['ci_lower'][::-1]]), # upper, then lower reversed\n",
    "            fill='toself',\n",
    "            fillcolor='rgba(0,100,80,0.2)',\n",
    "            line=dict(color='rgba(255,255,255,0)'),\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=True,\n",
    "            name='95% Confidence Interval'\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='X Value',\n",
    "        yaxis_title='Mean of Y Value',\n",
    "        showlegend=False\n",
    "    )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "    plot_with_ci('words_per_intertitle', title='Average number of words per intertitle').show()\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "    plot_with_ci('num_words', title='Average number of words per video').show()\n",
    "\n",
    "display(widgets.VBox([out1, out2])    ,\n",
    "        metadata={\n",
    "        \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-military-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"The chart above plots the number of words that were used in each intertitle covering the entire Journal Digital collection. The chart below charts the average number of words in each film with intertitles, also in the entire Journal Digital collection. \"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "yon5m": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As noted, automatic speech recognition and other machine listening techniques have contributed toward making audiovisual archives searchable and computable. In this case, the transcription of the intertitles allowed us to explore the textual descriptions using a well-known tool such as Voyant. Some simple observations can be made with regard to topics covered. Not surprisingly, “Sweden”, “Swedish” and the capital of “Stockholm” are among the most frequently occurring words in the intertitle dataset. In terms of geography, other frequently mentioned cities are “Gothenburg”, “Paris” and “London”. This highlights the fact that the newsreel as a medium was highly transnational: reels depicting current events were bought, exchanged and distributed across Europe and the world <cite id=\"yon5m\"><a href=\"#zotero%7C22783102%2F685XZA23\">(Chambers et al., 2018)</a></cite>\n",
    ". In terms of thematic coverage, it is also noteworthy that the word “staden”, a city (117 counts), and the word “by”, village (118 counts)(`#TODO: verify count`), occur almost just as frequently in the intertitle corpus. Whereas the word city shows a concentration around the 1920s and 1930s, the word by is distributed more evenly across the corpus. This is thought-provoking given that the 1920s and 1930s have usually been described as a period of dramatic transformation, and a time when modernity arrived in Sweden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: add 46/47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "bk7y7": [],
      "pw91f": [],
      "uoqlf": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Intertitle transcriptions cannot only be used to mine the text material at scale, it is also makes it possible to navigate the material from a qualitative point-of-view. Zooming in on the issue of modernity, for example, it is feasible to use keyword search to find newsreels on distinct topics <cite id=\"pw91f\"><a href=\"#zotero%7C22783102%2FKADI4AFW\">(Armaselu &#38; Fickers, 2024)</a></cite>. For instance, searching for the word “moderna” results in 36 hits and “modern” in 29 hits. This allows one to detect specific newsreels with modern aspects of Swedish society, prevalent mostly during the 1920s and 1930s, with urban renewal projects, progressive social and employment reforms, and women gaining the right to vote (<cite id=\"bk7y7\"><a href=\"#zotero%7C22783102%2F6VFT9YB8\">Widenheim, 2002</a></cite>, <cite id=\"uoqlf\"><a href=\"#zotero%7C22783102%2F2X3XHIU7\">Habel, 2002</a></cite>\n",
    "). Some parts of the intertitle dataset naturally mirror prior metadata. Yet, the dataset of intertitles (with its .srt-files) also allows you to find the exact filmic moment (via time stamps) when an intertitle appears—which, furthermore, holds true for all transcribed speech—making it possible to navigate the audiovisual material in new ways. Given our interest in issues around Swedish modernity, a search for modern in the intertitle dataset, gives a vivid result of films—from a 1920s newsreel on defence exercise including “modern artillery weapons” (SF488B), and another newsreel item about a novel (and modern) fish market in the Stockholm Old Town (SF460.1), to a newsreel insert about state-of-art telephones in 1926 (SF519.1), the same year that the Swedish inventor Lars Magnusson Ericsson celebrated his 80th birthday (sadly he passed away later the same year). In this way, the intertitle dataset—gleaned from the Journal Digital corpus—indeed makes it possible to easily shift from large-scale text mining, to close qualitative analysis of particular newsreels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-telephone-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"The difference between the first telephone ... and the modern table telephone is of significance”, the SF’s Weekly Review (10 May 1926) stated. Via search through the intertitle dataset of the Journal Digital collection, it is possible to detect films, or sections of newsreels, otherwise hard to find—in this case using the search phrase moderna.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "display(Image(\"./media/img10.png\", width=800), metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Staden Vs by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load NER and GEO stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Scalable Geographic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "37mld": [],
      "495hw": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Since all newsreel production at Swedish Film Industry was headquartered in Stockholm—did this urban location dictate which parts of Sweden that appeared on cinema screens across the country? Which places were depicted, and how were they represented? Did the SF Weekly Review favour certain locations? Was there an urban gaze framing modernity via the provincial, the rural, or the remote? Such geographic questions of representation have prior been difficult to answer in a systematic way. While individual newsreels can be analysed, the sheer volume of filmic material within the SF-archive—decades of weekly or bi-weekly releases—has made corpus-level inquiry impractical. However, with the introduction of the Journal Digital corpus, it is possible to analyse filmic geographies of scale. If we previously described how signal archaeology was used to analyse the SF-archive via AST, and how we subsequently used the application stum to create a dataset of intertitles from silent newsreels, we created yet another application, SweScribe, based on sound extraction from the collection of newsreels. SweScribe uses WhisperX <cite id=\"495hw\"><a href=\"#zotero%7C22783102%2F89SWX3HE\">(Bain et al., 2023)</a></cite>, combined with a Whisper model from OpenAI—with a wav2vec2 model fine-tuned for Swedish—to transcribe and temporally align speech <cite id=\"37mld\"><a href=\"#zotero%7C22783102%2FAGCZGSA8\">(Malmsten et al., 2022)</a></cite>. Feeding SweScribe with a total 2,553(`# TODO: verify count`) sound newsreels containing—the previously mentioned speech, music and other—we were able to create a textual dataset comprising 2,229,854(`# TODO: verify count`) words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "0va8r": [],
      "p4u1o": [],
      "typgb": [],
      "uj108": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "It should be noted that early testing revealed weaknesses: SweScribe struggled with noisy environments and overlapping speakers, and tended to hallucinate plausible but often incorrect content when speech was unintelligible. The model also produces artefacts likely leaked from training data, such as subtitle credits. We addressed these through iterative cleaning steps, expanding our ground truth dataset from 27 to 89 manual transcriptions (72,812 words)(`#TODO: verify count`) across three sampling rounds, which considerably reduced Word Error Rate (WER) from 17 percent to only seven  percent <cite id=\"p4u1o\"><a href=\"#zotero%7C22783102%2F5LZCK9F3\">(Aspenskog et al., 2025)</a></cite>. As we have previously stated, when it came to sound newsreels were characterised by voice-over commentary, sometimes designated as voice-of-God narration, with a smaller proportion of interviews, and other speech events. Then again, with a low WER, the resulting Journal Digital corpus was deemed sufficiently accurate for the newsreels to be treated as textual sources. This transmediation enabled us to model a range of distant reading <cite id=\"typgb\"><a href=\"#zotero%7C22783102%2FSSCKKMRE\">(Moretti, 2000)</a></cite> and scalable reading approaches that hoovered between micro and macro level analyses (<cite id=\"uj108\"><a href=\"#zotero%7C22783102%2F8XFJBPEC\">(Weitin, 2017)</a></cite>, \n",
    "<cite id=\"0va8r\"><a href=\"#zotero%7C22783102%2FWEZNWR96\">(Fickers &#38; Clavert, 2021</a></cite>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In this article precursory examples have stressed different ways to address modernity via newsreel representation. SweScribe can be used in a similar way, and in the following we will showcase an analysis of various relations between the provincial and the urban in Swedish newsreels during a period of immense modernisation. One way is to examine the general division between the Stockholm region on one hand, and mentions of other Swedish regions on the other. We have been primarily interested in the urban gaze of the provincial, hence we pay particular attention to regions in the south and west of Sweden, situated near the second largest cities respectively, Gothenburg and Malmö. It should be stressed that each newsreel has a corresponding catalogue entry in the Swedish Media Database. Metadata include title, year, description, people, identifiers, and so called SAB subject codes (a library classification system). Such SAB codes were once assigned to newsreels, representing geographic as well as topical keywords. Topical SAB spans broader categories such as Military, to more specific ones like Christmas customs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In order to proceed, we scraped all metadata entries of each newsreel and extracted SAB codes from the catalogue. We discovered that the annotations varied in extensiveness, with some newsreels being carefully annotated, while others were poorly marked. This suggested that existing SAB metadata for the newsreels were sometimes unreliable for topic or geographic analysis. We continued our research set-up, and analysed the Journal Digital corpus through the application of Named Entity Recognition (NER), which—as is well known—can transform a corpus into a structured representation of who, what, and where. For our purposes, we applied off-the-shelf NER models primarily to extract toponyms from the corpus. When aggregated at the level of individual reels, years, or thematic groupings, these entities made it possible to pose questions such as which regions were most frequently mentioned in the commentary, and in what kinds of discursive surroundings. To compare these two approaches, we visualised both layers—the geographic SAB codes and NER data—through an interactive heatmap with a chronological slider. This visualisation confirmed that the differences between the SAB and NER datasets were substantial, reinforcing our earlier observation about the inconsistency of the SAB annotations. While functioning as a birds-eye comparison and verification tool, ​the heatmap also made it possible to see broader geographical trends in newsreel coverage over time at a glance. Given the often unreliable SAB metadata, we chose NER data for our continued geographic analysis of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MAP widget."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "In order to develop a workflow combining NER with geolocation—an approach we deemed more reliable for systematically mapping the spatial dimensions of the corpus—we used bert-base-swedish-cased-ner to extract locations from the corpus. Afterwards, we ran them through Nominatim to assign coordinates to each geographical location. We then passed the coordinates through to map the locations to an OpenStreetMap map ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Explain map above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"object\": {\n",
    "            \"tags\": [\"figure-sefyr-*\"],\n",
    "            \"type\":\"image\",\n",
    "            \"source\": [\n",
    "                \"During the mid 1930s Swedish Film Industry joined the newspaper Stockholm-Tidningen and purchased an airplane – SE-FYR. The small aircraft was used extensively within newsreel film production, both as a way to reach regional locations in Sweden, as well as for aerial cinematography. Illustrations from Svensk Flyghistorisk Förening.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "display(Image(\"./media/img11.png\", width=800), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### A Flying Symbol of Modernity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "It did not come as a total surprise that SF’s Weekly Review favoured the capital of Sweden. Extracted location data from SweScribe reveals a persistent over-representation of the Stockholm region. Yet, given SF’s metropolitan base, it raises questions if there were any attempts made to address this form of over-representation. While exploring the corpus, we encountered repeated references to an airplane named Sefyr—or SE-FYR—jointly owned by SF and the newspaper Stockholms-Tidningen; the aircraft was acquired in 1934. Sefyr was dispatched whenever important events occurred at distances from the capital, and required rapid coverage both in SF’s newsreels and in Stockholms-Tidningen’s reports. This prompted us to investigate whether Sefyr might have functioned as an infrastructural response to the geographic concentration visible in our data—and whether its deployment had any measurable effect on the spatial distribution of newsreel coverage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "bduio": []
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "There is no prior academic inquiry on Sefyr’s function in SF’s newsreels. However, the company’s twenty-fifth anniversary book described the aircraft’s role within newsreel production. Besides the fact that the airplane “always lent something of the allure of speed and the wide open spaces,” its merits as an express carrier of news were habitually emphasised. Momentum and tempo—chief characteristics of modernity—were often associated with Sefyr. One vivid example was the marriage of the Swedish Princess Ingrid to the Danish Prince Frederik in late May 1935. Stockholm cinemas were packed with audiences who wanted to see daily audiovisual reports surrounding the wedding, which took place in the capital. The SF-newsreel department had even promised coverage of the princely couple’s arrival in Copenhagen aboard the Danish royal yacht: “There was nothing for it but to advertise it. Without reservation. Sefyr was the guarantor.” In fact, Sefyr’s “popular pilot,” Åke Söderberg, arrived in Copenhagen the day before to make preparations, together with a reporter and a cameraman. As soon as the team had shot their material from both air and land, the airplane took off for Stockholm with the reels. Sefyr landed in Stockholm at 18:40; the reels were then developed and edited, and a few hours later the sequences were shown to audiences by the end of that evening’s last screenings in Stockholm <cite id=\"bduio\"><a href=\"#zotero%7C22783102%2FZWKH378T\">(Skoglund, 1944: 159–160)</a></cite>. Moreover, in December 1936, Stockholms-Tidningen proudly proclaimed with a large header in Aftonbladet the aircraft’s faithful service: “the only newspaper in the Nordic countries with its own news aircraft ... Sefyr will guarantee the best film material also in 1937” (Aftonbladet 1936a [det var visst i Aftonbladet, och utan författare – om jag förstått det rätt är det då korrekt att hänvisa till tidningens namn]). In a similar vein, readers were reassured that “wherever something happens, someone from our wide circle of colleagues is always there to relay the news back to us by telephone, car or airplane” (Aftonbladet 1936b). Sefyr was, hence, not merely a tool for speeding up news distribution. It also formed part of a broader self-image of a technologically well-equipped, mobile and tempo-prone news organisation—a flying symbol of journalistic modernity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Within the Journal Digital corpus, searches for the term Sefyr yield 17 occurrences across ten newsreel transcriptions, all dating from the period 1934–36. Sefyr was first mentioned in passing in a 1934 newsreel where the narrator spoke of it as a successor to another SF-airplane. Sefyr then debuted in February 1935, which was reported in another newsreel (SF855B); as the airplane flew over SF’s studios in the outskirts of Stockholm on its maiden flight, carrying the directors of the two owning companies, the narrator proclaimed: “Surely our engine noise interrupts the final scene \\[below\\] but we dare to indulge ourselves on this first day with Sefyr.” Given the celebratory meta-reporting, the airplane appears to have functioned both as a media-infrastructural solution and as well as a media event (in itself)—a technological novelty that SF and Stockholms-Tidningen could foreground to visualise modern, mobile news-gathering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video, display\n",
    "\n",
    "metadata={\n",
    "    \"jdh\": {\n",
    "        \"module\": \"object\",\n",
    "        \"tags\": [\"video-filmarkivet-*\",],\n",
    "        \"object\": {\n",
    "            \"type\":\"video\",\n",
    "            \"source\": [\n",
    "                \"SF’s Weekly Review in December 1935 displayed the Sefyr aircraft, in which the ten finalists of Stockholms-Tidningen’s Saint Lucy’s Day pageant were flown from Bromma airfield in Stockholm.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "display(Video(\"./media/vid4.mp4\", width=500), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "By the end of 1935, Sefyr had been further integrated into promotional activities beyond journalistic duties. Sometimes these were rather curious (to say the least): in one newsreel Sefyr was depicted flying all ten (young women) finalists of Stockholms-Tidningen’s Saint Lucy’s Day pageant, with the narrator playfully referring to the aircraft as “the winged steed Sefyr. He is the one who is going to ride off with that lovely cargo”. While the shivering contestants “brave the biting cold wind,” the sequence devoted considerable attention to displaying the young women before the camera, transforming a straightforward competition announcement into an elaborate publicity stunt. Observing two of the finalists, the narrator remarked that “number nine on the left and number eight on the right have apparently really fallen in love with Sefyr,” before adding that “Sefyr is a popular machine in the best sense of the word.” This sequence makes apparent what the deployment signaled: Sefyr did not serve merely as a piece of journalistic equipment, but also as a promotional asset, and a recognisable attraction in its own right; a celebrity status lending modernity and excitement to events sponsored by two media companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Bibliography\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "citation-manager": {
   "items": {
    "zotero": {
     "22783102/7HB6GAHN": {
      "DOI": "10.1080/03468755.2025.2511644",
      "URL": "https://www.tandfonline.com/doi/full/10.1080/03468755.2025.2511644",
      "author": [
       {
        "family": "Stjernholm",
        "given": "Emil"
       },
       {
        "family": "Eriksson",
        "given": "Maria"
       },
       {
        "family": "Mohammadi Norén",
        "given": "Fredrik"
       }
      ],
      "container-title": "Scandinavian Journal of History",
      "id": "22783102/7HB6GAHN",
      "issue": "4",
      "issued": {
       "date-parts": [
        [
         2025
        ]
       ]
      },
      "page": "458–488",
      "shortTitle": "On the Historical Gaze of Generative AI",
      "system_id": "zotero|22783102/7HB6GAHN",
      "title": "On the Historical Gaze of Generative AI: Visions of Scandinavia in Stable Diffusion",
      "type": "article-journal",
      "volume": "50"
     },
     "22783102/UK5SM8C2": {
      "DOI": "10.25969/MEDIAREP/22316",
      "URL": "https://mediarep.org/entities/article/fcc4a926-1e5d-4434-a55e-cf779477cf67",
      "author": [
       {
        "family": "Offert",
        "given": "Fabian"
       }
      ],
      "container-title": "IMAGE. Zeitschrift für interdisziplinäre Bildwissenschaft",
      "id": "22783102/UK5SM8C2",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         2023
        ]
       ]
      },
      "page": "121–134",
      "system_id": "zotero|22783102/UK5SM8C2",
      "title": "On the Concept of History (in Foundation Models)",
      "type": "article-journal",
      "volume": "19"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
