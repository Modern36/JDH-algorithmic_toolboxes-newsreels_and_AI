{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "title"
    ]
   },
   "source": [
    "# Algorithmic toolboxes for the study of the filmic past -- on newsreels & AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "citation-manager": {
     "citations": {
      "8n3os": [
       {
        "id": "22783102/TT5RIEE2",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import http.server\n",
    "import socketserver\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from itertools import pairwise\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import IFrame, Image, Video, display\n",
    "from journal_digital import Corpus\n",
    "from plotly import colors\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "root = Path(\".\")\n",
    "data = root / \"script\"\n",
    "\n",
    "# Checking if rendered locally. Used to render .gif\n",
    "#  .mp4 will be shown when rendered in binder\n",
    "local = \"m36\" in sys.prefix.split('/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "### Mathias Johansson [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0000-0002-3338-0551) \n",
    "Department of Arts and Cultural Sciences, Lund University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    " ### Robert Aspenskog [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0009-0005-4720-3352) \n",
    "\n",
    "Department of Cultural Sciences, Linnaeus University \n",
    "\n",
    "Department of Arts and Cultural Sciences, Lund University\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "### Johan Malmstedt [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0000-0001-5207-4296) \n",
    "\n",
    "GRIDH, University of Gothenburg \n",
    "\n",
    "metaLAB, Harvard University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "### Emil Stjernholm [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0000-0001-9871-5191) \n",
    "Department of Communication, Lund University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "### Pelle Snickars [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0000-0001-5122-1549) \n",
    "Department of Arts and Cultural Sciences, Lund University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "copyright"
    ]
   },
   "source": [
    "[![cc-by](https://licensebuttons.net/l/by/4.0/88x31.png)](https://creativecommons.org/licenses/by/4.0/) \n",
    "©AUTHORS. Published by De Gruyter in cooperation with the University of\n",
    "Luxembourg Centre for Contemporary and Digital History. This is an Open\n",
    "Access article distributed under the terms of the\n",
    "[Creative Commons Attribution License CC-BY](https://creativecommons.org/licenses/by/4.0/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "keywords"
    ]
   },
   "source": [
    "Media History, Newsreels, Multimodal Analysis, Digital humanities, Film studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "abstract"
    ]
   },
   "source": [
    "Using a computational film studies framework, this article examines a major\n",
    "Swedish newsreel archive—the Journal Digital collection—deploying among others:\n",
    "signal\n",
    "archaeology, named entity recognition, and geocoding. We also apply a broad\n",
    "algorithmic toolbox to convert both intertitles and speech \n",
    "into a transcribed and timestamped corpus of the entire collection. Our basic\n",
    "idea is to construct a number of mid-sized datasets from the Journal Digital\n",
    "collection in different modalities, and proceed with an examination using\n",
    "various approaches. Consequently, our intention is to increase the scholarly\n",
    "capacity of media historical sources, while at the same time critically\n",
    "scrutinizing AI and algorithmic toolboxes for the multimodal study of the past. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "cover"
    ]
   },
   "outputs": [],
   "source": [
    "display(Image(\"./media/img1.png\", width=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-Gunnar-*"
    ]
   },
   "outputs": [],
   "source": [
    "metadata = {\n",
    "  \"jdh\": {\n",
    "    \"module\": \"object\",\n",
    "    \"tags\": [\"figure-Gunnar-*\"],\n",
    "    \"object\": {\n",
    "      \"type\": \"image\",\n",
    "      \"type\": \"image\",\n",
    "      \"source\": [\n",
    "        \"Gunnar Skoglund (1899-1983)—once hailed in the Swedish press \"\n",
    "        'as a \"speaking artist\"—did hundreds of voice-over for the '\n",
    "        \"national SF newsreel. At the time, his voice was arguably \"\n",
    "        \"the most familiar in Sweden. Skoglund was also a skilled \"\n",
    "        \"director, actor and producer of some thirty short films, \"\n",
    "        \"dating from the late 1920s to the 1950s.\"\n",
    "      ],\n",
    "    },\n",
    "  }\n",
    "}\n",
    "display(Image(\"./media/skoglund.png\", width=1000), metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "At the archive of Swedish Television (SVT) and Radio Sweden (SR) there are some\n",
    "thirty volumes of so-called speaker lists used for voice-over in the production\n",
    "of the national SF newsreel–_Svensk Filmindustris Veckorevy_ (_Svensk\n",
    "Filmindustri’s Weekly Review_). During the 1960s, the film company Svensk\n",
    "Filmindustri (SF) sold its non-fiction film and newsreel archive to public\n",
    "service radio and tv. The making of newsreels, however, had begun already in\n",
    "1914, when SF started producing a weekly newsreel in a similar fashion and\n",
    "format as in other countries. These newsreels were nationally distributed in\n",
    "dozens of copies across Sweden; during the silent era they naturally included\n",
    "textual intertitles. From 1932 and onwards sound was added; the preserved\n",
    "voice-over scripts in the SVT and SR vaults hence range from 1932 until 1959.\n",
    "These lists were as detailed as plentiful; today each volume in the archive\n",
    "includes some 150 manuscripts, making the total number of speaker lists to\n",
    "approximately 5,000. In a literal sense they were production manuscripts,\n",
    "almost all contained handwritten edits, and small commentary. All likely they\n",
    "served as the final manuscript for the person who did the voice-over commentary\n",
    "in the film studio, describing the length in seconds when text should be\n",
    "spoken, while also indicating what type of shot the edited newsreel depicted\n",
    "during each particular sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-first-newsreel-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/img2.png\", width=1000),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-first-newsreel-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"The first episode in a SF-newsreel from March 1933 \"\n",
    "          \"depicted the Swedish frigate Vanadis, a naval training \"\n",
    "          \"ship. The commentary was read by \"\n",
    "          \"[Gunnar Skoglund](#figure-Gunnar-*), and as is evident \"\n",
    "          \"from the preserved speaker list, it was meticulous, \"\n",
    "          \"customized in seconds, and almost identical to what was \"\n",
    "          \"heard in the film. In English translation Skoglund \"\n",
    "          'rapidly announced: \"Since the beginning of the 20th '\n",
    "          \"century, the venerable frigate Vanadis has been anchored \"\n",
    "          \"at Skeppsholmen in Stockholm as a lodging and training \"\n",
    "          \"ship. In its disrigged hull, two generations of sailors \"\n",
    "          \"have slept the warrior's heavy and well-deserved sleep in \"\n",
    "          \"hammocks. Lying in a bunk it is called in sailor's \"\n",
    "          \"language, but it is not quite the same as sleeping in a \"\n",
    "          \"bed at home. If nothing else, the alarm clock is a little \"\n",
    "          'louder here\"— trumpet immediately!'\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "For digital media historians, trying to analyse \n",
    "speaker lists from the SF\n",
    "archive as a textual dataset poses challenges. If one, for example, uploads an\n",
    "archival sample of a speaker lists to an AI-powered engine such as Perplexity,\n",
    "with the prompt to OCR a particular section, the result is not particularly\n",
    "impressive. The AI-model does a fair job with all typed Swedish text, but fails\n",
    "with handwritten notes as well as words that have been manually crossed out.\n",
    "Occasionally, Swedish words and letters even turn into Cyrillic script: \"8 sek.\n",
    "Strömmen. Alltsedan mitte av 1890-talet karxxіях кирракX Momenxxxxsixxxkxxmxx\".\n",
    "Trying to work with the SF speaker lists in digitised form is hence scholarly\n",
    "difficult. These lists exhibit many of the common traits that archival\n",
    "documents often encompass; combined typed and handwritten text with corrections\n",
    "often hinders OCR, and structuring of data in correct ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "wt62q": [
       {
        "id": "22783102/UK5SM8C2",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "AI hallucination of a Swedish voice-over manuscript into Russian can of course also be\n",
    "seen as an example of how large language models generate information that is both\n",
    "historically inaccurate—and even fabricated. By now it is well known among\n",
    "historians that LLM's often hallucinate about the past, particularly when more\n",
    "specific questions are posed. While it is true that generative AI does give apt\n",
    "textual answers, such models have repeatedly been critiqued when it comes to\n",
    "producing historical images. Fabian Offert has stressed that models such as\n",
    "CLIP or DALL-E find themselves in \"a triple bind: they suffer from syntactic\n",
    "invariability in the case of _generally_ historical prompts, semantic arbitrarity\n",
    "in the case of _specifically historical_ prompts, and superficial, corporate\n",
    "censorship that affects both\" \n",
    "<cite id=\"wt62q\"><a href=\"#zotero%7C22783102%2FUK5SM8C2\">(Offert 2023)</a></cite>. \n",
    "The latter is, of course, particularly problematic. Nearly all forms of\n",
    "generative AI are circumscribed by commercial constraints; encoded values are\n",
    "neither epistemic nor scholarly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "emq9i": [
       {
        "id": "22783102/5LZCK9F3",
        "source": "zotero"
       }
      ],
      "oan5f": [
       {
        "id": "22783102/H4XMMWYS",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Despite these AI shortcomings regarding the past, in this article we aim to\n",
    "analyse the SF-archive—today usually referred to as the Journal Digital\n",
    "collection—with a diverse set of algorithmic tools. Given our initial\n",
    "discussion, we have however refrained from digitising textual sources (such as\n",
    "the preserved SF speaker lists), and instead focused on the audiovisual\n",
    "material _per se_. Using a computational film studies framework \n",
    "<cite id=\"oan5f\"><a href=\"#zotero%7C22783102%2FH4XMMWYS\">(Oiva et al. 2024)</a></cite>, \n",
    "this article hence examines the Journal Digital collection\n",
    "deploying both signal archaeology, named entity recognition and geocoding. We\n",
    "will also apply a small algorithmic toolbox developed for this article, speficically\n",
    "_<code>stum</code>_ and _<code>SweScribe</code>_. Using these tools we have converted all intertitle-texts\n",
    "and all speech into a time-aligned corpus we call Digital Journal Corpus\n",
    "<cite id=\"emq9i\"><a href=\"#zotero%7C22783102%2F5LZCK9F3\">(Aspenskog, Johansson, and Snickars 2025)</a></cite>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-composition-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/vid1.gif\") if local else Video(\"./media/vid1.mp4\"),\n",
    "  width=1000,\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"tags\": [\n",
    "        \"figure-composition-*\",\n",
    "      ],\n",
    "      \"object\": {\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"It is indeed difficult to visualise a dataset with \"\n",
    "          \"thousands of nonfiction films, still a small _quick and \"\n",
    "          \"dirty_ compilation of 28 silent films (from the 1920s) \"\n",
    "          \"gives an impression of the vivid depiction of Swedish \"\n",
    "          \"society—and modernity—that the SF-archive encompasses.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "iunbf": [
       {
        "id": "22783102/TV37XT5P",
        "source": "zotero"
       }
      ],
      "kh5xp": [
       {
        "id": "22783102/7HB6GAHN",
        "source": "zotero"
       }
      ],
      "ktmd7": [
       {
        "id": "22783102/VL4UHIWF",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Our work is rooted in the research project Modern Times 1936, that explores\n",
    "what software sees, hears and perceives when technologies for pattern\n",
    "recognition are applied to media historical sources. Within this research\n",
    "project we have prior been interested in the the historical gaze of generative\n",
    "AI\n",
    "<cite id=\"kh5xp\"><a href=\"#zotero%7C22783102%2F7HB6GAHN\">(Stjernholm, Eriksson, and Mohammadi Norén 2025)</a></cite>,\n",
    "algorithmic scaling of early cinema on YouTube\n",
    "<cite id=\"iunbf\"><a href=\"#zotero%7C22783102%2FTV37XT5P\">(Stjernholm and Snickars 2024)</a></cite>,\n",
    "and techniques for assessing photorealism in synthetic images\n",
    "<cite id=\"ktmd7\"><a href=\"#zotero%7C22783102%2FVL4UHIWF\">(Eriksson 2024)</a></cite>.\n",
    "As Charlie Chaplin in _Modern Times_ (1936) once struggled to comprehend an\n",
    "industrialised world with giant machines, a common denominator in our research\n",
    "project has been to explore how computational methods can help us understand\n",
    "modernity in new ways. In this article, the idea is hence to construct a number\n",
    "of mid-sized datasets from the Journal Digital collection in different\n",
    "modalities, and proceed with an examination using various computational\n",
    "approaches. Consequently, our intention is to increase the scholarly capacity\n",
    "of media historical sources, while at the same time critically scrutinizing AI\n",
    "and algorithmic toolboxes for the study of the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-SF-facilities-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/img3.png\", width=1000),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-SF-facilities-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"The Swedish SF film company had its production facilities \"\n",
    "          \"with studio and film laboratory located in the so called \"\n",
    "          \"Film-City (Filmstaden) in the suburb of Råsunda \"\n",
    "          \"(north of Stockholm), from 1920 until 1969. As is evident \"\n",
    "          \"from these late 1920s and 1930s photographs, the \"\n",
    "          \"production of newsreels was a practical craft; it \"\n",
    "          \"involved editing, cleaning, and copying film, as well as \"\n",
    "          \"synchronising added sound. The film itself was \"\n",
    "          \"nitrate-based celluloid, known both for its high image \"\n",
    "          \"quality—and dangerous flammability. Illustrations from \"\n",
    "          \"the Swedish Film Institute and the Swedish National \"\n",
    "          \"Museum of Science and Technology. \"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Biography of a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "e3b9w": [
       {
        "id": "22783102/6APYGVMY",
        "source": "zotero"
       }
      ],
      "jkgmd": [
       {
        "id": "22783102/BNUCIK7T",
        "source": "zotero"
       }
      ],
      "zytto": [
       {
        "id": "22783102/BQLCIUEW",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "During the late 1950s, the film manuscript writer Gardar Sahlberg (1908–1983)\n",
    "started to take an increased interest in the film archive at Svensk\n",
    "Filmindustri (SF). At the time, however, the company archive of nitrate films,\n",
    "such as newsreels and short films, was in dire need of restoration (and\n",
    "preservation). Most of the oldest footage was filmed by cinematographers from\n",
    "Swedish Biograph, a company that in 1919 merged into SF\n",
    "<cite id=\"e3b9w\"><a href=\"#zotero%7C22783102%2F6APYGVMY\">(Olsson 2022)</a></cite>.\n",
    "From the beginning of the 1920s until the 1960s, SF had been the leading\n",
    "producer of newsreels, educational cinema, and other types of useful films,\n",
    "distributed in both theatrical and non-theatrical venues \n",
    "<cite id=\"zytto\"><a href=\"#zotero%7C22783102%2FBQLCIUEW\">(Stjernholm and Florin Persson 2019)</a></cite>.\n",
    "As a way to finance a reconstruction and improvement of the\n",
    "SF archive, Sahlberg and SF decided to produce historical compilation films\n",
    "based on the same old film material. In 1961, for example, the documentary _När\n",
    "seklet var ungt_ (_When the century was young_) had its premiere. Critics\n",
    "endorsed the film—but audiences did not. Instead, SF started negotiations with\n",
    "Radio Sweden (SR), which at the time was also responsible for national public\n",
    "service television. During the winter of 1964, it was announced that SR had\n",
    "acquired the whole newsreel archive from SF; one million meters of film dating\n",
    "from 1897 to 1960 was purchased \n",
    "<cite id=\"jkgmd\"><a href=\"#zotero%7C22783102%2FBNUCIK7T\">(Snickars 2024)</a></cite>.\n",
    "The deal was explosive, not only because of the number of preserved nitrate\n",
    "prints; the SF-archive would now find a novel audience in another medium:\n",
    "television."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-seklet-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/img4.png\", width=1000),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-seklet-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"The compilation film, _När seklet var ungt_ \"\n",
    "          \"(_When the century was young_) from 1961, was \"\n",
    "          \"based on the oldest nonfiction films and \"\n",
    "          \"newsreels within the SF-archive. In February \"\n",
    "          \"1962, the director Gardar Sahlberg stated in \"\n",
    "          \"a letter to the national archivist in Sweden, \"\n",
    "          \"that the intention of the film was to \"\n",
    "          'show \"the qualitatively impressive archival film material\" '\n",
    "          \"to a culturally interested audience. \"\n",
    "          \"At SF we had the belief, he admitted, \"\n",
    "          \"that curiosity of this type of older films \"\n",
    "          'would be so great \"that the money received '\n",
    "          \"from the box office would make it possible \"\n",
    "          \"to go ahead, and finance the renewal of \"\n",
    "          'the [SF-]archive\". But unfortunately that '\n",
    "          \"was not the case—despite excellent reviews. \"\n",
    "          \"When the film was shown \"\n",
    "          '\"in a few places in the countryside, there was no audience,\" '\n",
    "          \"he sadly concluded.\"\n",
    "          ''\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "9dljg": [
       {
        "id": "22783102/DSU6R48K",
        "source": "zotero"
       }
      ],
      "fq2ce": [
       {
        "id": "22783102/DVKUX2N4",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As part of the deal, Sahlberg and a few colleagues at SF were hired by SR to\n",
    "work with safeguarding the SF-archive. During the 1960s and 1970s, the archive\n",
    "was preserved, duplicated, catalogued, and subsequently re-used in numerous\n",
    "television programs. In fact, SR made a remarkable cultural-historical effort\n",
    "in saving this film archive. From the old nitrate prints, Sahlberg had three\n",
    "different film materials made: a master copy on 35 mm (for preservation), a\n",
    "duplicate negative on 35 mm to obtain new copies, and a 16 mm display copy for\n",
    "program producers at SR. Sahlberg also took personal responsibility to\n",
    "catalogue the entire SF-archive, manual work he basically did on his own.\n",
    "Notably, all films from SF were catalogued under a specific SF-number; SF2001\n",
    "for example was the oldest film in the archive, dating from 1897. Since SR took\n",
    "excellent care of these films, the company was able to acquire other film\n",
    "collections as well. Some 400 films were purchased from Kinocentralen in the\n",
    "mid 1960s, a company that had produced short and industrial films from the\n",
    "early 1920s. Other similar films were donated to SR from, for example, the\n",
    "Swedish Film Library (Filmhistoriska Samlingarna), the Salvation Army Sweden,\n",
    "the Stockholm City Museum, and the film archive at the Swedish State Railways\n",
    "(SJ)—the latter collection contained almost two hundred nonfiction films\n",
    "produced by SJ between 1920 and 1960. SR also bought the newsreel Nuet (Now)\n",
    "produced by the film company Nordisk Tonefilm during a few years in the mid\n",
    "1950s \n",
    "<cite id=\"9dljg\"><a href=\"#zotero%7C22783102%2FDSU6R48K\">(Asp 2014)</a></cite>.\n",
    "Finally, in 1969 SR also decided to acquire all short films produced by SF, a\n",
    "deal that made the entire collection at SR amount to more than five thousand\n",
    "films. As a consequence, the initial SF-archive came to contain a range of\n",
    "different types of documentary film, with different provenances. It should be\n",
    "noted, however, that the rationale behind all these film acquisitions was the\n",
    "potential usage of old films in new tv-programs. Still, SR was also interested\n",
    "in developing a sales organisation for tv-programs, with film rights as a\n",
    "prospective revenue stream. An interesting aspect of the initial purchase of\n",
    "the SF-archive hence concerned what type of rights (to old footage) that SF\n",
    "actually sold to SR, since the archive also contained films of foreign origin\n",
    "(such as Pathé and Gaumont). In a memo from 1964, the head of the film archive\n",
    "at SR therefore urged a certain degree of caution when it came to the reuse of\n",
    "foreign films\n",
    "<cite id=\"fq2ce\"><a href=\"#zotero%7C22783102%2FDVKUX2N4\">(Norrlander 1964)</a></cite>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-composition2-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/vid2.gif\") if local else Video(\"./media/vid2.mp4\"),\n",
    "  width=1000,\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"tags\": [\n",
    "        \"figure-composition2-*\",\n",
    "      ],\n",
    "      \"object\": {\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"The film collection at SR grew steadily during the \"\n",
    "          \"1960s—and it was indeed heterogenous. The collection \"\n",
    "          \"included early cinema, silent newsreels from Swedish \"\n",
    "          \"Biograph, Svensk Filmindustris Veckorevy, films from the \"\n",
    "          \"Swedish State Railways (SJ) and their film archive, short \"\n",
    "          \"films from Kinocentralen, and the 1950s newsreel Nuet, \"\n",
    "          \"produced by Nordisk Tonefilm.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "17vqq": [
       {
        "id": "22783102/24HEASLG",
        "source": "zotero"
       }
      ],
      "1oy6f": [
       {
        "id": "22783102/DW4S37Y5",
        "source": "zotero"
       }
      ],
      "8to8g": [
       {
        "id": "22783102/2RDITF4M",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "From the mid 1960s, Swedish public service television appropriated the films\n",
    "that Sahlberg and his colleagues had preserved, and catalogued. Footage from\n",
    "the SF-archive and the other film collections at SR was reused in thousands of\n",
    "tv programs \n",
    "<cite id=\"17vqq\"><a href=\"#zotero%7C22783102%2F24HEASLG\">(Eriksson, Skotare, and Snickars 2024)</a></cite>.\n",
    "In many ways these moving images shaped the ways that Swedes perceived their\n",
    "past \n",
    "<cite id=\"8to8g\"><a href=\"#zotero%7C22783102%2F2RDITF4M\">(Eriksson, Skotare, and Snickars 2022)</a></cite>.\n",
    "In the 1980s, the first steps towards digitising the catalogue of films and\n",
    "metadata were taken. Interestingly, the motivation for both microfilming the\n",
    "catalogue, and developing a rudimentary database of information about the\n",
    "content of old newsreels, were financial. When the new head of the TV archive\n",
    "(as it was now called), Birgitta Lagnell, was interviewed in the mid 1980s, her\n",
    "major quest was how to monetise the film archive: \"She will make the gold mine\n",
    "of television profitable\", headlines stated \n",
    "<cite id=\"1oy6f\"><a href=\"#zotero%7C22783102%2FDW4S37Y5\">(Bergman 1986)</a></cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "asqbb": [
       {
        "id": "22783102/928EZRZ4",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Ten years later, an increased academic interest in the SF-archive resulted in\n",
    "an externally funded research project with the aim to make the old film\n",
    "collections more accessible. As a result, the department of cinema studies at\n",
    "Stockholm University started a collaboration with the TV archive, granting\n",
    "access to scholars and PhD students interested in the SF-archive. One of us\n",
    "(Snickars) started his PhD training in cinema studies in 1995 by examining 16\n",
    "mm prints from the SF-archive at a Steenbeck editing desk located in the vaults\n",
    "of the TV archive. In parallel, and on the agenda at the time, Swedish public\n",
    "service television began developing digital technology for terrestrial\n",
    "television. A governmental report, SOU 1996:25—_From mass media to multi media:\n",
    "how to digitise Swedish television_—laid the groundwork, and described in detail\n",
    "the technical requirements. Since the digitisation of the SF-archive was\n",
    "foremost media archival work, the TV archive contacted the publicly funded\n",
    "Swedish National Archive of Recorded Sound and Moving Images (ALB) with a\n",
    "request to scan the SF-archive to video—with the prospective to later transfer\n",
    "content to digital tape \n",
    "<cite id=\"asqbb\"><a href=\"#zotero%7C22783102%2F928EZRZ4\">(ALB 1996)</a></cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "ejjgj": [
       {
        "id": "22783102/R86YMEXD",
        "source": "zotero"
       }
      ],
      "s75ig": [
       {
        "id": "22783102/M63TBZ7V",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "During the summer of 1997, ALB started scanning; the deal was to transfer five\n",
    "hundred nonfiction films every year \n",
    "<cite id=\"ejjgj\"><a href=\"#zotero%7C22783102%2FR86YMEXD\">(ALB 1997)</a></cite>.\n",
    "Additional external funding was secured, and ALB also decided to transfer all\n",
    "catalogue information to machine readable formats. ALB had been inaugurated in\n",
    "the late 1970s, due to an extension in the Swedish deposit law that came to\n",
    "include audiovisual material as well. ALB was in many ways a video archive in\n",
    "the service of academic research; public service broadcasts were stored on\n",
    "magnetic tape. Yet, in the mid 1990s it became all too apparent that video and\n",
    "tape recordings would not sustain content for longer periods of time. In\n",
    "digital format, however, it was likely that the same content could be\n",
    "preserved—for ALB, the digitisation of the SF-archive hence developed into a\n",
    "case study of how to proceed with such a major technical, and media archival\n",
    "transition. In a description (for an application) from 1998, The digital\n",
    "newsreel archive, it was stated that ALB was now planning \"to digitise all\n",
    "scanned video tapes \\[from the SF-archive\\]. The digitised recordings will then\n",
    "be stored \\[on\\] discs in an automated archive\". Converted catalog information\n",
    "would also be linked to each film. \"This will allow the user to perform catalog\n",
    "searches, and also view the requested film directly online on a computer, which\n",
    "would effectively streamline research usage\" \n",
    "<cite id=\"s75ig\"><a href=\"#zotero%7C22783102%2FM63TBZ7V\">(ALB 1998)</a></cite>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-ALB-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/img5.png\", width=1000),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-ALB-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"In 2003, the Swedish National Archive of Recorded Sound and \"\n",
    "          \"Moving Images (formerly ALB) launched Journal Digital—a \"\n",
    "          \"collection with more than 5,000 digitised films and linked \"\n",
    "          \"metadata, accessible through a user-friendly interface. \"\n",
    "          \"At the same time, one percent of the films from Journal \"\n",
    "          \"Digital were also made available online on the web, a site \"\n",
    "          \"that rapidly became popular among (foremost elderly) Swedes. \"\n",
    "          'Today, twenty years later, at the portal [filmarkivet.se](https://filmarkivet.se){:target=\"_blank\"}—a '\n",
    "          \"joint venture between the National Library of Sweden and the \"\n",
    "          \"Swedish Film Institute also—some three hundred SF-newsreels \"\n",
    "          \"are openly available for anyone to watch.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "op55s": [
       {
        "id": "22783102/BXDUCBBT",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The digitisation work proceeded in the coming years—albeit slowly. At a board\n",
    "meeting in late 1999, the head of ALB, Sven Allerstrand, had to confess that\n",
    "\"unfortunately, as resources are lacking for an R&D function within ALB,\n",
    "development work \\[with the SF-archive\\] is progressing very slowly. Resources\n",
    "must be taken from ordinary operations, which has a negative impact on the\n",
    "overall result.\" However, Allerstrand stated, at our media archive we are still\n",
    "\"convinced that the only possible solution to ensure the long-term preservation\n",
    "of ALB’s material is automated processing in a digital mass storage system\"\n",
    "<cite id=\"op55s\"><a href=\"#zotero%7C22783102%2FBXDUCBBT\">(ALB 1999)</a></cite>. \n",
    "A year later, ALB finally secured funding from the government, and the transfer\n",
    "of the SF-archive into digital format proceeded with a more rapid pace. In\n",
    "2002, all newsreels and short films had finally been digitised. However, since\n",
    "the film collection included not only films from SF—but also films from\n",
    "Kinocentralen, the Swedish State Railways, and newsreels from Nordisk\n",
    "Tonefilm—ALB decided to change the name of the digitised collection to Journal\n",
    "Digital. A new search interface for the collection, publicly accessible on\n",
    "computers at ALB, was developed, as well as a web site with one percent of the\n",
    "collection online (through permission from SVT). In all, Journal Digital gave\n",
    "access to 4,348 newsreels and short films from Svensk Filmindustri, 421\n",
    "nonfiction films from Kinocentralen, 267 Nuet-newsreels from Nordisk Tonefilm,\n",
    "and 170 SJ-documentary films from the Swedish State Railways—in all 5,206 films\n",
    "dating from 1896 to the mid 1960s. Consequently, that is the amount of films\n",
    "that our dataset—the Journal Digital collection—is based upon. It should be\n",
    "stressed, however, that in the following we will often write about the analyses\n",
    "of newsreels, since they make up the major part of our dataset. Yet, we are\n",
    "aware that our examined film material also contains other genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-box-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/img6.png\"),\n",
    "  width=1000,\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-box-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"Via the content management system Box, Swedish \"\n",
    "          \"researchers can today remotely access the audiovisual \"\n",
    "          \"collections at the National Library of Sweden. While \"\n",
    "          \"sound recordings are fine and acceptable, this is hardly \"\n",
    "          \"the case for film or television content—which is \"\n",
    "          \"displayed in low resolution formats, 704 x 576 pixels, in \"\n",
    "          \"a small square on the screen measuring nine times seven \"\n",
    "          \"centimetres. \"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Formats tend to stick, and remain the same: when the Swedish National Archive\n",
    "of Recorded Sound and Moving Images (ALB)—in the year 2000 digitised the\n",
    "SF-archive, all films were converted into MPEG-2-format, a digital video and\n",
    "audio compression standard developed during the 1990s by the Moving Picture\n",
    "Experts Group (MPEG). The MPEG-2-versions were preserved on digital tape at\n",
    "ALB. From these preservation files, another video converter compressed films\n",
    "into a browse copy in MPEG-1-format, a lossy compression format with files\n",
    "stored on a hard drive for instant access via an interface. 25 years ago,\n",
    "MPEG-1 was a standard resolution for compressed video online. Yet, this is\n",
    "obviously not the case any more. If film archivist Gardar Sahlberg during the\n",
    "1960s made sure to preserve the SF-archive on both a master copy on 35 mm, a\n",
    "duplicate negative on 35 mm, and a 16 mm display copy, this is far from how\n",
    "researchers today are confronted with the SF-archive in the digital domain.\n",
    "Decisions taken back then still linger; researchers working with audiovisual\n",
    "materials today must still be satisfied with late 1990s low resolution copies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-filmarkivet-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/vid3.gif\") if local else Video(\"./media/vid3.mp4\"),\n",
    "  width=1000,\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\n",
    "          \"figure-filmarkivet-*\",\n",
    "        ],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"Proper filmic heritage is naturally dependent on digital \"\n",
    "          \"quality; both sequences display the Stockholm exhibition \"\n",
    "          \"in  1897, shot by a Lumière cinematographer (SF2001). \"\n",
    "          \"The version to the right is low resolution with pixels \"\n",
    "          \"clearly visible if the frame is enlarged—the speed is \"\n",
    "          \"also not adjusted. Sadly, this is the version that \"\n",
    "          \"academic researchers are confronted with in the Box \"\n",
    "          \"interface at the National Library of Sweden. In the \"\n",
    "          \"version to the left—visible in the public interface \"\n",
    "          '[filmarkivet.se](filmarkivet.se){:target=\"_blank\"}—'\n",
    "          \"speed is adjusted, and the sequence is displayed in \"\n",
    "          \"MPEG-2, a still acceptable digital resolution.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "8sz1i": [
       {
        "id": "22783102/583554VC",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "### Reanimating the Dataset [del]\n",
    "\n",
    "Decisions made two decades ago still haunt us today. Consequently, in this article\n",
    "we have been working with low resolution (MPEG-1) copies from Journal Digital.\n",
    "As stated, the National Library of Sweden and the Swedish Film Institute also\n",
    "gives online access to some three hundred SF-newsreels in high resolution,\n",
    "MPEG-2-versions, at the portal\n",
    "[filmarkivet.se](https://filmarkivet.se){:target=\"_blank\"}—thus,\n",
    "occasionally we will\n",
    "illustrate our arguments with these film versions as well. Then again, there is\n",
    "a sharp contrast between the highly curated selection of restored\n",
    "high-resolution newsreels available through\n",
    "[filmarkivet.se](https://filmarkivet.se){:target=\"_blank\"}\n",
    "and the low-quality digitisation of a vast majority of the SF newsreel archive.\n",
    "In addition,\n",
    "[filmarkivet.se](https://filmarkivet.se){:target=\"_blank\"}\n",
    "provides patchy and limited metadata, little contextualization using film\n",
    "historical sources, and no possibility to analyze the content at hand as data,\n",
    "effectively limiting the scholarly utility of the site \n",
    "<cite id=\"8sz1i\"><a href=\"#zotero%7C22783102%2F583554VC\">(Snickars 2015)</a></cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "It is worth noting that nearly every video file in the Journal Digital collection\n",
    "has its own entry in the [Swedish Media Database (SMDB)](https://smdb.kb.se/){:target=\"_blank\"}.\n",
    "Metadata include title, year, description, people, identifiers,\n",
    "and so called SAB subject codes (a library classification system). Such SAB\n",
    "codes were once assigned to newsreels, representing geographic as well as\n",
    "topical keywords. Topical SAB spans broader categories such as Military, to\n",
    "more specific ones like Christmas customs. However, the metadata quality varies: \n",
    "some newsreels being carefully annotated scene for \n",
    "scene with carefully applied SAB codess, while others only have the absolute \n",
    "minimum of an title, identifier, year of production and wether the file has audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "In our efforts to pry open the Journal Digital collection we developed a small set of\n",
    "processing pipelines. Most of these pipelines take several hours or a few days\n",
    "to make their way throught the entire collection. Some of which require access to\n",
    "a GPU. All of which make it unfeasible to actually run any of these pipelines\n",
    "here in the notebook, even to process an example. However, we have copied in\n",
    "the _key_ functions and describe them in the hermeneutic layer to showcase and explain how the\n",
    "different pipelines have processed the collection—producing new meta-datasets\n",
    "that we base our investigations on. The full pipelines, and the datasets they\n",
    "produced, are made available elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "In the [first](#anchor-sec-signal-archeology) section we apply two separate\n",
    "object detection pipelines on [audio](#anchor-pipe-ast) and\n",
    "[frames](#pipe-visual) respectively. For the [second](#anchor-sec-inter) and\n",
    "[third](#sec-geo) sections we rely on _Journal Digital Corpus_ to analyse\n",
    "transcriptions of intertitles and speech respectively. We show how we overcame\n",
    "the problem of [flash intertitles](#anchor-pipe-stum) and\n",
    "[hallucinations](#anchor-pipe-swescribe) to create a time-aligned corpus of\n",
    "transcribed intertitles and speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "anchor-sec-signal-archeology"
    ]
   },
   "source": [
    "## Audiovidusal Signal Archeology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "3uifr": [
       {
        "id": "22783102/WHSQVQAB",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Annotating content within 5,205 nonfiction films is already a demanding\n",
    "task, but doing so with precision across both the sonic and visual domains\n",
    "requires even greater care and effort. Previous research has emphasized the\n",
    "time-consuming nature of audiovisual annotation\n",
    "<cite id=\"3uifr\"><a href=\"#zotero%7C22783102%2FWHSQVQAB\">(Guyot et al. 2019)</a></cite>.\n",
    "Nevertheless, to fully understand how these films are structured, both audio\n",
    "and visuals must be taken into consideration. Not only do image and sound play\n",
    "crucial roles within newsreels—naturally, after the introduction of sound in\n",
    "the early 1930s—but the genre also provides a valuable window into the\n",
    "historical formation of specific ways of juxtaposing these modalities within\n",
    "the Journal Digital collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "ndpmw": [
       {
        "id": "22783102/K4N8PIGZ",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Importantly, approaching this film collection through an archaeology of the\n",
    "audiovisual signal invites a shift in perspective: from meaning to trace, from\n",
    "representation to inscription\n",
    "<cite id=\"ndpmw\"><a href=\"#zotero%7C22783102%2FK4N8PIGZ\">(Malmstedt 2025)</a></cite>.\n",
    "Each film can be understood as a layered field of signals that bears the marks\n",
    "of its technological circumstances, institutional routines, and cultural\n",
    "habits. Sound and image are, then, less regarded as vehicles of meaning, but\n",
    "rather historical artefacts that carry within their textures and fluctuations\n",
    "the sedimented practices of production and aesthetics. Accordingly, the initial\n",
    "experiments conducted on this dataset account for both sound and image,\n",
    "complementing human interpretation with automated annotations. This approach\n",
    "enables the generation of first-level segmentations for each modality, allowing\n",
    "for both separate and integrated navigation within large, untagged archival\n",
    "collections. It also establishes a foundation for comparative analysis of the\n",
    "relationship between the visual and auditory modalities, to be explored in the\n",
    "following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Multimodal analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "8zr5m": [
       {
        "id": "22783102/I8MEJEFP",
        "source": "zotero"
       }
      ],
      "ku8u3": [
       {
        "id": "22783102/BY6TRM9R",
        "source": "zotero"
       }
      ],
      "ywzk9": [
       {
        "id": "22783102/EVKA7BG8",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To analyse this aspect of audiovisual communication, we employ computational\n",
    "methods that can register both the visual and sonic dimensions of newsreels.\n",
    "Specifically, we use transformer-based models such as Moondream, a\n",
    "vision-language model for object detection and vision tasks \n",
    "<cite id=\"ywzk9\"><a href=\"#zotero%7C22783102%2FEVKA7BG8\">(Korrapati 2025)</a></cite>,\n",
    "and an AST (Audio Spectrogram Transformer) \n",
    "<cite id=\"ku8u3\"><a href=\"#zotero%7C22783102%2FBY6TRM9R\">(Gong, Chung, and Glass 2021)</a></cite>.\n",
    "Each model\n",
    "processes its respective sensory channels independently. Yet their outputs\n",
    "can be aligned to enable cross-modal comparison. \n",
    "Both models were used in their publicly available, pre-trained forms,\n",
    "which have demonstrated high general accuracy across a wide range of\n",
    "audiovisual tasks. Moondream, a transformer-based vision-language model, is\n",
    "designed for lightweight image understanding and captioning, enabling efficient\n",
    "object detection and scene parsing even on modest computational resources.\n",
    "However, we made several adjustments to tailor their performance to the\n",
    "specific requirements of historical newsreel material. For the visual analysis,\n",
    "we limited the number of detected objects in each frame to emphasize overall\n",
    "compositional and semantic features rather than exhaustive enumeration. Without\n",
    "this constraint, the model tended to generate redundant detections, for\n",
    "instance, identifying every instance of a person separately, which led to\n",
    "overly cluttered outputs. In the audio domain, we refined the results by\n",
    "filtering out misleading detections, such as static noise being misclassified\n",
    "as environmental sounds like rain. These calibrations allowed us to focus on\n",
    "the broader audiovisual texture of the material rather than on granular or\n",
    "noisy details.\n",
    "The full details of all the steps, outputs and code for these pipelines see \n",
    "<cite id=\"8zr5m\"><a href=\"#zotero%7C22783102%2FI8MEJEFP\">(Johansson and Malmstedt 2026)</a></cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "### Filtering for Useful Audio [ del ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Many of the 5,205 film files of Journal Digital do not contain useful \n",
    "audio for audio-processing. That is, many of them contain no audio-track at \n",
    "all; others have an audio track that is either completely silent, \n",
    "is white noise or has loud noises at seeminlgy random places. \n",
    "To avoid processing and having noise entering our dataset, \n",
    "we implemented the following filtering steps: \n",
    "(1.) each film file has an audio track; \n",
    "(2.), the audio track’s length in seconds is longer than the threshold value \n",
    "of two seconds; \n",
    "(3.) a ratio of silence to sound is lower than 0.98. If any of these three \n",
    "steps fail, the film does not contain useful audio. \n",
    "Next we apply two different approaches (4.) and (5.) to check the loudness of \n",
    "the present audio track. If either test passes we have enough audio to pass on \n",
    "to the audio processing pipeline. Finally, we compare the list of files with \n",
    "useful audio to the SMDB-metadata for each file and create a whitelist of the \n",
    "intersection of both sets. This whitelist includes 2,319 files out of the full \n",
    "5,205."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "# ./src/audiovisual/utils/audio_calculator.py\n",
    "\n",
    "\n",
    "def has_meaningful_audio(\n",
    "  video_path: Path,\n",
    "  min_duration_sec: float = 2.0,\n",
    "  min_integrated_lufs: float = -45.0,\n",
    "  min_lra_lu: float = 1.0,\n",
    "  min_mean_dbfs: float = -40.0,\n",
    "  max_peak_dbfs: float = -6.0,\n",
    "  max_silence_ratio: float = 0.98,\n",
    ") -> bool:\n",
    "  \"\"\"Determine if video file has meaningful audio content.\n",
    "\n",
    "  Checks for:\n",
    "  - Presence of audio stream\n",
    "  - Minimum duration\n",
    "  - Silence ratio below threshold\n",
    "  - EBU R128 loudness metrics OR volume detection metrics\n",
    "\n",
    "  Args:\n",
    "      video_path: Path to video file.\n",
    "      min_duration_sec: Minimum audio duration (default 2.0s).\n",
    "      min_integrated_lufs: Minimum integrated loudness (default -45.0 LUFS).\n",
    "      min_lra_lu: Minimum loudness range (default 1.0 LU).\n",
    "      min_mean_dbfs: Minimum mean volume (default -40.0 dB).\n",
    "      max_peak_dbfs: Maximum peak volume (default -6.0 dB).\n",
    "      max_silence_ratio: Maximum silence ratio (default 0.98).\n",
    "\n",
    "  Returns:\n",
    "      True if video has meaningful audio, False otherwise.\n",
    "\n",
    "  Example:\n",
    "      >>> has_meaningful_audio(Path(\"video.mp4\"))\n",
    "      True\n",
    "  \"\"\"\n",
    "  # 1. Check for audio stream\n",
    "  if not _any_audio_stream(video_path):\n",
    "    return False\n",
    "  # 2. Make sure audio is long enough\n",
    "  dur = _probe_duration_seconds(video_path)\n",
    "  if dur is None or dur < min_duration_sec:\n",
    "    return False\n",
    "  # 3. Calculate silence ratio\n",
    "  sil = _silence_ratio(video_path)\n",
    "  if sil is not None and sil >= max_silence_ratio:\n",
    "    return False\n",
    "  # 4. Make sure audio is loud enough\n",
    "  ebu = _ebur128_stats(video_path)\n",
    "  if ebu:\n",
    "    I_LUFS, LRA_LU = ebu\n",
    "    if I_LUFS > min_integrated_lufs and LRA_LU >= min_lra_lu:\n",
    "      return True\n",
    "  # 5. Make sure audio is loud enough\n",
    "  vd = _volumedetect_stats(video_path)\n",
    "  if vd:\n",
    "    mean_db, max_db = vd\n",
    "    if mean_db > min_mean_dbfs or max_db > max_peak_dbfs:\n",
    "      return True\n",
    "  return False\n",
    "\n",
    "\n",
    "# 1. Check for audio stream\n",
    "def _any_audio_stream(video_path: Path) -> bool:\n",
    "  \"\"\"Check if video has any audio stream.\"\"\"\n",
    "  return _any_audio_stream_json(\n",
    "    video_path\n",
    "  ) or _any_audio_stream_ffmpeg_fallback(video_path)\n",
    "\n",
    "\n",
    "# 2. Make sure audio is long enough\n",
    "def _probe_duration_seconds(video_path: Path):\n",
    "  \"\"\"Get audio/video duration in seconds.\"\"\"\n",
    "  for s in _ffprobe_streams(video_path):\n",
    "    if s.get(\"codec_type\") == \"audio\" and s.get(\"duration\"):\n",
    "      try:\n",
    "        d = float(s[\"duration\"])\n",
    "        if math.isfinite(d) and d > 0:\n",
    "          return d\n",
    "      except (ValueError, TypeError):\n",
    "        pass\n",
    "  rc, out, err = _run(\n",
    "    [\n",
    "      \"ffprobe\",\n",
    "      \"-v\",\n",
    "      \"error\",\n",
    "      \"-show_entries\",\n",
    "      \"format=duration\",\n",
    "      \"-of\",\n",
    "      \"default=nw=1:nk=1\",\n",
    "      str(video_path),\n",
    "    ]\n",
    "  )\n",
    "  try:\n",
    "    d = float(out.strip())\n",
    "    return d if math.isfinite(d) and d > 0 else None\n",
    "  except (ValueError, TypeError):\n",
    "    return None\n",
    "\n",
    "\n",
    "# 3. Calculate silence ratio\n",
    "def _silence_ratio(\n",
    "  video_path: Path,\n",
    "  noise_floor_db: float = -40.0,\n",
    "  min_silence_d: float = 0.3,\n",
    "):\n",
    "  \"\"\"Calculate ratio of silence in audio track.\n",
    "\n",
    "  Args:\n",
    "      video_path: Path to video file.\n",
    "      noise_floor_db: Noise floor threshold in dB.\n",
    "      min_silence_d: Minimum silence duration to count (seconds).\n",
    "\n",
    "  Returns:\n",
    "      Ratio of silence (0.0 to 1.0) or None if duration unavailable.\n",
    "  \"\"\"\n",
    "  dur = _probe_duration_seconds(video_path)\n",
    "  if not dur or dur <= 0:\n",
    "    return None\n",
    "  af = f\"silencedetect=noise={noise_floor_db}dB:d={min_silence_d}\"\n",
    "  rc, out, err = _run(\n",
    "    [\n",
    "      \"ffmpeg\",\n",
    "      \"-hide_banner\",\n",
    "      \"-nostats\",\n",
    "      \"-i\",\n",
    "      str(video_path),\n",
    "      \"-af\",\n",
    "      af,\n",
    "      \"-f\",\n",
    "      \"null\",\n",
    "      \"-\",\n",
    "    ]\n",
    "  )\n",
    "  total_sil = 0.0\n",
    "  last_start = None\n",
    "  for line in err.splitlines():\n",
    "    if \"silence_start:\" in line:\n",
    "      m = re.search(r\"silence_start:\\s*([0-9.]+)\", line)\n",
    "      if m:\n",
    "        last_start = float(m.group(1))\n",
    "    elif \"silence_end:\" in line:\n",
    "      md = re.search(r\"silence_duration:\\s*([0-9.]+)\", line)\n",
    "      if md:\n",
    "        total_sil += float(md.group(1))\n",
    "      else:\n",
    "        me = re.search(r\"silence_end:\\s*([0-9.]+)\", line)\n",
    "        if me and last_start is not None:\n",
    "          total_sil += max(0.0, float(me.group(1)) - last_start)\n",
    "      last_start = None\n",
    "  if last_start is not None:\n",
    "    total_sil += max(0.0, dur - last_start)\n",
    "  return min(1.0, max(0.0, total_sil / dur))\n",
    "\n",
    "\n",
    "# 4. Make sure audio is loud enough\n",
    "def _ebur128_stats(video_path: Path):\n",
    "  \"\"\"Get EBU R128 loudness stats (integrated loudness, loudness range).\n",
    "\n",
    "  Returns:\n",
    "      Tuple of (I_LUFS, LRA_LU) or None if stats unavailable.\n",
    "  \"\"\"\n",
    "  rc, out, err = _run(\n",
    "    [\n",
    "      \"ffmpeg\",\n",
    "      \"-hide_banner\",\n",
    "      \"-nostats\",\n",
    "      \"-i\",\n",
    "      str(video_path),\n",
    "      \"-vn\",\n",
    "      \"-sn\",\n",
    "      \"-filter_complex\",\n",
    "      \"ebur128=peak=true\",\n",
    "      \"-f\",\n",
    "      \"null\",\n",
    "      \"-\",\n",
    "    ]\n",
    "  )\n",
    "  text = err\n",
    "  I_LUFS = None\n",
    "  LRA_LU = None\n",
    "  for pat in [\n",
    "    r\"\\bI:\\s*([-+]?\\d+(?:[.,]\\d+)?)\\s*LUFS\",\n",
    "    r\"\\bIntegrated loudness:\\s*([-+]?\\d+(?:[.,]\\d+)?)\\s*LUFS\",\n",
    "  ]:\n",
    "    m = re.search(pat, text, re.I)\n",
    "    if m:\n",
    "      I_LUFS = _parse_float_any(m.group(1))\n",
    "      break\n",
    "  for pat in [\n",
    "    r\"\\bLRA:\\s*([-+]?\\d+(?:[.,]\\d+)?)\\s*LU\\b\",\n",
    "    r\"\\bLoudness range:\\s*([-+]?\\d+(?:[.,]\\d+)?)\\s*LU\\b\",\n",
    "  ]:\n",
    "    m = re.search(pat, text, re.I)\n",
    "    if m:\n",
    "      LRA_LU = _parse_float_any(m.group(1))\n",
    "      break\n",
    "  if I_LUFS is not None and LRA_LU is not None:\n",
    "    return I_LUFS, LRA_LU\n",
    "  return None\n",
    "\n",
    "\n",
    "# 5. Make sure audio is loud enough\n",
    "def _volumedetect_stats(video_path: Path):\n",
    "  \"\"\"Get volume detection stats (mean_volume, max_volume) in dB.\n",
    "\n",
    "  Returns:\n",
    "      Tuple of (mean_dB, max_dB) or None if stats unavailable.\n",
    "  \"\"\"\n",
    "  rc, out, err = _run(\n",
    "    [\n",
    "      \"ffmpeg\",\n",
    "      \"-hide_banner\",\n",
    "      \"-nostats\",\n",
    "      \"-i\",\n",
    "      str(video_path),\n",
    "      \"-vn\",\n",
    "      \"-sn\",\n",
    "      \"-af\",\n",
    "      \"volumedetect\",\n",
    "      \"-f\",\n",
    "      \"null\",\n",
    "      \"-\",\n",
    "    ]\n",
    "  )\n",
    "  m_mean = re.search(\n",
    "    r\"mean_volume:\\s*([-+]?\\d+(?:[.,]\\d+)?)\\s*dB\", err\n",
    "  )\n",
    "  m_max = re.search(r\"max_volume:\\s*([-+]?\\d+(?:[.,]\\d+)?)\\s*dB\", err)\n",
    "  if m_mean and m_max:\n",
    "    return _parse_float_any(m_mean.group(1)), _parse_float_any(\n",
    "      m_max.group(1)\n",
    "    )\n",
    "  return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Traces of sonic experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To understand how content is distributed, the first thing to consider is the\n",
    "nature of the dataset itself. The SF-archive—and the subsequent Journal Digital\n",
    "collection—varies widely in scope and condition; the latter have during decades\n",
    "been conditioned by differences in film production, and later by dissimilar and\n",
    "uneven processes of preservation. Some nitrate prints have hence only survived\n",
    "in partial form, and (after the introduction of sound) many films still lack a\n",
    "complete soundtrack, usually because the audio has deteriorated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-audio_bars-*"
    ]
   },
   "outputs": [],
   "source": [
    "audio_files_year = pd.read_csv(\n",
    "  data / \"year_audio_files.tsv\", sep=\"\\t\"\n",
    ").set_index(\"Year\")\n",
    "\n",
    "\n",
    "def get_audio_bars():\n",
    "  fig = px.bar(\n",
    "    audio_files_year,\n",
    "    y=\"audio\",\n",
    "    title=\"Files with Useful Sound per Year (≥1930)\",\n",
    "  )\n",
    "\n",
    "  fig.update_layout(\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"# of files with useful audio\",\n",
    "    xaxis=dict(tickmode=\"linear\", tick0=1930, dtick=10),\n",
    "    yaxis=dict(tickmode=\"linear\", tick0=0, dtick=10),\n",
    "  )\n",
    "  if not local:\n",
    "    return fig\n",
    "\n",
    "  file = root / \"media\" / \"audio-bars.png\"\n",
    "\n",
    "  fig.write_image(file)\n",
    "\n",
    "  return Image(file)\n",
    "\n",
    "  return fig\n",
    "\n",
    "\n",
    "display(\n",
    "  get_audio_bars(),\n",
    "  width=1000,\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-audio_bars-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"The overall distribution of audiovisual films \"\n",
    "          \"in the Journal Digital collection—with the digital emphasis \"\n",
    "          \"on files with sound As is evident, the distribution of files \"\n",
    "          \"is uneven, with a gradual increase during the 1930s.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "1gwtf": [
       {
        "id": "22783102/TEPVQNE3",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Tracing and tracking sound, the pattern above is expected: early in the 1930s,\n",
    "sound production of newsreels was limited by technical constraints and\n",
    "substantial costs. However, the data also offers a revealing media-historical\n",
    "insight into the gradual incorporation of sound into the newsreel format.\n",
    "Whereas the arrival of sound in cinema is often portrayed as a sudden and\n",
    "decisive transformation, usually pinpointing the talkie musical drama, _The Jazz\n",
    "Singer_ (1927)—featuring six songs performed by Al Jolson—evidence from the\n",
    "Journal Digital collection indicate a more gradual and slower media migration,\n",
    "that is a slightly uneven process of sound integration\n",
    "<cite id=\"1gwtf\"><a href=\"#zotero%7C22783102%2FTEPVQNE3\">(Beck 2011)</a></cite>.\n",
    "Furthermore, the second half of the figure above shows a gradual decline. At\n",
    "first glance, this might seem surprising, but it is more likely a reflection of\n",
    "the structure of the film collection than of an actual historical trend. If one\n",
    "instead plots the proportion of films containing sound for each year, a more\n",
    "consistent pattern of integration appears, evident in the figure below. It also\n",
    "provides a clearer foundation for our following analysis, where we examine how\n",
    "image and sound interact across different phases of newsreel development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-audio_shares-*"
    ]
   },
   "outputs": [],
   "source": [
    "audio_files_year[\"share\"] = (\n",
    "  audio_files_year[\"audio\"] / audio_files_year[\"files\"]\n",
    ")\n",
    "\n",
    "\n",
    "def get_audio_line():\n",
    "  fig = px.line(\n",
    "    audio_files_year,\n",
    "    y=\"share\",\n",
    "    title=\"Share of Files with Useful Sound per Year (≥1930)\",\n",
    "  )\n",
    "\n",
    "  fig.update_layout(\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"# of files with useful audio\",\n",
    "    xaxis=dict(tickmode=\"linear\", tick0=1930, dtick=10),\n",
    "    yaxis=dict(tickmode=\"linear\", tick0=0, dtick=10),\n",
    "  )\n",
    "\n",
    "  if not local:\n",
    "    return fig\n",
    "\n",
    "  file = root / \"media\" / \"audio_shares.png\"\n",
    "\n",
    "  fig.write_image(file)\n",
    "\n",
    "  return Image(file)\n",
    "\n",
    "  return fig\n",
    "\n",
    "\n",
    "display(\n",
    "  get_audio_line(),\n",
    "  width=1000,\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-audio_shares-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"The share of files in the Journal Digital collection \"\n",
    "          \"with useful sound from 1930 until 1966.\"\n",
    "          \n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "e7cth": [
       {
        "id": "22783102/UVAHYVZ2",
        "source": "zotero"
       }
      ],
      "frccr": [
       {
        "id": "22783102/2IBV4AM6",
        "source": "zotero"
       }
      ],
      "ojenj": [
       {
        "id": "22783102/PCBNCFMD",
        "source": "zotero"
       }
      ],
      "v6hgz": [
       {
        "id": "22783102/NEKVNJJD",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "One observation to be made, is that the graph makes the process of audiovisual\n",
    "integration in newsreel production appear almost linear, a steady movement\n",
    "toward the normalization of sound. But it is also striking to observe that\n",
    "silent films continued to appear well into the 1940s. The data therefore resist\n",
    "any neat periodisation. What can be seen instead is a slow and uneven adoption\n",
    "that depends as much on institutional practice and local conditions, as on\n",
    "technological possibilities. It is worth keeping in mind, and a reminiscence\n",
    "that patterns one might observe later are shaped by underlying imbalances in\n",
    "the Journal Digital collection itself. But the gradual nature of sound transition is\n",
    "interesting for another reason as well. It suggests that the Journal Digital\n",
    "collection does not simply document the use of sound, but also the process\n",
    "through which sound was being tested, adjusted, and creatively incorporated\n",
    "into the newsreel format. In other words, films capture a moment of\n",
    "experimentation, starting in the early 1930s when the vocabulary of sound in\n",
    "nonfiction film production was still being invented, including the documented\n",
    "ambivalence to the invention of audio supplementation within moving images.\n",
    "When sound was finally incorporated, film critics such as Béla Balázs or Rudolf\n",
    "Arnheim, and filmmakers such as Sergei Eisenstein and Vsevolod Pudovin,\n",
    "lamented that it destroyed the purity of cinematic realism \n",
    "(<cite id=\"v6hgz\"><a href=\"#zotero%7C22783102%2FNEKVNJJD\">(Arnheim 1957)</a></cite>,\n",
    "<cite id=\"ojenj\"><a href=\"#zotero%7C22783102%2FPCBNCFMD\">(Eisenstein, Pudovkin, and Alexandrov 1994)</a></cite>,\n",
    "<cite id=\"frccr\"><a href=\"#zotero%7C22783102%2F2IBV4AM6\">(Balázs 2010)</a></cite>,\n",
    "<cite id=\"e7cth\"><a href=\"#zotero%7C22783102%2FUVAHYVZ2\">(Balázs 2017)</a></cite>)\n",
    "While others celebrated the shift as a deepening of the medium’s evidential\n",
    "power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics",
     "anchor-pipe-ast"
    ]
   },
   "source": [
    "### Audio Object Detection [ del ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "First we passed all the files through an Audio Spectrogram Transformer\n",
    "(AST) pipeline, that segments the audio streams and gives the segments to the \n",
    "AST-model to automatically attach multiple labels to every segment. \n",
    "Suggested labels are associated with a probabilityfilesa confidence score that tells\n",
    "us how _certain_ the model is about its labelling. \n",
    "We save both the raw output as an .npz file and a filtered\n",
    "version, keeping only the top five (sorted by probability) labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "./src/audiovisual/processing/audio_extraction.py\n",
    "\n",
    "# HuggingFace model for audio classification\n",
    "HF_MODEL = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "\n",
    "# Audio processing parameters\n",
    "SR_TARGET = 16000  # Target sample rate (Hz)\n",
    "WIN_SEC = 2.56  # Window size (seconds)\n",
    "HOP_SEC = 0.64  # Hop size (seconds)\n",
    "TOPK = 5  # Number of top predictions to save\n",
    "BATCH_SZ = 32  # Batch size for model inference\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_ast(video_path: Path, out_dir: Path):\n",
    "  \"\"\"Run AST model on video audio and save results.\n",
    "\n",
    "  Extracts audio in sliding windows, computes probabilities for each\n",
    "  window, and saves:\n",
    "  - ast_probs.npz: Probability matrix, window times, metadata\n",
    "  - ast_topk.jsonl: Top-k predictions per window\n",
    "\n",
    "  Args:\n",
    "      video_path: Path to input video.\n",
    "      out_dir: Directory to save outputs.\n",
    "  \"\"\"\n",
    "  wav, sr = extract_audio_16k(video_path, settings.SR_TARGET)\n",
    "  win = int(round(settings.WIN_SEC * sr))\n",
    "  hop = int(round(settings.HOP_SEC * sr))\n",
    "\n",
    "  starts = list(range(0, max(1, len(wav) - win + 1), hop))\n",
    "  if len(wav) > (starts[-1] + win):\n",
    "    starts.append(len(wav) - win)\n",
    "\n",
    "  segments = []\n",
    "  starts_sec = []\n",
    "  for s0 in starts:\n",
    "    seg = wav[s0 : s0 + win]\n",
    "    if len(seg) < win:\n",
    "      seg = np.pad(seg, (0, win - len(seg)))\n",
    "    segments.append(seg)\n",
    "    starts_sec.append(s0 / sr)\n",
    "\n",
    "  ends_sec = np.array(starts_sec) + settings.WIN_SEC\n",
    "  probs_all = np.zeros((len(segments), num_labels), dtype=np.float32)\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    for i in tqdm(\n",
    "      range(0, len(segments), settings.BATCH_SZ),\n",
    "      desc=f\"AST {video_path.name}\",\n",
    "      position=1,\n",
    "      leave=False,\n",
    "    ):\n",
    "      batch = segments[i : i + settings.BATCH_SZ]\n",
    "      inputs = processor(\n",
    "        batch,\n",
    "        sampling_rate=settings.SR_TARGET,\n",
    "        return_tensors=\"pt\",\n",
    "      )\n",
    "      inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "      logits = model(**inputs).logits\n",
    "      probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "      probs_all[i : i + len(probs)] = probs\n",
    "\n",
    "  # 1: Save probability matrix\n",
    "  np.savez(\n",
    "    out_dir / \"ast_probs.npz\",\n",
    "    probs_all=probs_all,\n",
    "    win_starts_sec=np.array(starts_sec),\n",
    "    win_ends_sec=ends_sec,\n",
    "    meta={\n",
    "      \"sr\": sr,\n",
    "      \"model_id\": settings.HF_MODEL,\n",
    "      \"win_sec\": settings.WIN_SEC,\n",
    "      \"hop_sec\": settings.HOP_SEC,\n",
    "      \"topk\": settings.TOPK,\n",
    "    },\n",
    "  )\n",
    "\n",
    "  # 2: Save top-k predictions\n",
    "  with open(out_dir / \"ast_topk.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, p in enumerate(probs_all):\n",
    "      idx = np.argsort(p)[::-1][: settings.TOPK]\n",
    "      labs = [id2label[int(j)].lower() for j in idx]\n",
    "      f.write(\n",
    "        json.dumps(\n",
    "          {\n",
    "            \"start\": float(starts_sec[i]),\n",
    "            \"end\": float(ends_sec[i]),\n",
    "            \"labels\": labs,\n",
    "          }\n",
    "        )\n",
    "        + \"\\n\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-audiomix-*"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_audio_mix(per_year_mix, top_overall_df):\n",
    "  \"\"\"\n",
    "  Create audio mix visualization showing distribution by year and top labels.\n",
    "\n",
    "  Args:\n",
    "      per_year_mix: DataFrame with columns year, speech_pct, music_pct,\n",
    "      other_pct top_overall_df: DataFrame with top labels per category\n",
    "\n",
    "  Returns:\n",
    "      fig: Plotly figure object (for display or ipywidgets)\n",
    "  \"\"\"\n",
    "  if per_year_mix.empty:\n",
    "    raise ValueError(\"Supplied DataFrame is empty.\")\n",
    "\n",
    "  years = per_year_mix[\"year\"].astype(int).tolist()\n",
    "  s = per_year_mix[\"speech_pct\"].to_numpy(dtype=float)\n",
    "  m = per_year_mix[\"music_pct\"].to_numpy(dtype=float)\n",
    "  o = per_year_mix[\"other_pct\"].to_numpy(dtype=float)\n",
    "\n",
    "  colors = {\n",
    "    \"speech\": \"#1f77b4\",  # blue\n",
    "    \"music\": \"#ff7f0e\",  # orange\n",
    "    \"other\": \"#7f7f7f\",  # gray\n",
    "  }\n",
    "\n",
    "  # Create subplot with two columns: chart (left) and annotations (right)\n",
    "  fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    column_widths=[0.65, 0.35],\n",
    "    subplot_titles=(\"\", \"\"),  # We'll add custom title instead\n",
    "    specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}]],\n",
    "    horizontal_spacing=0.05,\n",
    "  )\n",
    "\n",
    "  # Add stacked area chart (traces added in reverse order for proper stacking)\n",
    "  # Other (bottom layer)\n",
    "  fig.add_trace(\n",
    "    go.Scatter(\n",
    "      x=years,\n",
    "      y=o,\n",
    "      name=\"Other\",\n",
    "      mode=\"lines\",\n",
    "      line=dict(width=0.5, color=colors[\"other\"]),\n",
    "      fillcolor=colors[\"other\"],\n",
    "      fill=\"tozeroy\",\n",
    "      stackgroup=\"one\",\n",
    "      opacity=0.85,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    "  )\n",
    "\n",
    "  # Music (middle layer)\n",
    "  fig.add_trace(\n",
    "    go.Scatter(\n",
    "      x=years,\n",
    "      y=m,\n",
    "      name=\"Music\",\n",
    "      mode=\"lines\",\n",
    "      line=dict(width=0.5, color=colors[\"music\"]),\n",
    "      fillcolor=colors[\"music\"],\n",
    "      fill=\"tonexty\",\n",
    "      stackgroup=\"one\",\n",
    "      opacity=0.85,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    "  )\n",
    "\n",
    "  # Speech (top layer)\n",
    "  fig.add_trace(\n",
    "    go.Scatter(\n",
    "      x=years,\n",
    "      y=s,\n",
    "      name=\"Speech\",\n",
    "      mode=\"lines\",\n",
    "      line=dict(width=0.5, color=colors[\"speech\"]),\n",
    "      fillcolor=colors[\"speech\"],\n",
    "      fill=\"tonexty\",\n",
    "      stackgroup=\"one\",\n",
    "      opacity=0.85,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    "  )\n",
    "\n",
    "  # Add invisible trace to right subplot to establish coordinate system\n",
    "  fig.add_trace(\n",
    "    go.Scatter(\n",
    "      x=[0, 1],\n",
    "      y=[0, 1],\n",
    "      mode=\"markers\",\n",
    "      marker=dict(size=0, opacity=0),\n",
    "      showlegend=False,\n",
    "      hoverinfo=\"skip\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    "  )\n",
    "\n",
    "  # Update left subplot (chart) layout\n",
    "  fig.update_xaxes(\n",
    "    title_text=\"Year\",\n",
    "    range=[min(years), max(years)],\n",
    "    showgrid=False,\n",
    "    row=1,\n",
    "    col=1,\n",
    "  )\n",
    "  fig.update_yaxes(\n",
    "    title_text=\"Share of audio-active time (%)\",\n",
    "    range=[0, 100],\n",
    "    dtick=20,\n",
    "    showgrid=True,\n",
    "    gridwidth=0.5,\n",
    "    gridcolor=\"rgba(128, 128, 128, 0.3)\",\n",
    "    row=1,\n",
    "    col=1,\n",
    "  )\n",
    "\n",
    "  # Configure right subplot for text annotations (0-1 coordinate system)\n",
    "  fig.update_xaxes(visible=False, range=[0, 1], row=1, col=2)\n",
    "  fig.update_yaxes(visible=False, range=[0, 1], row=1, col=2)\n",
    "\n",
    "  # Add text annotations to right panel\n",
    "  y_pos = 0.98\n",
    "  line_height = 0.055\n",
    "\n",
    "  for cat, title in [\n",
    "    (\"speech\", \"Speech\"),\n",
    "    (\"music\", \"Music\"),\n",
    "    (\"other\", \"Other\"),\n",
    "  ]:\n",
    "    block = top_overall_df[top_overall_df[\"category\"] == cat]\n",
    "    if block.empty:\n",
    "      continue\n",
    "\n",
    "    # Category header\n",
    "    fig.add_annotation(\n",
    "      text=f\"<b>{title}</b>\",\n",
    "      xref=\"x2\",\n",
    "      yref=\"y2\",\n",
    "      x=0.0,\n",
    "      y=y_pos,\n",
    "      showarrow=False,\n",
    "      font=dict(size=11, color=colors.get(cat, \"black\")),\n",
    "      xanchor=\"left\",\n",
    "      yanchor=\"top\",\n",
    "    )\n",
    "    y_pos -= line_height * 0.9\n",
    "\n",
    "    # Individual labels\n",
    "    for _, r in block.iterrows():\n",
    "      label = r[\"label\"]\n",
    "      share = r[\"category_share_pct\"]\n",
    "      secs = r[\"seconds\"]\n",
    "      txt = (\n",
    "        f\"{int(r['rank']):>2d}. {label} ({share:4.1f}%, {secs:,.0f}s)\"\n",
    "      )\n",
    "      fig.add_annotation(\n",
    "        text=txt,\n",
    "        xref=\"x2\",\n",
    "        yref=\"y2\",\n",
    "        x=0.02,\n",
    "        y=y_pos,\n",
    "        showarrow=False,\n",
    "        font=dict(size=9, family=\"monospace\"),\n",
    "        xanchor=\"left\",\n",
    "        yanchor=\"top\",\n",
    "      )\n",
    "      y_pos -= line_height\n",
    "\n",
    "    y_pos -= line_height * 0.6\n",
    "\n",
    "  # Update overall layout\n",
    "  fig.update_layout(\n",
    "    title={\n",
    "      \"text\": \"Audio mix by year and overall top-5 labels per category\",\n",
    "      \"x\": 0.32,\n",
    "      \"xanchor\": \"center\",\n",
    "      \"font\": {\"size\": 14},\n",
    "    },\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "      orientation=\"h\",\n",
    "      yanchor=\"top\",\n",
    "      y=0.98,\n",
    "      xanchor=\"left\",\n",
    "      x=0.01,\n",
    "      bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
    "    ),\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    hovermode=\"x unified\",\n",
    "  )\n",
    "\n",
    "  # Add subplot title for left panel\n",
    "  fig.add_annotation(\n",
    "    text=\"Audio content distribution by year\",\n",
    "    xref=\"x domain\",\n",
    "    yref=\"y domain\",\n",
    "    x=1.3,\n",
    "    y=1.1,\n",
    "    showarrow=False,\n",
    "    font=dict(size=12),\n",
    "    xanchor=\"center\",\n",
    "    yanchor=\"bottom\",\n",
    "  )\n",
    "\n",
    "  if not local:\n",
    "    return fig\n",
    "\n",
    "  file = root / \"media\" / \"audiomix.png\"\n",
    "\n",
    "  fig.write_image(file)\n",
    "\n",
    "  return Image(file)\n",
    "\n",
    "\n",
    "audio_mix_path = data / \"audio_mix_by_year.csv\"\n",
    "audio_mix_labels_path = data / \"audio_mix_top_labels_overall.csv\"\n",
    "\n",
    "display(\n",
    "  plot_audio_mix(\n",
    "    pd.read_csv(data / \"audio_mix_by_year.csv\"),\n",
    "    pd.read_csv(data / \"audio_mix_top_labels_overall.csv\"),\n",
    "  ),\n",
    "  width=1000,\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-audiomix-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"Audio content distribution within the Journal Digital \"\n",
    "          \"collection from 1930–1967. \"\n",
    "          \"The three categories _Speech_, _Music_, and _Other_ \"\n",
    "          \"are also split into a number of subcategories.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "When newsreels during the 1930s started to include sound—what could be heard in\n",
    "Swedish cinemas? That is, what kind of specific sounds on a general level can\n",
    "be detected in the Journal Digital collection by way of an aural, computational\n",
    "analyses? As is evident from the graph above, the majority of the sound\n",
    "consisted of speech and music. This is perhaps not entirely unexpected, and can\n",
    "be understood as an extension of the role once played by intertitles, which\n",
    "previously carried much of the newsreel’s informational value—an issue we will\n",
    "return to. There also appears to be a slight trend toward increased use of\n",
    "music over time. All of this holds true up until the final years represented in\n",
    "the dataset. However, we should be mindful of the distribution of data in this\n",
    "period, where the smaller number of film files means that percentages may be\n",
    "skewed (by only a few examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "ketkq": [
       {
        "id": "22783102/NLX2C8VR",
        "source": "zotero"
       }
      ],
      "ltq11": [
       {
        "id": "22783102/URY9RMYJ",
        "source": "zotero"
       }
      ],
      "oa81u": [
       {
        "id": "22783102/6AUNIX6I",
        "source": "zotero"
       }
      ],
      "p243l": [
       {
        "id": "22783102/JSI4ETR6",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If speech and music are obvious categories that a sound analysis of the entire\n",
    "Journal Digital collection would detect, the third category (_Other_) is of more\n",
    "interest. It encompasses both sound effects and diegetic elements, as well as\n",
    "how they relate to actual imagery \n",
    "<cite id=\"ketkq\"><a href=\"#zotero%7C22783102%2FNLX2C8VR\">(Chion 1994)</a></cite>.\n",
    "Listing the main types of\n",
    "sounds in this category immediately gives some sense of their function. A large\n",
    "number of detections are, for example, labeled as bursts or explosions. They\n",
    "should not, however, be taken as evidence of a particularly violent film\n",
    "corpus. In many cases, these are false positives: early optical audio\n",
    "recordings simply contain too much noise, and the AST model tends to interpret\n",
    "such random distortions as explosions. In fact, even to the human ear, the\n",
    "newsreel soundtracks are often so rough that it is difficult to tell whether a\n",
    "noise belongs to a recorded scene, or if it is simply an artifact of the medium\n",
    "itself. Beyond these, the data also show frequent detections of animals, cars,\n",
    "and other vehicles. A fascination for hearing modernity, and bringing the\n",
    "sounds of the streets to cinema audiences, was apparent in the early reception\n",
    "of the sound film technology. A Stockholm film critic in 1928, upon reviewing\n",
    "the emergent sound-infused newsreels (from Denmark), exclaimed: \"The cars\n",
    "screeched, the horses’ hooves rattled—and far off in the distance the guard\n",
    "parade approached. There came the first real reminder of where sound film has\n",
    "its greatest significance: in the newsreels\" \n",
    "<cite id=\"p243l\"><a href=\"#zotero%7C22783102%2FJSI4ETR6\">(Dagend Nyheter 1928)</a></cite>.\n",
    "In fact, vehicle sounds appear especially often in our dataset, accounting for\n",
    "around six percent of all entries in the _Other_ category. This prevalence\n",
    "may merit closer attention. The sound of a vehicle in the 1930s would have\n",
    "carried very different connotations than it does today\n",
    "<cite id=\"oa81u\"><a href=\"#zotero%7C22783102%2F6AUNIX6I\">(Brownell 1972)</a></cite>.\n",
    "It was less an everyday background noise—and more a distinctive signal of\n",
    "modernity. \"What they heard was a new kind of sound that was the product of\n",
    "modern technology\" \n",
    "<cite id=\"ltq11\"><a href=\"#zotero%7C22783102%2FURY9RMYJ\">(Thompson 2004)</a></cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics",
     "pipe-visual"
    ]
   },
   "source": [
    "### Visual Extraction [ del ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Next we reproduced a similar object-labelling on the visual signals using\n",
    "the Visual Language Model _Moondream_. \n",
    "Since Moondream is made for image processing—rather than video processing—we \n",
    "(1.) extracted a frame every fifth second; \n",
    "(2), homogenized image sizes; and \n",
    "(3.) asked Moondream to select up to six distinct objects visible in the frame.\n",
    "Mondream thus created a list of zero to six objects detected every five \n",
    "second segment. By temporally \n",
    "aligning the audio-annotations with the visual-annotations we were then able \n",
    "to compare how often sound-object pairs occured across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ".src/audiovisual/processing/visual_extraction.py\n",
    "\n",
    "# Frame extraction rate\n",
    "FRAME_FPS = 0.2  # Frames per second (0.2 = 1 frame every 5 seconds)\n",
    "\n",
    "# Image processing\n",
    "RESIZE_MAX = 256  # Maximum dimension for resizing\n",
    "JPEG_QUALITY = 60  # JPEG compression quality\n",
    "MAX_LABELS_PER_FRAME = 6  # Maximum labels to save per frame\n",
    "SAVE_EVERY = 50  # Save progress every N videos\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def process_video_file(video_path: Path, out_dir: Path) -> None:\n",
    "  \"\"\"Process single video file, extracting and labeling frames.\n",
    "\n",
    "  Args:\n",
    "      video_path: Path to input video.\n",
    "      out_dir: Directory for output files.\n",
    "  \"\"\"\n",
    "  per_frame_csv = out_dir / \"labels_per_frame.csv\"\n",
    "  per_frame_jsonl = out_dir / \"labels_per_frame.jsonl\"\n",
    "  freq_csv = out_dir / \"label_frequency.csv\"\n",
    "  uniq_txt = out_dir / \"unique_labels.txt\"\n",
    "\n",
    "  processed = load_processed_frames(per_frame_csv)\n",
    "  header_written = per_frame_csv.exists()\n",
    "  pending: List[Dict[str, Any]] = []\n",
    "\n",
    "  # 1. Extract one frame every 5 seconds\n",
    "  for fidx, t, frame in tqdm(\n",
    "    frames_from_video(video_path, settings.FRAME_FPS),\n",
    "    position=1,\n",
    "    leave=False,\n",
    "    desc=video_path.name,\n",
    "  ):\n",
    "    if fidx in processed:\n",
    "      continue\n",
    "\n",
    "    # 2. Re size frames, ensuring that they are all the same size\n",
    "    img_small = resize_keep_aspect(\n",
    "      pil_from_bgr(frame), settings.RESIZE_MAX\n",
    "    )\n",
    "\n",
    "    # 3. Prompt Moondream and record the answer\n",
    "    answer = md_query(\n",
    "      img_small,\n",
    "      (\n",
    "        \"List up to 6 distinct objects visible in the image as a comma-separated list \"\n",
    "        \"of short nouns only (singular form, no adjectives, no counts).\"\n",
    "      ),\n",
    "    )[\"answer\"]\n",
    "\n",
    "    labels = normalize_visual_labels(\n",
    "      answer, cap=settings.MAX_LABELS_PER_FRAME\n",
    "    )\n",
    "    pending.append(\n",
    "      {\n",
    "        \"frame\": fidx,\n",
    "        \"time_s\": round(t, 3),\n",
    "        \"labels\": \"|\".join(labels),\n",
    "      }\n",
    "    )\n",
    "    processed.add(fidx)\n",
    "\n",
    "    if len(pending) >= settings.SAVE_EVERY:\n",
    "      header_written = append_rows_csv(\n",
    "        per_frame_csv, pending, header_written\n",
    "      )\n",
    "      append_rows_jsonl(per_frame_jsonl, pending)\n",
    "      pending.clear()\n",
    "\n",
    "  if pending:\n",
    "    header_written = append_rows_csv(\n",
    "      per_frame_csv, pending, header_written\n",
    "    )\n",
    "    append_rows_jsonl(per_frame_jsonl, pending)\n",
    "\n",
    "  compute_and_save_frequency(per_frame_csv, freq_csv, uniq_txt)\n",
    "  write_summary_json(out_dir, per_frame_csv, freq_csv, video_path)\n",
    "  print(f\"[done] {video_path.name} → {out_dir}\")\n",
    "\n",
    "# 1. Extract one frame every 5 seconds\n",
    "def frames_from_video(path: Path, fps_target: float = None):\n",
    "  \"\"\"Extract frames from video at specified FPS.\n",
    "\n",
    "  Args:\n",
    "      path: Path to video file.\n",
    "      fps_target: Target frames per second. Defaults to settings.FRAME_FPS.\n",
    "\n",
    "  Yields:\n",
    "      Tuples of (frame_index, time_seconds, frame_bgr).\n",
    "\n",
    "  Raises:\n",
    "      RuntimeError: If video cannot be opened.\n",
    "  \"\"\"\n",
    "\n",
    "  fps_target = fps_target or settings.FRAME_FPS\n",
    "  cap = cv2.VideoCapture(str(path))\n",
    "  if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Cannot open video: {path}\")\n",
    "\n",
    "  fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "  step = max(1, int(round(fps / max(1e-6, fps_target))))\n",
    "  idx = 0\n",
    "\n",
    "  while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "      break\n",
    "    if idx % step == 0:\n",
    "      yield idx, idx / fps, frame\n",
    "    idx += 1\n",
    "\n",
    "  cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Invisible Vehicles [ del ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Another way to discover how sounds of modernity are manifested in the Journal\n",
    "Digital collection, is to take a closer look at how vehicle sounds are paired\n",
    "with particular types of images. Interestingly, none of the detected vehicle\n",
    "sounds correspond directly to images of cars. Instead, they tend to appear\n",
    "alongside signs of outdoor or on-location filming: buildings, stretches of sky,\n",
    "grass, and trees all coincide with the presence of vehicle sounds. To some\n",
    "extent, this may be an artifact of the analysis, since the model occasionally\n",
    "identifies vehicle sounds in scenes where no vehicles are visible. Yet, the\n",
    "pattern is revealing, and also demonstrates a surprisingly sophisticated way of\n",
    "representing sound. Rather than merely mirroring what is seen, the soundtrack\n",
    "adds another layer of meaning. Vehicle sounds are often paired with other kinds\n",
    "of visual information, suggesting that sound was used to evoke atmosphere,\n",
    "location, or a sense of movement rather than simply adding an ordinary sound\n",
    "track. This raises the question how sound and image were actually attached,\n",
    "both practically and conceptually, within newsreels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-vehiclepairs-*"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_x_pairing(\n",
    "  df_plot, top_visuals, chosen_audio, anypair_year_min\n",
    "):\n",
    "  \"\"\"\n",
    "  Create X-pairing visualization showing audio-visual token pairings over years.\n",
    "\n",
    "  Args:\n",
    "      df_plot: DataFrame with visual_token, year, seconds columns\n",
    "      top_visuals: List of top visual tokens to plot\n",
    "      chosen_audio: The selected audio token name\n",
    "      anypair_year_min: Minimum year for the plot subtitle\n",
    "\n",
    "  Returns:\n",
    "      fig: Plotly figure object (for display or ipywidgets)\n",
    "  \"\"\"\n",
    "  years_sorted = sorted(df_plot[\"year\"].unique().tolist())\n",
    "\n",
    "  fig = go.Figure()\n",
    "\n",
    "  for v in top_visuals:\n",
    "    yvals = []\n",
    "    for y in years_sorted:\n",
    "      s = df_plot.loc[\n",
    "        (df_plot[\"visual_token\"] == v) & (df_plot[\"year\"] == y),\n",
    "        \"seconds\",\n",
    "      ]\n",
    "      yvals.append(float(s.iloc[0]) if len(s) else 0.0)\n",
    "\n",
    "    fig.add_trace(\n",
    "      go.Scatter(\n",
    "        x=years_sorted,\n",
    "        y=yvals,\n",
    "        mode=\"lines+markers\",\n",
    "        name=str(v),\n",
    "        marker=dict(size=6),\n",
    "        line=dict(width=2),\n",
    "      )\n",
    "    )\n",
    "\n",
    "  # Update layout\n",
    "  fig.update_layout(\n",
    "    title=f\"'{chosen_audio}' pairings — seconds per year (≥ {anypair_year_min})\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"Seconds overlapped\",\n",
    "    showlegend=(len(top_visuals) <= 20),\n",
    "    legend=dict(\n",
    "      yanchor=\"top\",\n",
    "      y=0.99,\n",
    "      xanchor=\"left\",\n",
    "      x=1.01,\n",
    "    ),\n",
    "    hovermode=\"x unified\",\n",
    "    height=500,\n",
    "    width=1000,\n",
    "  )\n",
    "\n",
    "  # Update axes\n",
    "  fig.update_xaxes(\n",
    "    showgrid=True, gridwidth=0.5, gridcolor=\"rgba(128, 128, 128, 0.2)\"\n",
    "  )\n",
    "  fig.update_yaxes(\n",
    "    showgrid=True, gridwidth=0.5, gridcolor=\"rgba(128, 128, 128, 0.2)\"\n",
    "  )\n",
    "\n",
    "  if not local:\n",
    "    return fig\n",
    "\n",
    "  file = root / \"media\" / \"vehiclepairs.png\"\n",
    "\n",
    "  fig.write_image(file)\n",
    "\n",
    "  return Image(file)\n",
    "\n",
    "\n",
    "def csv_path_to_audioVisual_pairing_plot(csv_path, min_year=1930):\n",
    "  df_plot = pd.read_csv(csv_path)\n",
    "\n",
    "  # Extract audio token from filename\n",
    "  chosen_audio = csv_path.stem.split(\"__\")[0].replace(\"audio_\", \"\")\n",
    "  top_visuals = df_plot[\"visual_token\"].unique().tolist()\n",
    "\n",
    "  # Create and display plot\n",
    "  return plot_x_pairing(df_plot, top_visuals, chosen_audio, min_year)\n",
    "\n",
    "\n",
    "display(\n",
    "  csv_path_to_audioVisual_pairing_plot(\n",
    "    data / \"audio_vehicle__visuals_topk_seconds_long.csv\"\n",
    "  ),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-vehiclepairs-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"Audio content of _vehicles_ from the Journal \"\n",
    "          \"Digital collection—paired with fifteen types of \"\n",
    "          \"specific imagery.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To explore the relationship between sound and image in the Journal Digital\n",
    "collection, the following figure \n",
    "presents a method designed to track recurring\n",
    "pairings between audiovisual elements. This method extracts co-occurring audio\n",
    "and visual label pairs from films and summarises their temporal association\n",
    "across years. Visual labels are read at frame times, merged within a short\n",
    "window around each timestamp, and cleaned to remove placeholders, numbers,\n",
    "generic words, and banned categories. Audio categories come either from time\n",
    "aligned probability scores or—when class names are unreliable—from a stored\n",
    "list of top labels; both paths are converted into simple word tokens after the\n",
    "same cleaning. At each timestamp the present audio tokens and visual tokens\n",
    "form pairs that are tracked as segments with start time, end time, and\n",
    "duration; very short segments are dropped, and files dominated by silence are\n",
    "skipped early. Segments are then matched to a year using a name to year table,\n",
    "then aggregated to compute total seconds and the number of distinct videos for\n",
    "each pair, with a minimum total duration filter. Results are written to CSV\n",
    "files including all pairs, per year summaries, and a ranked shortlist that\n",
    "enforces per audio and per visual caps, along with a global limit so no single\n",
    "label dominates. For the shortlisted pairs the code also exports per year\n",
    "totals and percentages of each year’s total duration to support plotting and\n",
    "later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-pair-overlap-*"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_top_pair_share(\n",
    "  pct_long_path,\n",
    "  year_min_plot=1930,\n",
    "  exclude_audio_tokens=None,\n",
    "  exclude_visual_tokens=None,\n",
    "  exclude_any_tokens=None,\n",
    "  exclude_substrings=None,\n",
    "):\n",
    "  \"\"\"\n",
    "  Create top pair share visualization showing percent per year with legend panel.\n",
    "\n",
    "  Args:\n",
    "      pct_long_path: Path to top_pairs_percent_long.csv\n",
    "      year_min_plot: Minimum year to include in plot\n",
    "      exclude_audio_tokens: Set of audio tokens to exclude\n",
    "      exclude_visual_tokens: Set of visual tokens to exclude\n",
    "      exclude_any_tokens: Set of tokens to exclude from either audio or visual\n",
    "      exclude_substrings: Set of substrings to exclude\n",
    "      legend_max_rows_per_col: Maximum rows per legend column (unused, kept for compatibility)\n",
    "      legend_col_width: Width of legend columns (unused, kept for compatibility)\n",
    "\n",
    "  Returns:\n",
    "      fig: Plotly figure object (for display or ipywidgets)\n",
    "  \"\"\"\n",
    "  exclude_audio_tokens = exclude_audio_tokens or {\n",
    "    \"speech\",\n",
    "    \"sound\",\n",
    "    \"effect\",\n",
    "  }\n",
    "  exclude_visual_tokens = exclude_visual_tokens or set()\n",
    "  exclude_any_tokens = exclude_any_tokens or set()\n",
    "  exclude_substrings = exclude_substrings or set()\n",
    "\n",
    "  def _require_file(path) -> bool:\n",
    "    if not path.exists():\n",
    "      print(f\"[skip] missing: {path}\")\n",
    "      return False\n",
    "    return True\n",
    "\n",
    "  def _split_pair_label(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Expect 'pair_label' like 'audio_token × visual_token'.\"\"\"\n",
    "    a_v = (\n",
    "      df[\"pair_label\"].astype(str).str.split(\" × \", n=1, expand=True)\n",
    "    )\n",
    "    df[\"audio_token_plot\"] = a_v[0].str.lower()\n",
    "    df[\"visual_token_plot\"] = (\n",
    "      a_v[1].str.lower() if a_v.shape[1] > 1 else \"\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "  def _apply_excludes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Apply EXCLUDE_* rules at plotting time only.\"\"\"\n",
    "    if df.empty:\n",
    "      return df\n",
    "\n",
    "    df = _split_pair_label(df)\n",
    "\n",
    "    ex_a = {t.lower() for t in exclude_audio_tokens}\n",
    "    ex_v = {t.lower() for t in exclude_visual_tokens}\n",
    "    ex_any = {t.lower() for t in exclude_any_tokens}\n",
    "\n",
    "    mask_exact = (\n",
    "      df[\"audio_token_plot\"].isin(ex_a)\n",
    "      | df[\"visual_token_plot\"].isin(ex_v)\n",
    "      | df[\"audio_token_plot\"].isin(ex_any)\n",
    "      | df[\"visual_token_plot\"].isin(ex_any)\n",
    "    )\n",
    "\n",
    "    if exclude_substrings:\n",
    "      lowersubs = {s.lower() for s in exclude_substrings}\n",
    "\n",
    "      def _has_sub(s: str) -> bool:\n",
    "        s = s or \"\"\n",
    "        s = s.lower()\n",
    "        return any(sub in s for sub in lowersubs)\n",
    "\n",
    "      mask_sub = df[\"audio_token_plot\"].apply(_has_sub) | df[\n",
    "        \"visual_token_plot\"\n",
    "      ].apply(_has_sub)\n",
    "      mask = mask_exact | mask_sub\n",
    "    else:\n",
    "      mask = mask_exact\n",
    "\n",
    "    before = len(df)\n",
    "    df = df[~mask].copy()\n",
    "    after = len(df)\n",
    "    if before - after:\n",
    "      print(\n",
    "        f\"[filter] excluded {before - after} rows based on token rules\"\n",
    "      )\n",
    "    return df\n",
    "\n",
    "  if not _require_file(pct_long_path):\n",
    "    raise SystemExit(\n",
    "      \"Required CSV not found. Run the anypair export step first.\"\n",
    "    )\n",
    "\n",
    "  pct_long = pd.read_csv(pct_long_path)\n",
    "\n",
    "  missing = {\"pair_label\", \"year\", \"percent\"} - set(pct_long.columns)\n",
    "  if missing:\n",
    "    raise SystemExit(\n",
    "      f\"top_pairs_percent_long.csv missing columns: {sorted(missing)}\"\n",
    "    )\n",
    "\n",
    "  pct_long[\"year\"] = pd.to_numeric(pct_long[\"year\"], errors=\"coerce\")\n",
    "  pct_long = pct_long.dropna(subset=[\"year\"]).copy()\n",
    "  pct_long[\"year\"] = pct_long[\"year\"].astype(int)\n",
    "\n",
    "  if year_min_plot is not None:\n",
    "    pct_long = pct_long[pct_long[\"year\"] >= year_min_plot].copy()\n",
    "\n",
    "  pct_long = _apply_excludes(pct_long)\n",
    "\n",
    "  if pct_long.empty:\n",
    "    print(\"[stop] No percent data after filters; nothing to plot.\")\n",
    "    return None\n",
    "\n",
    "  pairs_in_long = sorted(pct_long[\"pair_label\"].unique().tolist())\n",
    "\n",
    "  years = sorted(pct_long[\"year\"].unique().tolist())\n",
    "  pct_long_f = pct_long[\n",
    "    pct_long[\"pair_label\"].isin(pairs_in_long)\n",
    "  ].copy()\n",
    "\n",
    "  fig = go.Figure()\n",
    "\n",
    "  # Add line plots for each pair\n",
    "  for pair in pairs_in_long:\n",
    "    yvals = []\n",
    "    for y in years:\n",
    "      v = pct_long_f.loc[\n",
    "        (pct_long_f[\"pair_label\"] == pair)\n",
    "        & (pct_long_f[\"year\"] == y),\n",
    "        \"percent\",\n",
    "      ]\n",
    "      yvals.append(float(v.iloc[0]) if len(v) else 0.0)\n",
    "\n",
    "    fig.add_trace(\n",
    "      go.Scatter(\n",
    "        x=years,\n",
    "        y=yvals,\n",
    "        mode=\"lines+markers\",\n",
    "        name=pair,\n",
    "        marker=dict(size=6),\n",
    "        line=dict(width=2),\n",
    "      )\n",
    "    )\n",
    "\n",
    "  # Update layout\n",
    "  year_min_str = f\"≥ {year_min_plot}\"\n",
    "  fig.update_layout(\n",
    "    title=f\"Top pairs — share of each year's overlap (%) ({year_min_str}, exclusions applied)\".strip(),\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"% of year's total analysed overlap\",\n",
    "    hovermode=\"x unified\",\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "      yanchor=\"top\",\n",
    "      y=0.99,\n",
    "      xanchor=\"left\",\n",
    "      x=1.01,\n",
    "    ),\n",
    "    height=500,\n",
    "    width=1000,\n",
    "  )\n",
    "\n",
    "  # Update axes\n",
    "  fig.update_xaxes(\n",
    "    showgrid=True, gridwidth=0.5, gridcolor=\"rgba(128, 128, 128, 0.2)\"\n",
    "  )\n",
    "  fig.update_yaxes(\n",
    "    showgrid=True, gridwidth=0.5, gridcolor=\"rgba(128, 128, 128, 0.2)\"\n",
    "  )\n",
    "\n",
    "  if not local:\n",
    "    return fig\n",
    "\n",
    "  file = root / \"media\" / \"pair-overlap.png\"\n",
    "\n",
    "  fig.write_image(file)\n",
    "\n",
    "  return Image(file)\n",
    "\n",
    "\n",
    "display(\n",
    "  plot_top_pair_share(data / \"top_pairs_percent_long.csv\"),\n",
    "  width=1000,\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-pair-overlap-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"The sound of top-pair-content within the Journal Digital collection—with vehicle x tree as a winner.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Exploring the relationship between sound and image, some displayed correlations\n",
    "point toward the emergence of a few specific patterns. A number of these are\n",
    "straightforward and expected, such as artillery paired with gunfire, or\n",
    "applause with crowds, or fire with scenes of gathering people. Others make\n",
    "sense only partially, like the pairing of speedboats and airplanes, which\n",
    "likely results from a misrecognition of similar sound textures. Then there are\n",
    "combinations that are more puzzling, such as the frequent link between a bell\n",
    "sound and the appearance of a flag. Overall, there seems to be a recurring\n",
    "tendency for certain cross-domain associations to appear at specific moments in\n",
    "time, rather than evenly across the dataset. It is also clear that the highest\n",
    "occurrences are those paired with _vehicle_. Looking at the broader temporal\n",
    "figure, some co-occurrences peak quite distinctly in the early 1940s. This\n",
    "cannot simply be explained by the general volume of material from that period,\n",
    "since the overall number of films was then beginning to decline. Instead, it\n",
    "suggests an evolving approach to diegetic strategy—one that rises and recedes\n",
    "rather than progressing in a straight line. To explore this issue further, we\n",
    "manually examined the most frequent pairings identified across both sound and\n",
    "image domains. From these observations we compiled a list of potential diegetic\n",
    "connections. A rise in the use of sound was then observed, yet it is not clear\n",
    "that a distinctly diegetic style ever became dominant. Sound and image appear\n",
    "instead in the Journal Digital collection to function as largely independent\n",
    "channels of information. This separation was likely shaped by practical\n",
    "limitations, especially the uneven quality of early audio recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-top-audio-*"
    ]
   },
   "outputs": [],
   "source": [
    "def pre_pivot_top_pairs(\n",
    "  segments_csv_path,\n",
    "  pairs_overall_csv_path,\n",
    "  year_min=1930,\n",
    "  top_n_pairs=15,\n",
    "):\n",
    "  \"\"\"\n",
    "  Create three visualizations of top audio-visual pairs.\n",
    "\n",
    "  Line plot: percentage per year\n",
    "\n",
    "  Args:\n",
    "      segments_csv_path: Path to segments_filtered CSV\n",
    "      pairs_overall_csv_path: Path to pairs_overall CSV\n",
    "      year_min: Minimum year to include in titles\n",
    "      top_n_pairs: Number of top pairs to plot\n",
    "\n",
    "  Returns:\n",
    "      Plotly figure object\n",
    "  \"\"\"\n",
    "  # Load data\n",
    "  segs = pd.read_csv(segments_csv_path)\n",
    "  pairs_overall = pd.read_csv(pairs_overall_csv_path)\n",
    "\n",
    "  # Get top pairs list\n",
    "  top_pairs_list = (\n",
    "    pairs_overall.head(top_n_pairs)[[\"audio_label\", \"vision_label\"]]\n",
    "    .apply(tuple, axis=1)\n",
    "    .tolist()\n",
    "  )\n",
    "\n",
    "  # Filter segments to top pairs\n",
    "  segs[\"pair\"] = segs[[\"audio_label\", \"vision_label\"]].apply(\n",
    "    tuple, axis=1\n",
    "  )\n",
    "  segs_top = segs[segs[\"pair\"].isin(top_pairs_list)]\n",
    "\n",
    "  if segs_top.empty:\n",
    "    print(\"[warn] No segments found for top pairs\")\n",
    "    return None, None, None\n",
    "\n",
    "  # Create pivot table for seconds\n",
    "  pivot = (\n",
    "    segs_top.groupby([\"pair\", \"year\"])[\"duration_s\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .pivot(index=\"pair\", columns=\"year\", values=\"duration_s\")\n",
    "    .fillna(0.0)\n",
    "  )\n",
    "\n",
    "  # Create pivot table for percentages\n",
    "  totals_by_year = (\n",
    "    segs.groupby(\"year\", as_index=True)[\"duration_s\"]\n",
    "    .sum()\n",
    "    .astype(float)\n",
    "  )\n",
    "  pivot_pct = pivot.copy()\n",
    "  denoms = totals_by_year.reindex(pivot_pct.columns).replace(\n",
    "    0.0, np.nan\n",
    "  )\n",
    "  pivot_pct = (\n",
    "    (pivot_pct.divide(denoms, axis=1) * 100.0)\n",
    "    .replace([np.inf, -np.inf], np.nan)\n",
    "    .fillna(0.0)\n",
    "  )\n",
    "\n",
    "  return create_line_plot_percent(pivot_pct, year_min)\n",
    "\n",
    "\n",
    "def create_line_plot_percent(pivot_pct, year_min):\n",
    "  \"\"\"Create line plot showing percentage per year for top pairs.\"\"\"\n",
    "  years_sorted_pct = sorted(pivot_pct.columns.tolist())\n",
    "\n",
    "  fig = go.Figure()\n",
    "\n",
    "  for pair in pivot_pct.index:\n",
    "    yvals = [\n",
    "      pivot_pct.at[pair, y] if y in pivot_pct.columns else 0.0\n",
    "      for y in years_sorted_pct\n",
    "    ]\n",
    "    fig.add_trace(\n",
    "      go.Scatter(\n",
    "        x=years_sorted_pct,\n",
    "        y=yvals,\n",
    "        mode=\"lines+markers\",\n",
    "        name=f\"{pair[0]} × {pair[1]}\",\n",
    "        marker=dict(size=6),\n",
    "        line=dict(width=2),\n",
    "      )\n",
    "    )\n",
    "\n",
    "  fig.update_layout(\n",
    "    title=f\"Top audio–vision pairs over years (% of year's total) — year ≥ {year_min}\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"Share of year's overlap (%)\",\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "      orientation=\"h\",  # Horizontal legend\n",
    "      yanchor=\"top\",  # Anchor the top of the legend box...\n",
    "      y=-0.2,  # ...at a position below the x-axis (0 is the axis line)\n",
    "      xanchor=\"center\",\n",
    "      x=0.5,\n",
    "    ),\n",
    "    margin=dict(l=10, r=10, t=80, b=150),\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    template=\"plotly_white\",\n",
    "  )\n",
    "\n",
    "  fig.update_xaxes(\n",
    "    showgrid=True, gridwidth=0.5, gridcolor=\"rgba(128, 128, 128, 0.2)\"\n",
    "  )\n",
    "  fig.update_yaxes(\n",
    "    showgrid=True, gridwidth=0.5, gridcolor=\"rgba(128, 128, 128, 0.2)\"\n",
    "  )\n",
    "\n",
    "  if not local:\n",
    "    return fig\n",
    "\n",
    "  file = root / \"media\" / \"top-audio.png\"\n",
    "\n",
    "  fig.write_image(file)\n",
    "\n",
    "  return Image(file)\n",
    "\n",
    "\n",
    "display(\n",
    "  pre_pivot_top_pairs(\n",
    "    data / \"segments_filtered_year_ge_1930.csv\",\n",
    "    data / \"pairs_overall_year_ge_1930.csv\",\n",
    "  ),\n",
    "  # width=1000,\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-top-audio-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \" Top audio-vision pairs within the Journal Digital collection—with crowds and artillery as top scorers.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "6473a": [
       {
        "id": "22783102/FDPKQ7P8",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In 1947, Stellan Dahlstedt (1910–1991), published an article about the sound\n",
    "studios at Svensk Filmindustri. Sound recording on film is hardly \"the easiest\n",
    "procedure in filmmaking, as more than one director or producer is willing to\n",
    "attest\". During recording, it was often not possible to achieve the sound\n",
    "effects needed, Dahlstedt continued. In particular, it was difficult to \"adjust\n",
    "the strength and character of the different sounds during live recording.\n",
    "Therefore, each sound is recorded separately as much as possible and mixed\n",
    "during replay\". It was no secret that such a practice increased the amount of\n",
    "film stock used. Still, it saved time because there was \"no need to experiment\n",
    "with different sound effects during filming. It is the studio time that is the\n",
    "most expensive part of a film recording\"\n",
    "<cite id=\"6473a\"><a href=\"#zotero%7C22783102%2FFDPKQ7P8\">(Dahlstedt 1947)</a></cite>\n",
    "As director of film technology at SF, Dahlstedt knew what he was talking\n",
    "about—even if he was all likely writing about feature film production rather\n",
    "than newsreels. Then again, his statement to avoid experimenting with sound\n",
    "effects during filming, has relevance for our audio analyses. On-location sound\n",
    "in newsreel production seems to have been both fashionable and valued during\n",
    "the period, but also technically demanding. Most sounds were added during\n",
    "post-production, especially voice-over narration, but our analyses cannot\n",
    "really confirm the relation between diegetic and non-diegetic sound, at least\n",
    "not in a scholarly decent way. What is lacking within our signal archaeology\n",
    "set-up is the ability to align sound features more directly with visual\n",
    "content, as is today done in several other multimodal learning approaches. If\n",
    "newsreels did not consistently rely on synchronized or diegetic sound, it would\n",
    "be misleading for computational models to assume that a visible object should\n",
    "always have an audible counterpart. One way forward would be to integrate an\n",
    "adjacent layer of information—the textual. Intertitles, commentary, and other\n",
    "written elements often mediated the relationship between sound and image, and\n",
    "their gradual incorporation into the audiovisual mix hence deserves closer\n",
    "attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-blueprint-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/img7.png\", width=1000),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-blueprint-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \" At the Swedish SF company in the Film-City, north of \"\n",
    "          \"Stockholm, a new sound laboratory was inaugurated in the \"\n",
    "          \"late 1940s. It included a sound central (Ljudcentralen), an \"\n",
    "          \"echo-chamber (Ekorum) and a muting room (Dämpat rum). On the \"\n",
    "          \"second floor there was also a mixing room, and a specific \"\n",
    "          \"newsreel facility.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "anchor-sec-inter"
    ]
   },
   "source": [
    "## Intertitle Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "ukr4p": [
       {
        "id": "22783102/8P2FL3R2",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "While signal archaeology renders some insight into the audio dimensions of the\n",
    "Journal Digital collection, such a dataset by definition excludes early\n",
    "(silent) cinema. Yet non-visual data can also be gleaned from the latter by\n",
    "focusing on so-called intertitles. After 1900 they were inserted between scenes\n",
    "to provide important details about location, time or setting after a scene\n",
    "shift. With films growing longer, the use of intertitles also expanded. From\n",
    "1910 until the advent of sound cinema, intertitles became common practice in\n",
    "the film industry with its own conventions and codes. For examples, intertitles\n",
    "came to incorporate extended textual passages that filled the screen,\n",
    "typographic differentiation to mark hierarchies between narrator and dialogue,\n",
    "and ornamental as well as stylistic devices that underscored the intertitles\n",
    "aesthetic function within the cinematic experience\n",
    "<cite id=\"ukr4p\"><a href=\"#zotero%7C22783102%2F8P2FL3R2\">(Dupré La Tour 2005)</a></cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "2v933": [
       {
        "id": "22783102/8BSVNXZQ",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "When multi-reel feature films emerged, the intertitles provided a\n",
    "crucial function offering information necessary to condense the story or\n",
    "provide dialogue\n",
    "<cite id=\"2v933\"><a href=\"#zotero%7C22783102%2F8BSVNXZQ\">(Chaume 2020)</a></cite>.\n",
    "In newsreels, meanwhile, the intertitles functioned to structure the visual\n",
    "storyline, provide factual information about time, settings and portrayed\n",
    "individuals, and offer commentary guiding audience reactions. With the\n",
    "introduction of sound, the use of intertitles certainly changed, and the\n",
    "introduction of voice-over commentary made the intertitles shorter.\n",
    "Nevertheless, this overlooked and in previous digital historical research\n",
    "neglected audiovisual artefact includes a lot of textual information. In fact,\n",
    "the Journal Digital collection contains almost fifty thousand intertitles; they\n",
    "appear in more than 4,300 nonfiction films. Emphasis in this section will be\n",
    "placed on contextualizing the newsreel _Svensk Filmindustris Veckorevy_\n",
    "(_Svensk Filmindustri’s Weekly Review_) and the Journal Digital Corpus,\n",
    "describing the transcription pipeline, and exploring the intertitle contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-military-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/img8.png\", width=1000),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-military-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"Within the Journal Digital collection there are a number of \"\n",
    "          \"foreign nonfiction films, such as this unidentified short \"\n",
    "          \"film fragment from the mid 1910s, produced by Universal \"\n",
    "          \"Screen Magazine, with more than ten intertitles in less than \"\n",
    "          \"two minutes—albeit with short military orders!\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "6skwb": [
       {
        "id": "22783102/WQEJMM77",
        "source": "zotero"
       }
      ],
      "b3ct8": [
       {
        "id": "22783102/HDPCSX8E",
        "source": "zotero"
       }
      ],
      "coqqu": [
       {
        "id": "22783102/NTI97CTV",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Though previous research on newsreel intertitles is limited, there is a\n",
    "noticeable tension regarding how the editorial comments should be interpreted\n",
    "as a historical record. Some scholars argue that newsreel intertitles were\n",
    "primarily descriptive and that it was only with the invention of sound\n",
    "commentary that newsreels actually became a news medium proper. Nicolas Pronay,\n",
    "for example, argues that the \"range of social and political information which\n",
    "could be conveyed by pictures and monosyllabic captions alone, was obviously\n",
    "too restricted. The change-over to sound-film ... enabled them to cover any\n",
    "subject which was news-worthy irrespective of whether it was pictorial in\n",
    "nature\"\n",
    "<cite id=\"coqqu\"><a href=\"#zotero%7C22783102%2FNTI97CTV\">(Pronay 1971)</a></cite>.\n",
    "Similarly, Nicholas Reeves, writing on the topic of British film propaganda\n",
    "during World War I, contends that the \"dominant approach of the newsreels’\n",
    "editorial comment as carried by the titles was factual and restrained\"\n",
    "<cite id=\"6skwb\"><a href=\"#zotero%7C22783102%2FWQEJMM77\">(Reeves 1986)</a></cite>.\n",
    "From this perspective, the textual information in early cinema had a limited\n",
    "rhetorical function, due to both media technological conditions and established\n",
    "genre conventions. Recent scholarship, however, have argued that long before\n",
    "sound, newsreels included intertitles that \"served to explain and ideologically\n",
    "tint the footage sandwiched between them\"\n",
    "<cite id=\"b3ct8\"><a href=\"#zotero%7C22783102%2FHDPCSX8E\">(Scott 2024)</a></cite>.\n",
    "Hence, the rhetoric in the newsreel intertitles guided viewers’ opinions in\n",
    "advance of what appeared on screen—prior to the introduction of sound."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "citation-manager": {
     "citations": {
      "nz0oz": [
       {
        "id": "22783102/JQZ27MNN",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If the audio dataset of the Journal Digital collection gives us (at least some)\n",
    "insights about Swedish modernity, we argue that a dataset of some fifty\n",
    "thousand intertitles have a similar potential to provide commentary on Swedish\n",
    "society, touching on a wide variety of cultural, technological, and societal\n",
    "issues. Since intertitles were inserted into newsreeels—one textual prompt at\n",
    "the time—the amount of words is not mind-boggling. Nevertheless, our corpus\n",
    "still contains some 300,000 words. A key challenge when exploring these\n",
    "newsreel intertitles using digital methods is the frequent occurrence of\n",
    "mirrored flash intertitles. In film distribution and archiving, so-called flash\n",
    "intertitles served a distinct purpose. Notably, flash intertitles do not appear\n",
    "long enough for them to be readable. Rather they originally served as position\n",
    "markers on the negative, which in this context were used as a master copy for\n",
    "producing new prints, and hence pointing out exactly where to insert\n",
    "intertitles when producing a positive. Besides pointing out the position of the\n",
    "intertitles, the flash intertitles could also highlight the intended textual\n",
    "and visual design. Further, this practice has been commonplace in film\n",
    "distribution and archiving primarily to \"save on expensive film material\"\n",
    "<cite id=\"nz0oz\"><a href=\"#zotero%7C22783102%2FJQZ27MNN\">(Dobringer, Stöger, and Wratschko 2013)</a></cite>.\n",
    "Then again, to many film historians mirrored flash intertitles have always been\n",
    "a nuisance, not the least since some formats for moving images make it totally\n",
    "impossible to read them—on video it is hopeless, yet in an editing table they\n",
    "can be read, and now also in digital format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-ski-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/img9.png\", width=1000),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-ski-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"It is almost impossible to read the low resolution, and \"\n",
    "          \"mirrored flash intertitle, from _SF's Weekly Review_ \"\n",
    "          \"(15 April 1929)—a day when prince Fredrik from Denmark \"\n",
    "          \"arrived by train. The intertitle for the skiing competition \"\n",
    "          \"in Oslo at Holmenkolmen is easier to understand \"\n",
    "          \"(at least, if you speak Swedish), taken from, \"\n",
    "          \"_SF's Weekly Review_ \"\n",
    "          \"(26 February 1921). Mirrored flash intertitles are \"\n",
    "          \"today still default for film historians using the Journal \"\n",
    "          \"Digital collection at the National Library of Sweden; at \"\n",
    "          '[filmarkivet.se](https://filmarkivet.se){:target=\"_blank\"}, '\n",
    "          'however, restored and high resolution '\n",
    "          \"intertitle meets the viewer.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "77a57": [
       {
        "id": "22783102/PUAS8ZHL",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "There is little previous research on newsreel intertitles using digital\n",
    "methods. A notable exemption is a study on the Jean Desmet collection\n",
    "(1907–16), housed by the EYE Film Museum in the Netherlands. The authors show\n",
    "the usefulness of deep learning methods to detect intertitles in audiovisual\n",
    "corpora as markers of narrative structure\n",
    "<cite id=\"77a57\"><a href=\"#zotero%7C22783102%2FPUAS8ZHL\">(Bhargav, Van Noord, and Kamps 2019)</a></cite>.\n",
    "While Bhargav and colleagues demonstrate the technical feasibility of using\n",
    "deep learning to detect and analyse intertitles in early cinema, our study\n",
    "expands the approach by developing a multimodal transcription pipeline for a\n",
    "much larger corpus of Swedish newsreels spanning five decades. As briefly\n",
    "described in our introduction, we developed a custom transcription tool tool,\n",
    "_stum_, and deployed it to create individual .srt files for the 4,327 film with\n",
    "intertitles. The exact amount of texts totaled 302,312 words. Notably, the\n",
    "intertitles have a lower capacity for encoding text than a voice narrator, but\n",
    "still remains a vital source of information about the content of the films.\n",
    "Moreover, beside metadata about films, it is the only way to cover what the\n",
    "newsreels were actually about. It should be stressed, however, that given the\n",
    "major amount of catalogue work that Gardar Sahlberg (and other staff at SVT/SR)\n",
    "did during the 1960s and 1970s, the metadata for most films within the\n",
    "SF-archive is affluent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics",
     "figure-terrier-*"
    ]
   },
   "outputs": [],
   "source": [
    "class PNGSequencePlayer:\n",
    "  def __init__(self, file_paths, fps=24):\n",
    "    \"\"\"\n",
    "    file_paths: A list of string paths to the .png files (sorted).\n",
    "    fps: Default playback speed.\n",
    "    \"\"\"\n",
    "    # 1. Pre-load all PNG bytes into memory for zero-latency playback\n",
    "    self.frames_data = []\n",
    "    try:\n",
    "      for p in file_paths:\n",
    "        with open(p, \"rb\") as f:\n",
    "          self.frames_data.append(f.read())\n",
    "    except Exception as e:\n",
    "      print(f\"Error loading files: {e}\")\n",
    "      return\n",
    "\n",
    "    self.n_frames = len(self.frames_data)\n",
    "    self.is_paused_event = False\n",
    "\n",
    "    # --- UI Components ---\n",
    "\n",
    "    # We tell the widget these are PNGs\n",
    "    self.image_widget = widgets.Image(\n",
    "      value=self.frames_data[0],\n",
    "      format=\"png\",\n",
    "      layout=widgets.Layout(width=\"auto\", max_width=\"250px\"),\n",
    "    )\n",
    "\n",
    "    # Animation Controller\n",
    "    self.play_widget = widgets.Play(\n",
    "      value=0,\n",
    "      min=0,\n",
    "      max=self.n_frames - 1,\n",
    "      step=1,\n",
    "      interval=int(1000 / fps),\n",
    "      description=\"Press play\",\n",
    "      repeat=False,\n",
    "    )\n",
    "\n",
    "    # Scrubber\n",
    "    self.slider = widgets.IntSlider(\n",
    "      value=0, min=0, max=self.n_frames - 1, description=\"Frame\"\n",
    "    )\n",
    "\n",
    "    # Controls\n",
    "    self.fps_input = widgets.BoundedIntText(\n",
    "      value=fps,\n",
    "      min=1,\n",
    "      max=120,\n",
    "      step=1,\n",
    "      description=\"FPS:\",\n",
    "      layout=widgets.Layout(width=\"140px\"),\n",
    "    )\n",
    "\n",
    "    self.loop_box = widgets.Checkbox(value=False, description=\"Loop\")\n",
    "\n",
    "    # Pause Logic UI\n",
    "    self.pause_enable = widgets.Checkbox(\n",
    "      value=True, description=\"Wait 2s @ Frame:\"\n",
    "    )\n",
    "    self.pause_idx = widgets.BoundedIntText(\n",
    "      value=12,\n",
    "      min=0,\n",
    "      max=self.n_frames - 1,\n",
    "      description=\"\",\n",
    "      layout=widgets.Layout(width=\"60px\"),\n",
    "    )\n",
    "\n",
    "    # --- Logic Wiring ---\n",
    "\n",
    "    widgets.jslink(\n",
    "      (self.play_widget, \"value\"), (self.slider, \"value\")\n",
    "    )\n",
    "\n",
    "    self.slider.observe(self.on_frame_change, names=\"value\")\n",
    "    self.fps_input.observe(self.update_speed, names=\"value\")\n",
    "    self.loop_box.observe(self.update_loop, names=\"value\")\n",
    "\n",
    "    # --- Layout ---\n",
    "\n",
    "    # Group the specific pause controls\n",
    "    pause_group = widgets.HBox([self.pause_enable, self.pause_idx])\n",
    "\n",
    "    controls = widgets.VBox(\n",
    "      [\n",
    "        widgets.HBox([self.play_widget, self.slider]),\n",
    "        widgets.HBox([self.fps_input, self.loop_box, pause_group]),\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    self.ui = widgets.VBox([self.image_widget, controls])\n",
    "\n",
    "  def on_frame_change(self, change):\n",
    "    frame_idx = change[\"new\"]\n",
    "\n",
    "    # DIRECT BYTE SWAP - Extremely fast\n",
    "    self.image_widget.value = self.frames_data[frame_idx]\n",
    "\n",
    "    # Check for \"Magic Pause\"\n",
    "    if (\n",
    "      self.play_widget.playing\n",
    "      and self.pause_enable.value\n",
    "      and frame_idx == self.pause_idx.value\n",
    "      and not self.is_paused_event\n",
    "    ):\n",
    "      self.trigger_pause()\n",
    "\n",
    "  def trigger_pause(self):\n",
    "    \"\"\"Stops animation, waits 2s in background thread, resumes.\"\"\"\n",
    "    self.is_paused_event = True\n",
    "    self.play_widget.playing = False  # Stop\n",
    "\n",
    "    def resume_worker():\n",
    "      time.sleep(2)\n",
    "      self.play_widget.playing = True  # Resume\n",
    "      # Tiny buffer to ensure we don't re-trigger on the same millisecond\n",
    "      time.sleep(0.2)\n",
    "      self.is_paused_event = False\n",
    "\n",
    "    threading.Thread(target=resume_worker).start()\n",
    "\n",
    "  def update_speed(self, change):\n",
    "    if change[\"new\"] > 0:\n",
    "      self.play_widget.interval = int(1000 / change[\"new\"])\n",
    "\n",
    "  def update_loop(self, change):\n",
    "    self.play_widget.repeat = change[\"new\"]\n",
    "\n",
    "  def show(self):\n",
    "    display(self.ui)\n",
    "\n",
    "\n",
    "one_second = Path(\".\") / \"media\" / \"one_second\"\n",
    "\n",
    "\n",
    "def make_terrier():\n",
    "  terrier = PNGSequencePlayer(sorted(one_second.glob(\"*.png\")))\n",
    "  return terrier.show()\n",
    "\n",
    "\n",
    "display(\n",
    "  Image(\"./media/1s.grid.png\") if local else make_terrier(),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"tags\": [\n",
    "        \"figure-terrier-*\",\n",
    "      ],\n",
    "      \"object\": {\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"Blink and you will miss it. We have cut 25 frames, \"\n",
    "          \"equivalent to 1 second of playtime, from `SF604A.1.mpg` \"\n",
    "          \"which showcases several of the technical obstacles of \"\n",
    "          \"working with this this archival footage: 1) the \"\n",
    "          \"videocompression is very lossy, leading to many blocky \"\n",
    "          \"artefacts; 2) the flash intertitle is only fully visible \"\n",
    "          \"in a single frame (frame 12)—making it not only \"\n",
    "          \"impossible for a viewer to _read_ it—but also very likely \"\n",
    "          \"that they will miss it entirely;  3) the intertitle is \"\n",
    "          \"left-right mirrored, making it more difficult to \"\n",
    "          \"read—especially for an OCR software.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "4h8ft": [
       {
        "id": "22783102/DBCYMUBB",
        "source": "zotero"
       }
      ],
      "9cr2o": [
       {
        "id": "22783102/AZ3BT53M",
        "source": "zotero"
       }
      ],
      "qev7a": [
       {
        "id": "22783102/TT5RIEE2",
        "source": "zotero"
       }
      ],
      "vn2wg": [
       {
        "id": "22783102/MFU9DVN9",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics",
     "anchor-pipe-stum"
    ]
   },
   "source": [
    "### Transcribing Flash Intertitles [ del ] \n",
    "\n",
    "The application `stum`\n",
    "<cite id=\"qev7a\"><a href=\"#zotero%7C22783102%2FTT5RIEE2\">(Johansson 2025)</a></cite>\n",
    "combines three well established libraries to create a pipeline suitable for\n",
    "the analysis of the silent part of the Journal Digital film collection.\n",
    "More specifically stum uses OpenCV2 for image processing \n",
    "<cite id=\"vn2wg\"><a href=\"#zotero%7C22783102%2FMFU9DVN9\">(Bradski 2000)</a></cite>, \n",
    "EAST for text detection \n",
    "<cite id=\"4h8ft\"><a href=\"#zotero%7C22783102%2FDBCYMUBB\">(Zhou et al. 2017)</a></cite>, and TesseractOCR for the text extraction \n",
    "<cite id=\"9cr2o\"><a href=\"#zotero%7C22783102%2FAZ3BT53M\">(Smith 2007)</a></cite>. \n",
    "The OCR quality of all the tested intertitles were excellent; the highest \n",
    "Character Error Rate we encountered was below seven percent. The main problem \n",
    "to solve was intertitle detection. Due to the prevalence of flash intertitles, \n",
    "we first needed process every frame. However, passing \n",
    "every frame through the OCR engine is highly inefficient. To avoid this we\n",
    "gropued frames by sequential similarity. More specifically, we compared the\n",
    "Means Square Error of every two frames, and grouped images together where the\n",
    "difference was low, and instead used the middle image to represent the entire\n",
    "group of images. Next we passed all these representative images to detect\n",
    "large contour on the scale of a monochrome\n",
    "background. Next, we used EAST to filter out images with a low probability of\n",
    "containing text. Finally, we passed the original and left-right mirrored version\n",
    "through TesseractOCR for extraction of intertitle text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "# ./src/stum/contours.py\n",
    "\n",
    "# 3.c Calculate how large the biggest contour is relative to the frame\n",
    "def largest_contour(binary_image: cv2.typing.MatLike):\n",
    "  \"\"\"Returns the relative area of the largest contour of the image\"\"\"\n",
    "  contours = cv2.findContours(\n",
    "    binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "  )[0]\n",
    "  largest = cv2.contourArea(max(contours, key=cv2.contourArea))\n",
    "\n",
    "  width, height = binary_image.shape\n",
    "  total_area = width * height\n",
    "  relative_area = largest / total_area\n",
    "\n",
    "  return relative_area\n",
    "\n",
    "# 3 Filter out sequences without large contours\n",
    "def contour_filter(image: cv2.typing.MatLike, threshold=0.9) -> bool:\n",
    "  \"\"\"Check if image has one large contour\n",
    "\n",
    "  If the largest contour is smaller than the complement to the threshold,\n",
    "  it also calculates the largest contour of the inverted image. This is a\n",
    "  way to check for images with dark backgrounds and white text.\n",
    "\n",
    "  Parameters\n",
    "      image: cv2 image to check\n",
    "      threshold: threshold to check contour area against, default is 90%\n",
    "\n",
    "  Returns\n",
    "      True if image has one contour larger than given threshold\n",
    "  \"\"\"\n",
    "  # 3.b Convert image to grayscale and then binary \n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  binary = cv2.threshold(\n",
    "    gray, 100, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV\n",
    "  )[1]\n",
    "\n",
    "  # 3.c Calculate how large the biggest contour is relative to the frame\n",
    "  relative_area = largest_contour(binary)\n",
    "\n",
    "  # 3.d Check if complement is larger than threshold\n",
    "  if (1 - relative_area) > threshold:\n",
    "\n",
    "    # 3.e If so, invert the pixels and calculate a new largest areas\n",
    "    inverted = cv2.bitwise_not(binary)\n",
    "\n",
    "    inverteds_largest_area = largest_contour(inverted)\n",
    "\n",
    "    relative_area = max(relative_area, inverteds_largest_area)\n",
    "\n",
    "  return relative_area > threshold\n",
    "\n",
    "\n",
    "# ./src/stum/tesseract.py\n",
    "\n",
    "# 2.b Try to extract text\n",
    "def extract_text(image: cv2.typing.MatLike, contour_threshold=0.9) -> str:\n",
    "    \"\"\"Extract texts, or lack thereof from an image\n",
    "\n",
    "    Uses `ocr_mirror_ocr` to OCR original and mirrored version of the image.\n",
    "\n",
    "    If no text is found, it first checks for contours in the image -- and\n",
    "    if the largest contour is > `contour_threshold` (default 90%) the\n",
    "    binary inverse of the image will be used instead. If this also has a\n",
    "    single contour that is > `contour_threshold` an empty string is returned.\n",
    "\n",
    "    Otherwise, the image is cropped to the contour and then passed thorugh\n",
    "    `ocr_mirror_ocr` to get the text (or lack thereof.)\n",
    "\n",
    "    Arguments:\n",
    "        image {cv2.typing.MatLike} -- The image to extract texts from\n",
    "    output:\n",
    "        {str} -- The extracted text, is empty if no text is found\n",
    "    \"\"\"\n",
    "\n",
    "    # 4 use EAST to detect presence of text\n",
    "    if not east_filter(image):\n",
    "        return \"\"\n",
    "\n",
    "    # 5 first text extraction attempt\n",
    "    result = ocr_mirror_ocr(image)\n",
    "\n",
    "    if result != \"\":\n",
    "        return result\n",
    "\n",
    "    # If results were inconclusive, crop image to reduce noise and try again    \n",
    "    _, thresh1 = cv2.threshold(\n",
    "        cv2.cvtColor(\n",
    "            image,\n",
    "            cv2.COLOR_BGR2GRAY,\n",
    "        ),\n",
    "        100,\n",
    "        255,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "    )\n",
    "\n",
    "    im2 = image.copy()\n",
    "    width, height, _ = image.shape\n",
    "    total_area = width * height\n",
    "    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (18, 18))\n",
    "\n",
    "    # Find bounding box of largest contour in original\n",
    "    x, y, w, h = largest_contour_box(thresh1, rect_kernel)\n",
    "\n",
    "    if contour_area(x, y, w, h) / total_area > contour_threshold:\n",
    "        thresh1 = cv2.bitwise_not(thresh1)\n",
    "\n",
    "        # Find bounding box of largest contour in mirror\n",
    "        x, y, w, h = largest_contour_box(thresh1, rect_kernel)\n",
    "\n",
    "        if contour_area(x, y, w, h) / total_area > contour_threshold:\n",
    "\n",
    "            # If neither area is large enough to keep, terminate\n",
    "            return \"\"\n",
    "\n",
    "    # Cropping the text block for giving input to OCR\n",
    "    cropped = im2[y : y + h, x : x + w]\n",
    "\n",
    "    # 5 Final text extraction attempt\n",
    "    return ocr_mirror_ocr(cropped)\n",
    "\n",
    "\n",
    "# 5 first text extraction attempt\n",
    "def ocr_mirror_ocr(image):\n",
    "    \"\"\"Extract texts, or lack thereof from an image\n",
    "\n",
    "    Passes the original and a mirrored version of the image through OCR\n",
    "    and returns the 'best' text of the two.\n",
    "    'best' being the text with the fewest special characters.\n",
    "\n",
    "    Arguments:\n",
    "        image {cv2.typing.MatLike} -- The image to extract texts from\n",
    "    output:\n",
    "        {str} -- The extracted text, is empty if no text is found\n",
    "    \"\"\"\n",
    "\n",
    "    # Pass original and mirrored image through tesseract\n",
    "    original_text = pytesseract.image_to_string(image, lang=\"swe\")\n",
    "    mirrored_text = pytesseract.image_to_string(cv2.flip(image, 1), lang=\"swe\")\n",
    "\n",
    "    # Use the text with the fewest special characters.\n",
    "    if count_special_chars(mirrored_text) < count_special_chars(original_text):\n",
    "        text = mirrored_text\n",
    "    else:\n",
    "        text = original_text\n",
    "\n",
    "    result = clean_text(text)\n",
    "    return result\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "./src/stum/east.py\n",
    "\n",
    "model_loc = (\n",
    "    Path('.').parents[2] / \"models\" / \"frozen_east_text_detection.pb\"\n",
    ")\n",
    "\n",
    "east_net = cv2.dnn.readNet(str(model_loc))\n",
    "\n",
    "layerNames = [\"feature_fusion/Conv_7/Sigmoid\", \"feature_fusion/concat_3\"]\n",
    "\"\"\"\n",
    "\n",
    "# 4 use EAST to detect presence of text\n",
    "def east_filter(image: cv2.typing.MatLike) -> bool:\n",
    "  \"\"\"\n",
    "  This function filters an image using the EAST text detection model.\n",
    "\n",
    "  Parameters:\n",
    "  - image (cv2.typing\tMatLike): The input image to be filtered.\n",
    "\n",
    "  Returns:\n",
    "  - A boolean indicating whether the image contains any detected text or not.\n",
    "  \"\"\"\n",
    "\n",
    "  image_height, image_width = image.shape[:2]\n",
    "\n",
    "  blob = cv2.dnn.blobFromImage(\n",
    "    image,\n",
    "    1.0,\n",
    "    (image_width, image_height),\n",
    "    (123.68, 116.78, 103.94),\n",
    "    swapRB=True,\n",
    "    crop=False,\n",
    "  )\n",
    "\n",
    "  east_net.setInput(blob)\n",
    "  scores, _ = east_net.forward(layerNames)\n",
    "\n",
    "  num_scores = scores.shape[2]\n",
    "\n",
    "  score_data = [scores[0, 0, i] for i in range(num_scores)]\n",
    "\n",
    "  max_score = max([max(row) for row in score_data])\n",
    "  return max_score > 0.5\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ".src/stum/video_to_srt.py\n",
    "\n",
    "MSE_THRESHOLD = 10_000\n",
    "\"\"\"\n",
    "\n",
    "def mse(im1, im2):\n",
    "  err = np.sum((im1.astype(\"float\") - im2.astype(\"float\")) ** 2)\n",
    "  err /= float(im1.shape[0] * im1.shape[1])\n",
    "  return err\n",
    "\n",
    "# 2.a Check for changes in sequential frames\n",
    "def detect_scene_change(im1, im2):\n",
    "  score = mse(im1, im2)\n",
    "  return score > MSE_THRESHOLD\n",
    "\n",
    "\n",
    "# 2. Group farmes on sequential similarity \n",
    "def group_frames(frames_dir):\n",
    "    frames = sorted(frames_dir.glob(\"*.png\"))\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        raise FileNotFoundError(f\"No frames found in {frames_dir=}\")\n",
    "\n",
    "    grp_cnt = 0\n",
    "    for idx, frame in enumerate(frames):\n",
    "        if idx == 0:\n",
    "            im1 = cv2.imread(str(frame))\n",
    "            grp_dir = frames_dir / \"group_000\"\n",
    "            grp_dir.mkdir()\n",
    "\n",
    "            frame.rename(grp_dir / frame.name)\n",
    "            continue\n",
    "\n",
    "        im2 = cv2.imread(str(frame))\n",
    "        \n",
    "        # 2.a Check for changes in sequential frames\n",
    "        if detect_scene_change(im1, im2):\n",
    "            grp_cnt += 1\n",
    "            grp_dir = frames_dir / f\"group_{grp_cnt:03}\"\n",
    "            grp_dir.mkdir()\n",
    "\n",
    "        frame.rename(grp_dir / frame.name)\n",
    "\n",
    "        im1 = im2\n",
    "\n",
    "# 2.a Apply filters and extract texts\n",
    "def filter_frame_groups(group_dirs, debug=False):\n",
    "    def clear_dir(dir_path, debug=False):\n",
    "        if debug:\n",
    "            zip_file = dir_path.with_suffix(\".zip\")\n",
    "            with zipfile.ZipFile(zip_file, \"w\") as zf:\n",
    "                for file in dir_path.iterdir():\n",
    "                    zf.write(file, arcname=file.name)\n",
    "\n",
    "        for file in dir_path.iterdir():\n",
    "            file.unlink()\n",
    "        dir_path.rmdir()\n",
    "\n",
    "    for group_dir in group_dirs:\n",
    "        frames = sorted(group_dir.glob(\"*.png\"))\n",
    "        middle = int(len(frames) / 2)\n",
    "\n",
    "        # 2.b Use the middle frame to represent the entire scene\n",
    "        middle_frame = frames[middle]\n",
    "\n",
    "        image = cv2.imread(str(middle_frame))\n",
    "\n",
    "        # 3 Filter out sequences without large contours\n",
    "        if not contour_filter(image):\n",
    "            # 3.f if no large contours were found, discard group\n",
    "            clear_dir(group_dir)\n",
    "            continue\n",
    "\n",
    "        # 2.b Try to extract text\n",
    "        text = extract_text(image)\n",
    "        if text == \"\":\n",
    "            clear_dir(group_dir, debug)\n",
    "            continue\n",
    "\n",
    "        with open(group_dir / \"intertitle.txt\", \"x\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "\n",
    "def pipeline(input: Path, output_file: Path, debug: bool = False):\n",
    "    \"\"\"Extracts intertitletexts from a video file and writes them to an SRT.\n",
    "\n",
    "    Parameters:\n",
    "    - input (Path): The path to the input video file.\n",
    "    - output_file (Path): The path where the generated SRT subtitle file will\n",
    "      be saved.\n",
    "    - debug (bool, optional): If True, the intermed`iate processing files are\n",
    "      not deleted and can be used for debugging. Default is False.\n",
    "\n",
    "    Process:\n",
    "    1. Extract frames from the input video.\n",
    "    2. Group frames into sequences of similar frames using Mean Squared Error\n",
    "       (MSE).\n",
    "    3. Filter frame groups to keep only those with valid intertitles based on\n",
    "       contour detection and text extraction.\n",
    "    4. Merge sequences that have similar intertitle texts.\n",
    "    5. Convert the remaining intertitles into namedtuples, representing each\n",
    "       intertitle by its index, start frame number, end frame number, and\n",
    "       extracted text.\n",
    "    6. Generate SRT subtitle format from the namedtuple list of intertitles.\n",
    "    7. Save the generated SRT content to the specified output file.\n",
    "\n",
    "    The resulting SRT file will have timestamps derived from frame numbers\n",
    "    using a fixed frames per second (FPS) rate.\n",
    "    \"\"\"\n",
    "\n",
    "    if debug:\n",
    "        processing_dir = input.with_suffix(\"\")\n",
    "        processing_dir.mkdir()\n",
    "    else:\n",
    "        processing_dir = Path(mkdtemp())\n",
    "\n",
    "    # 1. Use ffmpeg to extract all frames\n",
    "    video_to_frames(input, processing_dir)\n",
    "\n",
    "    # 2. Group farmes on sequential similarity \n",
    "    group_frames(processing_dir)\n",
    "    \n",
    "    group_dirs = tqdm(\n",
    "        [dir for dir in processing_dir.iterdir() if dir.is_dir()],\n",
    "        desc=\"Processing groups\",\n",
    "    )\n",
    "\n",
    "    # 2.a Apply filters and extract texts\n",
    "    filter_frame_groups(group_dirs, debug=debug)\n",
    "\n",
    "    # Merge adjacent groups with near identical texts\n",
    "    merge_sequences(processing_dir)\n",
    "    \n",
    "    # Convert frame-numbering and extracted text to SRT \n",
    "    intertitles = sequence_to_namedtuples(processing_dir)\n",
    "    srt = intertitles_to_srt(intertitles)\n",
    "\n",
    "    output_file.open(\"w\", encoding=\"utf-8\").write(srt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "### Reading Intertitles [ del ]\n",
    "\n",
    "In the following code cell we load the intertitle corpus into a dataframe in\n",
    "preparation for the two upcoming figures. The simplest way to access the corpus\n",
    "in python is to install the `journal_digital` library from PyPI and load the \n",
    "_Corpus_ class, and use its iterator to access the transcriptions. \n",
    "While we load it, we also calculate\n",
    "the absolute and relative frequencies of the words 'by' and 'staden', the\n",
    "results of which are shown in [below](#figure-by-staden-*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "def load_intertitles():\n",
    "  corpus = Corpus(\"txt\", texts_to_include=\"intertitles\")\n",
    "\n",
    "  for srt in corpus:\n",
    "    year = srt.year\n",
    "    if not year.isdigit():\n",
    "      continue\n",
    "    year = int(year)\n",
    "    if year < 1900:\n",
    "      continue\n",
    "\n",
    "    intertitles = srt.content.split(\"\\n\")\n",
    "    tokens = srt.content.lower().split()\n",
    "    word_count = len(tokens)\n",
    "    words_per_intertitle = word_count / len(intertitles)\n",
    "\n",
    "    # Calculating for later\n",
    "    count_by = tokens.count(\"by\")\n",
    "    count_staden = tokens.count(\"staden\")\n",
    "    rel_by = count_by / word_count if word_count > 0 else 0.0\n",
    "    rel_staden = count_staden / word_count if word_count > 0 else 0.0\n",
    "\n",
    "    yield {\n",
    "      \"file\": srt.filename,\n",
    "      \"year\": year,\n",
    "      \"num_intertitles\": len(intertitles),\n",
    "      \"num_words\": word_count,\n",
    "      \"words_per_intertitle\": words_per_intertitle,\n",
    "      # Calculating for later\n",
    "      \"count_by\": count_by,\n",
    "      \"rel_by\": rel_by,\n",
    "      \"count_staden\": count_staden,\n",
    "      \"rel_staden\": rel_staden,\n",
    "    }\n",
    "\n",
    "\n",
    "corpus_df = pd.DataFrame(load_intertitles())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "4qxog": [
       {
        "id": "22783102/94IX6F2L",
        "source": "zotero"
       }
      ],
      "ejcan": [
       {
        "id": "22783102/3TIXWE3B",
        "source": "zotero"
       }
      ],
      "m6sna": [
       {
        "id": "22783102/GVASD2H8",
        "source": "zotero"
       }
      ],
      "rqbbs": [
       {
        "id": "22783102/94IX6F2L",
        "source": "zotero"
       }
      ],
      "sk6ia": [
       {
        "id": "22783102/GVASD2H8",
        "source": "zotero"
       }
      ],
      "tb5lm": [
       {
        "id": "22783102/94IX6F2L",
        "source": "zotero"
       }
      ],
      "wmyjk": [
       {
        "id": "22783102/94IX6F2L",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Quantitative and computational approaches to film history have a longer history\n",
    "than is often assumed. Indeed, experiments with quantification and data\n",
    "visualization date back to the 1960s and 1970s, when scholars such as Barry\n",
    "Salt began measuring average shot lengths\n",
    "<cite id=\"m6sna\"><a href=\"#zotero%7C22783102%2FGVASD2H8\">(Gaines 2024)</a></cite>.\n",
    "Similarly, in the mid-2000s, the large-scale Cinemetrics database for\n",
    "statistical film style analysis was launched\n",
    "<cite id=\"sk6ia\"><a href=\"#zotero%7C22783102%2FGVASD2H8\">(Gaines 2024)</a></cite>.\n",
    "These early initiatives foreshadowed the current wave of digital film history,\n",
    "which tends to combine distant and close viewing\n",
    "<cite id=\"ejcan\"><a href=\"#zotero%7C22783102%2F3TIXWE3B\">(Dang, Van Der Heijden, and Olesen 2024)</a></cite>.\n",
    "Our emphasis in the following lies on using word frequencies to explore\n",
    "what role intertitles had in newsreels over time, as well as exploring (the now\n",
    "searchable) newsreel intertitles focusing on the theme of modernity. With\n",
    "regard to Swedish film history, scholars have noted that the introduction of\n",
    "sound soon had a significant impact on the newsreel genre. In December 1929,\n",
    "the film _Say it with music_ (directed by Edvin Adolphson and Julius Jaenzon)\n",
    "was advertised as the first Swedish sound film\n",
    "<cite id=\"tb5lm\"><a href=\"#zotero%7C22783102%2F94IX6F2L\">(Furhammar 2003)</a></cite>.\n",
    "Shortly thereafter, in April 1930, the first newsreel with authentic sound was\n",
    "released featuring the Guard Parade in Stockholm\n",
    "<cite id=\"4qxog\"><a href=\"#zotero%7C22783102%2F94IX6F2L\">(Furhammar 2003)</a></cite>.\n",
    "However, due to the fact that the sound equipment was still difficult to\n",
    "handle, newsreels initially featured voice-over commentary with \"brisk and\n",
    "witty texts\"\n",
    "<cite id=\"wmyjk\"><a href=\"#zotero%7C22783102%2F94IX6F2L\">(Furhammar 2003)</a></cite>.\n",
    "Having extracted all intertitles from the Journal Digital collection it is\n",
    "possible to detect how the narrative usage of intertitles changed over time.\n",
    "While newsreels quickly became a sound medium—a \"medium of the voice\"\n",
    "<cite id=\"rqbbs\"><a href=\"#zotero%7C22783102%2F94IX6F2L\">(Furhammar 2003)</a></cite>—a\n",
    "quantitative analysis reveals that the reliance on intertitles persisted longer\n",
    "than one might have imagined. The period from the mid 1910s to the early 1930s\n",
    "stands out as the period when most words per intertitle were used, which is\n",
    "hardly surprising given that films were then silent. More surprisingly is the\n",
    "fact that it was not until the late 1930s that the number of words per\n",
    "intertitle was reduced to the same levels as prior to the introduction of\n",
    "sound. Similarly, the total number of words in the intertitles grew in the\n",
    "1920s, and then subsided toward the end of the 1930s. In addition—and worth\n",
    "stressing—is that intertitles remained in use throughout the whole newsreel\n",
    "era, up until the advent of television around 1960. In this sense, intertitles\n",
    "continued to play a narrative role also after newsreels became a \"medium of the\n",
    "voice\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-intertitle-trends-*"
    ]
   },
   "outputs": [],
   "source": [
    "def bootstrap_confidence_interval(data, n_bootstrap=1000, ci=95):\n",
    "  \"\"\"Calculates the mean and bootstrapped confidence interval.\"\"\"\n",
    "  bootstrap_means = np.zeros(n_bootstrap)\n",
    "  for i in range(n_bootstrap):\n",
    "    bootstrap_sample = np.random.choice(\n",
    "      data, size=len(data), replace=True\n",
    "    )\n",
    "    bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "  lower_bound = np.percentile(bootstrap_means, (100 - ci) / 2)\n",
    "  upper_bound = np.percentile(bootstrap_means, 100 - (100 - ci) / 2)\n",
    "\n",
    "  return pd.Series(\n",
    "    {\n",
    "      \"mean\": np.mean(data),\n",
    "      \"ci_lower\": lower_bound,\n",
    "      \"ci_upper\": upper_bound,\n",
    "    }\n",
    "  )\n",
    "\n",
    "\n",
    "def create_combined_plot(df):\n",
    "  # Create a figure with 2 rows and 1 column\n",
    "  fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    subplot_titles=(\n",
    "      \"Average number of words per intertitle\",\n",
    "      \"Average number of words per video\",\n",
    "    ),\n",
    "    vertical_spacing=0.15,\n",
    "  )\n",
    "\n",
    "  # Configuration for the two subplots\n",
    "  plot_configs = [\n",
    "    {\n",
    "      \"col\": \"words_per_intertitle\",\n",
    "      \"row\": 1,\n",
    "      \"y_label\": \"Words/Intertitle\",\n",
    "    },\n",
    "    {\"col\": \"num_words\", \"row\": 2, \"y_label\": \"Words/Video\"},\n",
    "  ]\n",
    "\n",
    "  for config in plot_configs:\n",
    "    # Calculate statistics\n",
    "    summary_df = (\n",
    "      df.groupby(\"year\")[config[\"col\"]]\n",
    "      .apply(bootstrap_confidence_interval)\n",
    "      .unstack()\n",
    "      .reset_index()\n",
    "    )\n",
    "\n",
    "    # 1. Add the Confidence Interval Band\n",
    "    fig.add_trace(\n",
    "      go.Scatter(\n",
    "        x=np.concatenate(\n",
    "          [summary_df[\"year\"], summary_df[\"year\"][::-1]]\n",
    "        ),\n",
    "        y=np.concatenate(\n",
    "          [summary_df[\"ci_upper\"], summary_df[\"ci_lower\"][::-1]]\n",
    "        ),\n",
    "        fill=\"toself\",\n",
    "        fillcolor=\"rgba(0,100,80,0.2)\",\n",
    "        line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "        hoverinfo=\"skip\",\n",
    "        showlegend=False,\n",
    "        name=\"95% CI\",\n",
    "      ),\n",
    "      row=config[\"row\"],\n",
    "      col=1,\n",
    "    )\n",
    "\n",
    "    # 2. Add the Mean Line\n",
    "    fig.add_trace(\n",
    "      go.Scatter(\n",
    "        x=summary_df[\"year\"],\n",
    "        y=summary_df[\"mean\"],\n",
    "        line=dict(color=\"rgb(0,100,80)\"),\n",
    "        mode=\"lines\",\n",
    "        name=\"Mean\",\n",
    "      ),\n",
    "      row=config[\"row\"],\n",
    "      col=1,\n",
    "    )\n",
    "\n",
    "    # Update individual axis labels\n",
    "    fig.update_yaxes(\n",
    "      title_text=config[\"y_label\"], row=config[\"row\"], col=1\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Year\", row=config[\"row\"], col=1)\n",
    "\n",
    "  # Global layout updates\n",
    "  fig.update_layout(\n",
    "    height=800,  # Adjust height for two subplots\n",
    "    width=1000,  # Adjust height for two subplots\n",
    "    showlegend=False,\n",
    "    title_text=\"Intertitle Trends Analysis\",\n",
    "    template=\"plotly_white\",\n",
    "  )\n",
    "\n",
    "  if not local:\n",
    "    return fig\n",
    "\n",
    "  file = root / \"media\" / \"intertitle-trends.png\"\n",
    "\n",
    "  fig.write_image(file)\n",
    "\n",
    "  return Image(file)\n",
    "\n",
    "\n",
    "display(\n",
    "  create_combined_plot(corpus_df),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-intertitle-trends-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"The chart above plots the number of words that were used in \"\n",
    "          \"each intertitle covering the entire Journal Digital \"\n",
    "          \"collection. The chart below charts the average number of \"\n",
    "          \"words in each film with intertitles, also in the entire \"\n",
    "          \"Journal Digital collection. \"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "ek61p": [
       {
        "id": "22783102/685XZA23",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As noted, automatic speech recognition and other machine listening techniques\n",
    "have contributed toward making audiovisual archives searchable and computable.\n",
    "In this case, the transcription of the intertitles allowed us to explore the\n",
    "textual descriptions with simple word frequencies. Some rudimentary\n",
    "observations can be made with regard to topics covered. Not surprisingly,\n",
    "\"Sweden\", \"Swedish\" and the capital of \"Stockholm\" are among the most\n",
    "frequently occurring words in the intertitle dataset. In terms of geography,\n",
    "other frequently mentioned cities are \"Gothenburg\", \"Paris\" and \"London\". This\n",
    "highlights the fact that the newsreel as a medium was highly transnational:\n",
    "reels depicting current events were bought, exchanged and distributed across\n",
    "Europe and the world\n",
    "<cite id=\"ek61p\"><a href=\"#zotero%7C22783102%2F685XZA23\">(Chambers, Jönsson, and Winkel 2018)</a></cite>.\n",
    "In terms of thematic coverage, it is also noteworthy that the word \"staden\", a\n",
    "town (115 counts), and the word \"by\", village (106 counts), occur almost just\n",
    "as frequently \n",
    "in the intertitle corpus. Whereas the word\n",
    "\"town\" shows a concentration around the 1920s and 1930s, the word \"by\" is\n",
    "distributed more evenly across the corpus. This is thought-provoking given that\n",
    "the 1920s and 1930s have usually been described as a period of dramatic\n",
    "transformation, and a time when modernity arrived in Sweden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-by-staden-*"
    ]
   },
   "outputs": [],
   "source": [
    "def create_frequency_scatter(df, word, color=\"salmon\"):\n",
    "  \"\"\"\n",
    "  Create a Plotly scatter plot showing relative frequencies (excluding zeros).\n",
    "\n",
    "  Args:\n",
    "      df: DataFrame with columns [filename, rel_frequency]\n",
    "      word: The word being plotted (for title)\n",
    "      color: Color for scatter points\n",
    "\n",
    "  Returns:\n",
    "      plotly.graph_objects.Figure\n",
    "  \"\"\"\n",
    "  # Filter out zero frequencies to focus on files that contain the word\n",
    "  df_nonzero = df[df[\"rel_frequency\"] > 0].copy()\n",
    "  df_nonzero = df_nonzero.sort_values(\"rel_frequency\").reset_index(\n",
    "    drop=True\n",
    "  )\n",
    "\n",
    "  fig = go.Figure()\n",
    "\n",
    "  # Create line plot\n",
    "  fig.add_trace(\n",
    "    go.Scattergl(\n",
    "      x=list(range(len(df_nonzero))),\n",
    "      y=df_nonzero[\"rel_frequency\"],\n",
    "      mode=\"lines\",\n",
    "      line=dict(color=color, width=2),\n",
    "      text=df_nonzero[\"filename\"],\n",
    "      hovertemplate=(\n",
    "        \"<b>%{text}</b><br>Relative \"\n",
    "        \"Frequency: %{y:.5f}<extra></extra>\"\n",
    "      ),\n",
    "      showlegend=False,\n",
    "    )\n",
    "  )\n",
    "\n",
    "  # Configure layout\n",
    "  fig.update_layout(\n",
    "    title=dict(\n",
    "      text=(\n",
    "        f'Relative Frequencies for \"{word}\"<br><sub>{len(df_nonzero)}'\n",
    "        f\"files (excluding {len(df) - len(df_nonzero)} files with \"\n",
    "        \"zero frequency)</sub>\"\n",
    "      ),\n",
    "      x=0.5,\n",
    "      xanchor=\"center\",\n",
    "      font=dict(size=14),\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "      title=\"Files (sorted by frequency)\",\n",
    "      rangemode=\"tozero\",\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "      title=\"Relative Frequency\",\n",
    "      rangemode=\"tozero\",\n",
    "    ),\n",
    "    plot_bgcolor=\"white\",\n",
    "    height=600,\n",
    "  )\n",
    "\n",
    "  return fig\n",
    "\n",
    "\n",
    "def create_dual_axis_plot(color_by=\"#E57373\", color_staden=\"#7D8B7D\"):\n",
    "  \"\"\"\n",
    "  Create a Plotly dual y-axis plot showing relative frequencies.\n",
    "\n",
    "  Returns:\n",
    "      plotly.graph_objects.Figure with dual y-axes\n",
    "  \"\"\"\n",
    "\n",
    "  dual_df = corpus_df.query(\n",
    "    \"`count_by` > 0 | `count_staden` > 0\"\n",
    "  ).sort_values([\"year\", \"file\"])\n",
    "\n",
    "  # Calculate statistics for y-axis labels\n",
    "  total_by = int(corpus_df[\"count_by\"].sum())\n",
    "  files_by = int((corpus_df[\"count_by\"] > 0).sum())\n",
    "  total_staden = int(corpus_df[\"count_staden\"].sum())\n",
    "  files_staden = int((corpus_df[\"count_staden\"] > 0).sum())\n",
    "\n",
    "  fig = go.Figure()\n",
    "\n",
    "  # Trace 1: by on left y-axis with circle markers\n",
    "  fig.add_trace(\n",
    "    go.Scattergl(\n",
    "      x=dual_df[\"file\"],\n",
    "      y=dual_df[\"rel_by\"],\n",
    "      mode=\"lines+markers\",\n",
    "      name=\"by\",\n",
    "      line=dict(color=color_by, width=2),\n",
    "      marker=dict(symbol=\"circle\", size=6, color=color_by),\n",
    "      customdata=dual_df[[\"count_by\"]].values,\n",
    "      hovertemplate=(\n",
    "        \"by: %{y:.5f} (%{customdata[0]:.0f} occurrences)\"\n",
    "        \"<extra></extra>\"\n",
    "      ),\n",
    "      yaxis=\"y1\",\n",
    "    )\n",
    "  )\n",
    "\n",
    "  # Trace 2: staden on right y-axis with triangle markers\n",
    "  fig.add_trace(\n",
    "    go.Scattergl(\n",
    "      x=dual_df[\"file\"],\n",
    "      y=dual_df[\"rel_staden\"],\n",
    "      mode=\"lines+markers\",\n",
    "      name=\"staden\",\n",
    "      line=dict(color=color_staden, width=2),\n",
    "      marker=dict(symbol=\"triangle-up\", size=8, color=color_staden),\n",
    "      customdata=dual_df[[\"count_staden\"]].values,\n",
    "      hovertemplate=(\n",
    "        \"staden: %{y:.5f} (%{customdata[0]:.0f} occurrences)\"\n",
    "        \"<extra></extra>\"\n",
    "      ),\n",
    "      yaxis=\"y2\",\n",
    "    )\n",
    "  )\n",
    "\n",
    "  # Configure layout with dual y-axes\n",
    "  fig.update_layout(\n",
    "    title=dict(\n",
    "      text=f'Relative Frequencies: \"by\" and \"staden\"<br>'\n",
    "      f\"<sub>{len(dual_df)} files (where at least one word appears)</sub>\",\n",
    "      x=0.5,\n",
    "      xanchor=\"center\",\n",
    "      font=dict(size=14),\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "      title=\"Files (sorted by year → filename)\",\n",
    "      showticklabels=False,\n",
    "      type=\"category\",\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "      title=dict(\n",
    "        text=(\n",
    "          f'<b style=\"color:{color_by}\">by</b> Relative Frequency<br>'\n",
    "          f'<sub>{total_by} occurrences in {files_by} files</sub>'\n",
    "          ),\n",
    "        font=dict(color=color_by),\n",
    "      ),\n",
    "      rangemode=\"tozero\",\n",
    "      side=\"left\",\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "      title=dict(\n",
    "        text=(\n",
    "          f'<b style=\"color:{color_staden}\">by</b> Relative Frequency'\n",
    "          f'<br><sub>{total_staden} occurrences in {files_staden} '\n",
    "          'files</sub>'),\n",
    "        font=dict(color=color_staden),\n",
    "      ),\n",
    "      rangemode=\"tozero\",\n",
    "      overlaying=\"y\",\n",
    "      side=\"right\",\n",
    "    ),\n",
    "    plot_bgcolor=\"white\",\n",
    "    height=400,\n",
    "    width=800,\n",
    "    hovermode=\"x unified\",\n",
    "    legend=dict(\n",
    "      orientation=\"h\",\n",
    "      yanchor=\"bottom\",\n",
    "      y=1.02,\n",
    "      xanchor=\"center\",\n",
    "      x=0.5,\n",
    "    ),\n",
    "  )\n",
    "\n",
    "  if not local:\n",
    "    return fig\n",
    "\n",
    "  file = root / \"media\" / \"by-staden.png\"\n",
    "\n",
    "  fig.write_image(file)\n",
    "\n",
    "  return Image(file)\n",
    "\n",
    "\n",
    "def make_by_stad_plot():\n",
    "  return create_dual_axis_plot(\n",
    "    color_by=\"#E57373\", color_staden=\"#7D8B7D\"\n",
    "  )\n",
    "\n",
    "\n",
    "display(\n",
    "  make_by_stad_plot(),\n",
    "  width=1000,\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-by-staden-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"Two charts display the occurrences of _staden_ (city) \"\n",
    "          \"and _by_ (village) in the intertitle dataset from the \"\n",
    "          \"Journal Digital collection—where they appear almost the \"\n",
    "          \"same amount of times. The films have archival names \"\n",
    "          \"(such as SF200) with an added year.\"\n",
    "          \"\\n\"\n",
    "          \"[ Del ? ]\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "7hx24": [
       {
        "id": "22783102/6VFT9YB8",
        "source": "zotero"
       }
      ],
      "8jann": [
       {
        "id": "22783102/KADI4AFW",
        "source": "zotero"
       }
      ],
      "er18t": [
       {
        "id": "22783102/2X3XHIU7",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Intertitle transcriptions cannot only be used to mine the text material at\n",
    "scale, it is also makes it possible to navigate the material from a qualitative\n",
    "point-of-view. Zooming in on the issue of modernity, for example, it is\n",
    "feasible to use keyword search to find newsreels on distinct topics\n",
    "<cite id=\"8jann\"><a href=\"#zotero%7C22783102%2FKADI4AFW\">(Armaselu and Fickers 2024)</a></cite>.\n",
    "For instance, searching for the word \"moderna\" results in \n",
    "[66 hits](https://modern36.github.io/jdc_reader/#q=moderna&type=intertitle){:target=\"_blank\"} \n",
    "and \"modern\" in\n",
    "[146 hits](https://modern36.github.io/jdc_reader/#q=modern&type=intertitle){:target=\"_blank\"}.\n",
    "This allows one to detect specific newsreels with modern aspects of Swedish\n",
    "society, prevalent mostly during the 1920s and 1930s, with urban renewal\n",
    "projects, progressive social and employment reforms, and women gaining the\n",
    "right to vote\n",
    "(<cite id=\"7hx24\"><a href=\"#zotero%7C22783102%2F6VFT9YB8\">(Widenheim 2002)</a></cite>,\n",
    "<cite id=\"er18t\"><a href=\"#zotero%7C22783102%2F2X3XHIU7\">(Habel 2002)</a></cite>).\n",
    "Some parts of the intertitle dataset naturally mirror prior metadata. Yet, our\n",
    "corpus of intertitles (with .srt-files) also allows you to find the exact\n",
    "filmic moment (via time stamps) when an intertitle appears—which, furthermore,\n",
    "holds true for all transcribed speech—making it possible to navigate the\n",
    "audiovisual material in new ways. Given our interest in issues around Swedish\n",
    "modernity, a search for _modern_ in the intertitle dataset, gives a vivid\n",
    "result of films—from a 1920s newsreel on defence exercise including \"modern\n",
    "artillery weapons\" (SF488B), and another newsreel item about a novel (and\n",
    "modern) fish market in the Stockholm Old Town (SF460.1), to a newsreel insert\n",
    "about state-of-art telephones in 1926 (SF519.1), the same year that the Swedish\n",
    "inventor Lars Magnusson Ericsson celebrated his 80th birthday (sadly he passed\n",
    "away later the same year). In this way, the intertitle dataset—gleaned from the\n",
    "Journal Digital corpus—indeed makes it possible to easily shift from\n",
    "large-scale text mining, to close qualitative analysis of particular newsreels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-telephone-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/img10.png\", width=1000),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-telephone-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          '\"The difference between the first telephone ... and the '\n",
    "          'modern table telephone is of significance\\\", the '\n",
    "          \"_SF's Weekly Review_ \"\n",
    "          \"(10 May 1926) stated. Via search through the \"\n",
    "          \"intertitle dataset of the Journal Digital collection, it \"\n",
    "          \"is possible to detect films, or sections of newsreels, \"\n",
    "          \"otherwise hard to find—in this case using the search \"\n",
    "          \"phrase moderna.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "sec-geo"
    ]
   },
   "source": [
    "## Scalable Geographic Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "2xlle": [
       {
        "id": "22783102/89SWX3HE",
        "source": "zotero"
       }
      ],
      "5cysi": [
       {
        "id": "22783102/5U2K4DR4",
        "source": "zotero"
       }
      ],
      "8zu0n": [
       {
        "id": "22783102/AGCZGSA8",
        "source": "zotero"
       }
      ],
      "rlzkj": [
       {
        "id": "22783102/5LZCK9F3",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Since all newsreel production at Swedish Film Industry was headquartered in\n",
    "Stockholm—did this urban location dictate which parts of Sweden that appeared\n",
    "on cinema screens across the country? Which places were depicted, and how were\n",
    "they represented? Did the _SF Weekly Review_ favour certain locations? Was there\n",
    "an urban gaze framing modernity via the provincial, the rural, or the remote?\n",
    "Such geographic questions of representation have prior been difficult to answer\n",
    "in a systematic way. While individual newsreels can be analysed, the sheer\n",
    "volume of filmic material within the SF-archive—decades of weekly or bi-weekly\n",
    "releases–has made corpus-level inquiry impractical. However, with the\n",
    "introduction of the Journal Digital Corpus, it is possible to analyse filmic\n",
    "geographies of scale. If we previously described how signal archaeology was\n",
    "used to analyse the Digital Journal collection via AST, \n",
    "and how we subsequently used the\n",
    "tool `stum` to create a corpus from newsreel intertitles, we\n",
    "created another tool for transcribing the speech in newsreels. \n",
    "SweScribe \n",
    "<cite id=\"5cysi\"><a href=\"#zotero%7C22783102%2F5U2K4DR4\">(Aspenskog and Johansson 2025)</a></cite>\n",
    "uses _WhisperX_\n",
    "<cite id=\"2xlle\"><a href=\"#zotero%7C22783102%2F89SWX3HE\">(Bain et al. 2023)</a></cite>,\n",
    "to combine a Whisper model from OpenAI with a _wav2vec2_ model, fine-tuned for\n",
    "Swedish\n",
    "<cite id=\"8zu0n\"><a href=\"#zotero%7C22783102%2FAGCZGSA8\">(Malmsten, Haffenden, and Börjeson 2022)</a></cite>\n",
    ", to transcribe and temporally align speech.\n",
    "Feeding SweScribe 2,544 newsreels containing speech\n",
    "we created a corpus comprising 2,225,334 words \n",
    "<cite id=\"rlzkj\"><a href=\"#zotero%7C22783102%2F5LZCK9F3\">(Aspenskog, Johansson, and Snickars 2025)</a></cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "qdv2n": [
       {
        "id": "22783102/5LZCK9F3",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics",
     "anchor-pipe-swescribe"
    ]
   },
   "source": [
    "### Converting Speech to Subtitles [ del ]\n",
    "\n",
    "It should be noted that early testing revealed weaknesses: SweScribe struggled\n",
    "with noisy environments and overlapping speakers, and tended to hallucinate\n",
    "plausible but often incorrect content when speech was unintelligible. The model\n",
    "also produces artefacts likely leaked from training data, such as subtitle\n",
    "credits. We addressed these through iterative cleaning steps, expanding our\n",
    "ground truth dataset from 27 to 89 manual transcriptions (72,812 words) across\n",
    "three sampling rounds, which considerably reduced Word Error Rate (WER) from 17\n",
    "percent to only seven percent\n",
    "<cite id=\"qdv2n\"><a href=\"#zotero%7C22783102%2F5LZCK9F3\">(Aspenskog, Johansson, and Snickars 2025)</a></cite>.\n",
    "SweScribe works in the following 4 steps:\n",
    "(1.) Extract the audio stream from the file;\n",
    "(2.) Transcribing the audio with WhisperX;\n",
    "(3.) Aligning the transcription with the audio, to create timestamps, with WhisperX and a wav2vec2 model;\n",
    "(4.) Clean up and removing known mistakes.\n",
    "The key contribution of SweScribe lies in the fourth step. Through iterations of\n",
    "tests and cleaning we have found many (but likely not all) the ways in which\n",
    "Whisper hallucinates in the transcriptions. Some errors are very simple to\n",
    "detect, such as URLs. Other's are more subtle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "# .src/swescribe/mpg_to_wav.py\n",
    "\n",
    "\n",
    "# 1. Extract audio\n",
    "def extract_audio(mpg_file_path: Path, wav_file_path: Path):\n",
    "  logging.debug(f\"Starting extraction for: {mpg_file_path.name}\")\n",
    "\n",
    "  if not mpg_file_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "      f\"The file {mpg_file_path} does not exist.\"\n",
    "    )\n",
    "  elif not wav_file_path.parent.exists():\n",
    "    raise FileNotFoundError(\n",
    "      f\"The ouput directory {wav_file_path.parent} does not exist.\"\n",
    "    )\n",
    "\n",
    "  # Use ffmpeg to extract audio, targeting a sample rate of 16kHz and a single channel (mono)\n",
    "  command = [\n",
    "    \"ffmpeg\",\n",
    "    \"-y\",  # Overwrite output files without asking\n",
    "    \"-i\",\n",
    "    str(mpg_file_path),  # Input file\n",
    "    \"-ar\",\n",
    "    \"16000\",  # Set audio sample rate to 16kHz\n",
    "    \"-ac\",\n",
    "    \"1\",  # Set audio channels to mono\n",
    "    str(wav_file_path),\n",
    "  ]\n",
    "\n",
    "  subprocess.run(\n",
    "    command,\n",
    "    check=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "  )\n",
    "  logging.debug(f\"Successfully extracted audio to: {wav_file_path}\\n\")\n",
    "\n",
    "\n",
    "# .src/swescribe/wavpath_to_srt.py\n",
    "\n",
    "\n",
    "def wavpath_to_srt(audio_file_path: Path):\n",
    "  \"\"\"Reads WAV file and generates a subtitle file in SRT format.\n",
    "\n",
    "  Args:\n",
    "      audio_file_path (Path): The path to the WAV file.\n",
    "\n",
    "  Returns:\n",
    "      str: The formatted SRT content.\n",
    "  \"\"\"\n",
    "  # 2. Transcribing audio\n",
    "  transcription_result = model_transcribe(audio_file_path)\n",
    "\n",
    "  # 3. Align results\n",
    "  aligned_result = align_results(\n",
    "    audio_file_path, transcription_result\n",
    "  )\n",
    "\n",
    "  # 4. Cleaning\n",
    "  srt_content = alignment_to_srt(aligned_result)\n",
    "  return srt_content\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ".src/swescribe/transcribe.py\n",
    "\n",
    "model = whisperx.load_model(\n",
    "    \"large\",\n",
    "    device,\n",
    "    language=language_code,\n",
    "    asr_options={\n",
    "        \"multilingual\": False,\n",
    "        \"max_new_tokens\": None,\n",
    "        \"clip_timestamps\": None,\n",
    "        \"hallucination_silence_threshold\": None,\n",
    "        \"hotwords\": None,\n",
    "    },\n",
    ")\n",
    "\n",
    "alignment_model, metadata = whisperx.load_align_model(\n",
    "    language_code=language_code,\n",
    "    device=device,\n",
    "    model_name=\"KBLab/wav2vec2-large-voxrex-swedish\",\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 2. Transcribing audio\n",
    "def model_transcribe(audio_file_path):\n",
    "  return model.transcribe(str(audio_file_path))\n",
    "\n",
    "\n",
    "# 3. Align results\n",
    "def align_results(audio_file_path, transcription_result):\n",
    "  return whisperx.align(\n",
    "    transcription_result[\"segments\"],\n",
    "    alignment_model,\n",
    "    metadata,\n",
    "    str(audio_file_path),\n",
    "    device,\n",
    "    preprocess=False,\n",
    "  )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ".src/swescribe/alignment_to_srt.py\n",
    "\n",
    "from swescribe.clean_whisper import clean_text\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def format_timestamp(seconds):\n",
    "  \"\"\"Create srt-compliant timestamp\n",
    "\n",
    "  Args:\n",
    "      seconds (float): The time in seconds, with milisecond precision\n",
    "\n",
    "  Returns:\n",
    "      str: The formatted timestamp\n",
    "  \"\"\"\n",
    "  hours = int(seconds // 3600)\n",
    "  minutes = int((seconds % 3600) // 60)\n",
    "  secs = int(seconds % 60)\n",
    "  milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "  return f\"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}\"\n",
    "\n",
    "\n",
    "def cleaned_segments(\n",
    "  segments,\n",
    "):\n",
    "  for segment in segments:\n",
    "    text = clean_text(segment[\"text\"].strip())\n",
    "\n",
    "    if not text:\n",
    "      logging.debug(f\"Skipping empty segment {segment=}\")\n",
    "      continue\n",
    "\n",
    "    yield {\n",
    "      \"start\": format_timestamp(segment[\"start\"]),\n",
    "      \"end\": format_timestamp(segment[\"end\"]),\n",
    "      \"text\": text,\n",
    "    }\n",
    "\n",
    "\n",
    "def alignment_to_srt(aligned_result):\n",
    "  \"\"\"Convert aligned result to SRT format.\n",
    "\n",
    "  Args:\n",
    "      aligned_result List of (dict): The aligned result from the Whisperx library.\n",
    "\n",
    "  Returns:\n",
    "      str: The formatted SRT content.\n",
    "  \"\"\"\n",
    "  srt_content = \"\"\n",
    "  for idx, segment in enumerate(\n",
    "    cleaned_segments(aligned_result[\"segments\"]), start=1\n",
    "  ):\n",
    "    srt_content += (\n",
    "      f\"{idx}\\n{segment['start']} --> {segment['end']}\\n\"\n",
    "      f\"{segment['text']}\\n\\n\")\n",
    "\n",
    "  return srt_content\n",
    "\n",
    "\n",
    "# .src/swescribe/clean_whisper.py\n",
    "\n",
    "\n",
    "# 4. Cleaning steps\n",
    "def clean_text(text):\n",
    "  result = text[:].strip()\n",
    "  for function in (\n",
    "    clean_elipsis,\n",
    "    clean_dashes,\n",
    "    clean_for,\n",
    "    clean_line_artefact,\n",
    "    clean_ja_repeat,\n",
    "    clean_urls,\n",
    "    clean_spaces,\n",
    "  ):\n",
    "    if result == \"\":\n",
    "      break\n",
    "    result = function(result)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "4siug": [
       {
        "id": "22783102/8XFJBPEC",
        "source": "zotero"
       }
      ],
      "bpz4r": [
       {
        "id": "22783102/WEZNWR96",
        "source": "zotero"
       }
      ],
      "f3beh": [
       {
        "id": "22783102/SSCKKMRE",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This transmediation enabled us to model a range of \n",
    "distant reading \n",
    "<cite id=\"f3beh\"><a href=\"#zotero%7C22783102%2FSSCKKMRE\">(Moretti 2000)</a></cite>\n",
    "and scalable reading \n",
    "approaches that switch between micro and macro level analyses \n",
    "(<cite id=\"4siug\"><a href=\"#zotero%7C22783102%2F8XFJBPEC\">(Weitin 2017)</a></cite>, \n",
    "<cite id=\"bpz4r\"><a href=\"#zotero%7C22783102%2FWEZNWR96\">(Fickers and Clavert 2021)</a></cite>).\n",
    "Our NER-based distant reading reveal broad patterns in \n",
    "the geographical distribution across the corpus. \n",
    "Most striking, albeit predictable, is the dominance of Stockholm, which \n",
    "remains the most frequently mentioned location throughout the entire period. \n",
    "Beyond the capital, Västergötland and Skåneform a consistent second tier, \n",
    "though at a considerable distance from Stockholm.\n",
    "This finding is also predictable, as these two regions contain Göteborg and Malmö, \n",
    "respectively, which are Sweden's second and third largest cities.\n",
    "Together, these three metropolitan regions account for a \n",
    "disproportionate share of all domestic geographic references. \n",
    "By contrast, the majority of regions appear only \n",
    "sporadically, often with single digit mentions per year, or remaining \n",
    "entirely absent for long stretches of time. At the same time, the aggregated \n",
    "category Foreign—which groups all non-Swedish locations—frequently rivals or \n",
    "exceeds individual domestic regions in yearly mentions. Although not an actual \n",
    "region, the Foreign category is analytically revealing, as it indicates the \n",
    "relative weight SF ascribed to international events in its newsreel coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This uneven geographic coverage was remarkably stable, but not quite static.\n",
    "The 1930s were characterised by pronounced volatility: alongside Stockholm’s \n",
    "steady prominence, several peripheral regions briefly move into visibility, \n",
    "producing sharp but short-lived peaks rather than sustained attention. \n",
    "This pattern is particularly evident in the mid 1930s, when regions such as \n",
    "Lappland, Dalarna, and Gotland momentarily gained prominence before receding \n",
    "again. By contrast, the 1950s exhibit \n",
    "a more consolidated structure: while \n",
    "Stockholm remains dominant, the overall number of regions entering the top \n",
    "rankings decreases, and geographic attention becomes more concentrated around \n",
    "the established metropolitan core with fewer peripheral spikes. Across both \n",
    "decades, however, the same structural hierarchy persists: a dominant capital \n",
    "region, two secondary metropolitan regions with intermittent prominence, and a \n",
    "broad set of other regions enter the newsreel discourse only episodically. \n",
    "Alongside this domestic hierarchy, foreign locations remained consistently \n",
    "prominent, often rivaling or surpassing Swedish regions in yearly mentions. \n",
    "This macroscopic perspective, made possible through NER-based distant reading, \n",
    "provides a necessary baseline against which the following closer readings can \n",
    "examine how and why particular regions were framed as meaningful within the newsreel discourse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-jdc-map-*"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hosting a local and embedding a local instance of\n",
    "Journal Digital Corpus Map, https://modern36.github.io/jdc-map/\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def mk_map():\n",
    "  if local:\n",
    "    return Image(\"./media/jdc-map.png\")\n",
    "  dist = data / \"dist\"\n",
    "  map_widget_port = 8822\n",
    "\n",
    "  # Custom handler to serve from dist/\n",
    "  class SilentHandler(http.server.SimpleHTTPRequestHandler):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "      super().__init__(*args, directory=str(dist.resolve()), **kwargs)\n",
    "\n",
    "    def log_message(self, format, *args):\n",
    "      pass  # Suppress server logs\n",
    "\n",
    "  # Function to run server\n",
    "  def run_server():\n",
    "    with socketserver.TCPServer(\n",
    "      (\"\", map_widget_port), SilentHandler\n",
    "    ) as httpd:\n",
    "      httpd.serve_forever()\n",
    "\n",
    "  # Start server in background thread\n",
    "  server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "  server_thread.start()\n",
    "\n",
    "  # Wait for server to start\n",
    "  time.sleep(1)\n",
    "  return IFrame(\n",
    "    src=f\"http://localhost:{map_widget_port}\",\n",
    "    width=\"1000\",\n",
    "    height=\"900\",\n",
    "  )\n",
    "\n",
    "\n",
    "display(\n",
    "  mk_map(),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-jdc-map-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"A mapping of mentioned locations in the Journal Digital\"\n",
    "          \"Corpus (red). \"\n",
    "          'The [live version](https://modern36.github.io/jdc-map/){:target=\"_blank\"} '\n",
    "          'also allows for a mapping of the SAB codes '\n",
    "          '[visit](https://modern36.github.io/jdc-map/){:target=\"_blank\"}.'\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In this article precursory examples have stressed different ways to address\n",
    "modernity via newsreel representation. SweScribe can be used in a similar way,\n",
    "and in the following we will showcase an analysis of various relations between\n",
    "the provincial and the urban in Swedish newsreels during a period of immense\n",
    "modernisation. One way is to examine the general division between the Stockholm\n",
    "region on one hand, and mentions of other Swedish regions on the other. We have\n",
    "been primarily interested in the urban gaze of the provincial, hence we pay\n",
    "particular attention to regions in the south and west of Sweden, situated near\n",
    "the second largest cities respectively, Gothenburg and Malmö. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "fjeyv": [
       {
        "id": "22783102/X4KI9JPL",
        "source": "zotero"
       }
      ],
      "s9wnk": [
       {
        "id": "22783102/BPGKCGSS",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "### From Text to Maps [ del ] \n",
    "\n",
    "Named Entity Recognition is a forceful NLP-technique, but it usually \n",
    "requires extensive data cleaning and processing before the output becomes useful.\n",
    "In our case, we applied a Swedish, BERT-based NER model trained\n",
    "<cite id=\"s9wnk\"><a href=\"#zotero%7C22783102%2FBPGKCGSS\">(KB Labb 2022)</a></cite>\n",
    "to extract all locations mentioned in the Journal Digital Corpus.\n",
    "The raw extracted entities were often split up into parts: such as\n",
    "“Gustav Adolfs torg” split into “Gustav” + “Adolfs” + “torg”.\n",
    "Consequently, before we could to get reliable geocoding, we had to re-assemble, clean and filter\n",
    "these location.\n",
    "In the next step, we reduced the list of locations to those that could reasonably \n",
    "be expected to be geolocated by filtering out discovered errors, and normalize \n",
    "spellings of known spelling variations. We kept entities BERT extracted\n",
    "with a high confidence score. Remaining locations were then compared to GeoNames,\n",
    "an open-sourced gazetteer, which contains a near exhaustive list of Swedish \n",
    "location names and alternate names. \n",
    "<cite id=\"fjeyv\"><a href=\"#zotero%7C22783102%2FX4KI9JPL\">(GeoNames 2025)</a></cite>.\n",
    "We supplemented this list with a manually crafted set of occuring\n",
    "international locations that the list might miss, and then we compare each unique\n",
    "location name to these lists in a series of fuzzy string matching. Locations not\n",
    "captured were discarded. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "aefja": [
       {
        "id": "22783102/PEB6LVXU",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "The resulting list of locations were used for two purposes: firstly, to\n",
    "automatically geocode all mentioned Swedish locations. Secondly, to manually\n",
    "geolocate and connect locations to regions, and compare Swedish versus foreign\n",
    "locations. For geocoding we set up Nominatim seeded with Sweden [locally](https://github.com/mediagis/nominatim-docker/blob/master/howto.md#persistent-container-data){:target=\"_blank\"} \n",
    "; this allowed us to query persistently without\n",
    "rate limits. We queried Nominatim once for each unique location, and stored results for\n",
    "later review and comparison. Many of the locations in our list were\n",
    "generic. Unfortunately, Nominatim does not always produce the correct location\n",
    "as the top results. Hence, we asked for five results, and applied a few simple\n",
    "automated steps to help make the process quicker, followed up by a manual\n",
    "review of suggestions. When there was but a single result, it was picked as\n",
    "the correct geocoding of the location. We also checked for common patterns.\n",
    "When there were multiple results, we measured the distance between their\n",
    "central coordinates; if the longest distance was <= 5km, we picked the first\n",
    "results. The rest were resolved with a manual review of the suggestions.\n",
    "Resulgting in geocoded metadata for Journal Digital Corpus\n",
    "<cite id=\"aefja\"><a href=\"#zotero%7C22783102%2FPEB6LVXU\">(Johansson and Askepskog 2026)</a></cite>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Named Entity Recognition\n",
    "\n",
    "./src/journal_NER/preprocessing/extract_entities.py\n",
    "\n",
    "from transformers import pipeline\n",
    "from journal_digital import Corpus\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def NER_main():\n",
    "  # 1. Load NER model\n",
    "  nlp = pipeline(\n",
    "    \"ner\",\n",
    "    model=\"KB/bert-base-swedish-cased-ner\",\n",
    "    tokenizer=\"KB/bert-base-swedish-cased-ner\",\n",
    "    device=\"cuda:1\",\n",
    "  )\n",
    "\n",
    "  corpus = Corpus(\"txt\", texts_to_include=\"speech\")\n",
    "\n",
    "  for srt in tqdm(corpus):\n",
    "    file = srt.filename\n",
    "    text = srt.content\n",
    "    year = srt.year\n",
    "    out_file = out_dir / srt.path.with_suffix(\".json\").name\n",
    "\n",
    "    if out_file.exists():\n",
    "      continue\n",
    "\n",
    "    lines = split_pattern.split(text)\n",
    "    results = {\n",
    "      \"year\": year,\n",
    "      \"video_name\": file,\n",
    "      \"entities\": [\n",
    "        # 1. Apply NER model on every line of the transcript\n",
    "        outputs_to_json_friendly(nlp(line)) for line in lines\n",
    "      ],\n",
    "    }\n",
    "\n",
    "    # 2. Store a transcription level nested JSON file\n",
    "    with open(out_file, \"x\") as f:\n",
    "      json.dump(results, f, indent=1)\n",
    "\n",
    "\n",
    "def outputs_to_json_friendly(data: list[dict]):\n",
    "  return [output_to_json_friendly(small_dict) for small_dict in data]\n",
    "\n",
    "\n",
    "def output_to_json_friendly(small_dict):\n",
    "  return {\n",
    "    \"entity\": small_dict[\"entity\"],\n",
    "    \"score\": float(small_dict[\"score\"]),\n",
    "    \"index\": small_dict[\"index\"],\n",
    "    \"word\": small_dict[\"word\"],\n",
    "    \"start\": small_dict[\"start\"],\n",
    "    \"end\": small_dict[\"end\"],\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reconstructing locations\n",
    "\n",
    "./src/journal_NER/preprocessing/step2_clean_locations.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def reconstruct_locations(entities):\n",
    "  \"\"\"\n",
    "  Reconstruct locations by grouping entities using the grp field.\n",
    "\n",
    "  The grp field is assigned by group_entities() in load_entities_to_db\n",
    "  and indicates which entities should be merged based on adjacency.\n",
    "\n",
    "  This function:\n",
    "  1. Groups entities by their grp field\n",
    "  2. Merges all words within each group (handling ## fragments)\n",
    "  3. Returns list of reconstructed location names\n",
    "\n",
    "  Args:\n",
    "      entities: List of (word, entity_type, score, entry_index, start,\n",
    "          end, srt_idx, grp, year) tuples\n",
    "\n",
    "  Returns:\n",
    "      List of cleaned location strings\n",
    "  \"\"\"\n",
    "  if not entities:\n",
    "    return []\n",
    "\n",
    "  from collections import defaultdict\n",
    "\n",
    "  # Group entities by grp field\n",
    "  groups = defaultdict(list)\n",
    "  for entity in entities:\n",
    "    word, _, _, _, _, _, _, grp, _ = entity\n",
    "    groups[grp].append(word)\n",
    "\n",
    "  locations = []\n",
    "  for grp_id, words in groups.items():\n",
    "    # Merge ## fragments and join words\n",
    "    merged = []\n",
    "    for word in words:\n",
    "      if word.startswith(\"##\"):\n",
    "        if merged:\n",
    "          # Merge with previous word (remove ##)\n",
    "          merged[-1] += word[2:]\n",
    "        # else: skip standalone ##\n",
    "      else:\n",
    "        merged.append(word)\n",
    "\n",
    "    # Join with spaces and title-case\n",
    "    if merged:\n",
    "      location = \" \".join(merged).strip().title()\n",
    "      locations.append(location)\n",
    "\n",
    "  return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filtering Locations\n",
    "\n",
    ".src/journal_NER/preprocessing/step3_filter_gazetteer.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Verification\n",
    "def verify_locations(session):\n",
    "  \"\"\"\n",
    "  Verify locations from clean_entity table against gazetteer.\n",
    "\n",
    "  Process:\n",
    "  1. Check if location has high-confidence score → keep as-is\n",
    "  2. Check if location exactly matches gazetteer → keep as-is\n",
    "  3. Try fuzzy matching → if match >= threshold, use canonical name\n",
    "  4. Otherwise → discard\n",
    "\n",
    "  Args:\n",
    "      session: SQLModel session\n",
    "      gazetteer: Set of known place names\n",
    "\n",
    "  Returns:\n",
    "      List of (video_name, verified_location, year, mentions) tuples\n",
    "  \"\"\"\n",
    "  from journal_NER.models import CleanEntity\n",
    "\n",
    "  # Construct set of spellings and mapping to 'correct' spelling\n",
    "  gazetteer, gazetteer_normalizer = make_gazzeteer_and_normalizer()\n",
    "\n",
    "  # Get all locations from clean_entity using SQLModel\n",
    "  results = (\n",
    "    session.query(\n",
    "      CleanEntity.video_name,\n",
    "      CleanEntity.location,\n",
    "      CleanEntity.year,\n",
    "      CleanEntity.mentions,\n",
    "    )\n",
    "    .order_by(CleanEntity.location)\n",
    "    .all()\n",
    "  )\n",
    "\n",
    "  all_entries = results\n",
    "\n",
    "  # Get high-confidence words\n",
    "  high_conf_words = get_high_confidence_locations(session)\n",
    "\n",
    "  verified = []\n",
    "  exact_matches = 0\n",
    "  fuzzy_matches = 0\n",
    "  high_conf_matches = 0\n",
    "  rejected = 0\n",
    "  blacklisted = 0\n",
    "  normalized = 0\n",
    "\n",
    "  location_stats = defaultdict(\n",
    "    lambda: {\n",
    "      \"exact\": 0,\n",
    "      \"fuzzy\": 0,\n",
    "      \"high_conf\": 0,\n",
    "      \"rejected\": 0,\n",
    "      \"blacklisted\": 0,\n",
    "      \"normalized\": 0,\n",
    "    }\n",
    "  )\n",
    "\n",
    "  for video_name, location, year, mentions in tqdm(\n",
    "    all_entries, desc=\"Processing high-confidence locations.\"\n",
    "  ):\n",
    "    verified_location = None\n",
    "    match_type = None\n",
    "\n",
    "    # 1. Check blacklist first\n",
    "    if location in constants.GAZETTEER_BLACKLIST:\n",
    "      match_type = \"blacklisted\"\n",
    "      blacklisted += 1\n",
    "      location_stats[location][match_type] += 1\n",
    "      continue\n",
    "\n",
    "    # 2. Apply normalization\n",
    "    if location in constants.LOCATION_NORMALIZE:\n",
    "      normalized_loc = constants.LOCATION_NORMALIZE[location]\n",
    "      location = normalized_loc\n",
    "      normalized += 1\n",
    "\n",
    "    # 3. High confidence from original NER\n",
    "    if location in high_conf_words:\n",
    "      verified_location = location\n",
    "      match_type = \"high_conf\"\n",
    "      high_conf_matches += 1\n",
    "\n",
    "    # 5. Exact match in gazetteer\n",
    "    elif location in gazetteer:\n",
    "      verified_location = location\n",
    "      match_type = \"exact\"\n",
    "      exact_matches += 1\n",
    "\n",
    "    # 5. Map against known, clear aliases:\n",
    "    elif location in gazetteer:\n",
    "      verified_location = gazetteer_normalizer[location]\n",
    "      match_type = \"normalized\"\n",
    "\n",
    "    # 6. Fuzzy match\n",
    "    else:\n",
    "      matched_name, score = fuzzy_match_location(location, gazetteer)\n",
    "      if matched_name:\n",
    "        verified_location = matched_name  # Use canonical form\n",
    "        match_type = \"fuzzy\"\n",
    "        fuzzy_matches += 1\n",
    "      else:\n",
    "        matched_name, score = fuzzy_match_location(\n",
    "          location, gazetteer_normalizer.keys()\n",
    "        )\n",
    "        if matched_name:\n",
    "          verified_location = gazetteer_normalizer[matched_name]\n",
    "          match_type = \"fuzzy\"\n",
    "          fuzzy_matches += 1\n",
    "\n",
    "        else:\n",
    "          match_type = \"rejected\"\n",
    "          rejected += 1\n",
    "\n",
    "    if verified_location:\n",
    "      verified.append((video_name, verified_location, year, mentions))\n",
    "\n",
    "    location_stats[location][match_type] += 1\n",
    "\n",
    "  return verified, location_stats\n",
    "\n",
    "\n",
    "# 4. Gather gazetteer data\n",
    "def make_gazzeteer_and_normalizer():\n",
    "  tmp_normalizer = defaultdict(set)\n",
    "  canons = constants.GAZETTEER_INTERNATIONAL_PLACES\n",
    "\n",
    "  # 4.1 Load Geonames data\n",
    "  for spelling, canon in load_geonames_variants():\n",
    "    canons.add(canon)\n",
    "    if spelling is not None:\n",
    "      tmp_normalizer[spelling].add(canon)\n",
    "\n",
    "  result = {}\n",
    "  for spelling, canon_set in tmp_normalizer.items():\n",
    "    if spelling in constants.LOCATION_NORMALIZE:\n",
    "      continue\n",
    "    if len(canon_set) == 0:\n",
    "      raise ValueError(f\"Empty canon_set for {spelling}\")\n",
    "    elif len(canon_set) == 1:\n",
    "      result[spelling] = list(canon_set)[0]\n",
    "  return canons, result\n",
    "\n",
    "\n",
    "# 4.1 Load Geonames data\n",
    "def load_geonames_variants():\n",
    "  with open(geonames_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "      fields = line.strip().split(\"\\t\")\n",
    "      if len(fields) < 4:\n",
    "        continue\n",
    "\n",
    "      # Add primary name\n",
    "      name = fields[1].strip()\n",
    "      yield None, name\n",
    "\n",
    "      # Add ASCII name if different\n",
    "      asciiname = fields[2].strip()\n",
    "      if asciiname and asciiname != name:\n",
    "        yield asciiname, name\n",
    "\n",
    "      # Add alternate names\n",
    "      alternates = fields[3].strip()\n",
    "      if alternates:\n",
    "        for alt in alternates.split(\",\"):\n",
    "          alt = alt.strip()\n",
    "          if alt:\n",
    "            yield alt, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Geocoding\n",
    "\n",
    ".src/journal_NER/geocode/geocode_locations.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 1. Query nominatim\n",
    "def geocode_location(location_name, session, limit=5):\n",
    "  \"\"\"\n",
    "  Geocode a location using local Nominatim server.\n",
    "\n",
    "  Queries Nominatim and stores top results in GeocodeCandidate table.\n",
    "\n",
    "  Args:\n",
    "      location_name: Name to geocode\n",
    "      session: SQLModel session for database operations\n",
    "      limit: Maximum number of results to retrieve (default: 5)\n",
    "\n",
    "  Returns:\n",
    "      List of GeocodeCandidate objects (empty if no results)\n",
    "  \"\"\"\n",
    "  url = (\n",
    "    f\"{constants.NOMINATIM_BASE_URL}/search.php?q={location_name}\"\n",
    "    f\"&format=json&limit={limit}\")\n",
    "\n",
    "  try:\n",
    "    response = requests.get(\n",
    "      url, timeout=constants.NOMINATIM_TIMEOUT_SECONDS\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    results = response.json()\n",
    "\n",
    "    if not results:\n",
    "      logger.warning(f\"No geocoding results for: {location_name}\")\n",
    "      return []\n",
    "\n",
    "    candidates = []\n",
    "    for rank, result in enumerate(results):\n",
    "      # Extract bounding box if present\n",
    "      bbox_min_lat = None\n",
    "      bbox_max_lat = None\n",
    "      bbox_min_lon = None\n",
    "      bbox_max_lon = None\n",
    "\n",
    "      if \"boundingbox\" in result and len(result[\"boundingbox\"]) == 4:\n",
    "        bbox_min_lat = float(result[\"boundingbox\"][0])\n",
    "        bbox_max_lat = float(result[\"boundingbox\"][1])\n",
    "        bbox_min_lon = float(result[\"boundingbox\"][2])\n",
    "        bbox_max_lon = float(result[\"boundingbox\"][3])\n",
    "\n",
    "      candidate = GeocodeCandidate(\n",
    "        location_name=location_name,\n",
    "        place_id=result.get(\n",
    "          \"place_id\", 0\n",
    "        ),  # Some responses lack place_id\n",
    "        osm_type=result.get(\n",
    "          \"osm_type\", result.get(\"class\", \"\")\n",
    "        ),  # Fallback to class\n",
    "        osm_id=result.get(\"osm_id\", 0),  # Some responses lack osm_id\n",
    "        display_name=result.get(\n",
    "          \"display_name\", result.get(\"name\", location_name)\n",
    "        ),\n",
    "        place_rank=result.get(\"place_rank\", 0),\n",
    "        category=result.get(\n",
    "          \"category\", result.get(\"class\", \"\")\n",
    "        ),  # Fallback to class\n",
    "        type=result.get(\"type\", \"\"),\n",
    "        importance=result.get(\"importance\", 0.0),\n",
    "        lat=float(result[\"lat\"]),\n",
    "        lon=float(result[\"lon\"]),\n",
    "        boundingbox_lat_min=bbox_min_lat,\n",
    "        boundingbox_lat_max=bbox_max_lat,\n",
    "        boundingbox_lon_min=bbox_min_lon,\n",
    "        boundingbox_lon_max=bbox_max_lon,\n",
    "        raw_json=json.dumps(result),\n",
    "        result_rank=rank,\n",
    "      )\n",
    "      session.add(candidate)\n",
    "      candidates.append(candidate)\n",
    "\n",
    "    session.commit()\n",
    "    logger.info(\n",
    "      f\"Geocoded '{location_name}': {len(candidates)} candidates\"\n",
    "    )\n",
    "    return candidates\n",
    "\n",
    "  except requests.RequestException as e:\n",
    "    logger.error(f\"Nominatim request failed for {location_name}: {e}\")\n",
    "    return []\n",
    "  except (KeyError, ValueError, TypeError) as e:\n",
    "    logger.error(\n",
    "      f\"Error parsing Nominatim response for {location_name}: {e}\"\n",
    "    )\n",
    "    return []\n",
    "\n",
    "\n",
    "# 5. Common patterns\n",
    "def auto_select_swedish_location(query_name, candidates):\n",
    "  \"\"\"\n",
    "  Apply Swedish-specific rules to auto-select the correct candidate.\n",
    "\n",
    "  Priority order:\n",
    "  1. Result starting with \"query_name(s)?, query_name(s)? kommun\"\n",
    "  2. Result starting with \"query_name(s)? kommun\"\n",
    "  3. Result starting with \"Landskapet query_name(s)?\"\n",
    "\n",
    "  Possessives are handled: optional 's' at end of query_name.\n",
    "  If multiple candidates match the same rule, checks distance between\n",
    "  them.\n",
    "  Only auto-selects if all matches are within the distance threshold.\n",
    "\n",
    "  All comparisons are case-insensitive using regex.\n",
    "\n",
    "  Args:\n",
    "      query_name: The original location name being queried\n",
    "      candidates: List of candidate results from Nominatim\n",
    "\n",
    "  Returns:\n",
    "      Selected candidate if a rule matches and distance check passes,\n",
    "      None otherwise\n",
    "  \"\"\"\n",
    "  if not candidates:\n",
    "    return None\n",
    "\n",
    "  # Escape query_name for regex, make case-insensitive\n",
    "  query_escaped = re.escape(query_name.lower())\n",
    "\n",
    "  # 6. City/town pattern\n",
    "  pattern1 = re.compile(\n",
    "    rf\"^{query_escaped}(s)?,\\s*{query_escaped}(s)?\\s+kommun\",\n",
    "    re.IGNORECASE,\n",
    "  )\n",
    "  matches = [\n",
    "    c for c in candidates if pattern1.match(c.display_name.lower())\n",
    "  ]\n",
    "  if matches:\n",
    "    if len(matches) == 1:\n",
    "      logger.info(\n",
    "        f\"  → Auto-selected (Rule 1: '{query_name}(s)?, {query_name}\"\n",
    "        f\"(s)? kommun'): {matches[0].display_name}\"\n",
    "      )\n",
    "      return matches[0]\n",
    "    else:\n",
    "      # 9. Multiple matches - check distance\n",
    "      max_dist = calculate_max_distance(matches)\n",
    "      if max_dist <= constants.GEOCODE_DISTANCE_THRESHOLD_KM:\n",
    "        logger.info(\n",
    "          f\"  → Auto-selected (Rule 1: '{query_name}(s)?, \"\n",
    "          f\"{query_name}(s)? kommun', {len(matches)} within \"\n",
    "          f\"{max_dist:.1f}km): {matches[0].display_name}\"\n",
    "        )\n",
    "        return matches[0]\n",
    "      # Distance too high, try next rule\n",
    "\n",
    "  # 7. Municipality pattern\n",
    "  pattern2 = re.compile(\n",
    "    rf\"^{query_escaped}(s)?\\s+kommun\", re.IGNORECASE\n",
    "  )\n",
    "  matches = [\n",
    "    c for c in candidates if pattern2.match(c.display_name.lower())\n",
    "  ]\n",
    "  if matches:\n",
    "    if len(matches) == 1:\n",
    "      logger.info(\n",
    "        f\"  → Auto-selected (Rule 2: '{query_name}(s)? kommun'): \"\n",
    "        f\"{matches[0].display_name}\"\n",
    "      )\n",
    "      return matches[0]\n",
    "    else:\n",
    "      # 9. Multiple matches - check distance\n",
    "      max_dist = calculate_max_distance(matches)\n",
    "      if max_dist <= constants.GEOCODE_DISTANCE_THRESHOLD_KM:\n",
    "        logger.info(\n",
    "          f\"  → Auto-selected (Rule 2: '{query_name}(s)? kommun', \"\n",
    "          f\"{len(matches)} within {max_dist:.1f}km): \"\n",
    "          f\"{matches[0].display_name}\"\n",
    "        )\n",
    "        return matches[0]\n",
    "      # Distance too high, try next rule\n",
    "\n",
    "  # 8. Province pattern\n",
    "  pattern3 = re.compile(\n",
    "    rf\"^landskapet\\s+{query_escaped}(s)?\", re.IGNORECASE\n",
    "  )\n",
    "  matches = [\n",
    "    c for c in candidates if pattern3.match(c.display_name.lower())\n",
    "  ]\n",
    "  if matches:\n",
    "    if len(matches) == 1:\n",
    "      logger.info(\n",
    "        f\"  → Auto-selected (Rule 3: 'Landskapet {query_name}(s)?'): \"\n",
    "        f\"{matches[0].display_name}\"\n",
    "      )\n",
    "      return matches[0]\n",
    "    else:\n",
    "      # 9. Multiple matches - check distance\n",
    "      max_dist = calculate_max_distance(matches)\n",
    "      if max_dist <= constants.GEOCODE_DISTANCE_THRESHOLD_KM:\n",
    "        logger.info(\n",
    "          f\"  → Auto-selected (Rule 3: 'Landskapet \"\n",
    "          f\"{query_name}(s)?', {len(matches)} within \"\n",
    "          f\"{max_dist:.1f}km): {matches[0].display_name}\"\n",
    "        )\n",
    "        return matches[0]\n",
    "      # Distance too high, fall through\n",
    "\n",
    "  return None\n",
    "\n",
    "\n",
    "def geocode_verified_entities(force_refresh: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Main geocoding function.\n",
    "\n",
    "    Processes all unique locations from VerifiedEntity table:\n",
    "    1. Skip if already geocoded (unless force_refresh=True)\n",
    "    2. Query Nominatim for all results\n",
    "    3. Calculate distances between candidates\n",
    "    4. Auto-select or mark for review based on threshold\n",
    "    5. Create GeocodedLocation entry\n",
    "    6. Populate VideoLocation bridge table\n",
    "\n",
    "    Args:\n",
    "        force_refresh: If True, re-geocode locations that already exist\n",
    "    \"\"\"\n",
    "    log_script_start(__file__)\n",
    "\n",
    "    with get_session() as session:\n",
    "        # Get unique locations from VerifiedEntity\n",
    "        statement = select(VerifiedEntity.location).distinct()\n",
    "        unique_locations = session.exec(statement).all()\n",
    "        total_locations = len(unique_locations)\n",
    "\n",
    "        logger.info(\n",
    "            f\"Starting geocoding for {total_locations} unique verified locations\"\n",
    "        )\n",
    "\n",
    "        stats = {\n",
    "            \"auto_single\": 0,\n",
    "            \"auto_threshold\": 0,\n",
    "            \"ambiguous\": 0,\n",
    "            \"no_results\": 0,\n",
    "            \"skipped\": 0,\n",
    "        }\n",
    "\n",
    "        for location in tqdm(unique_locations, desc=\"geocoding\"):\n",
    "            # Check if already geocoded\n",
    "            existing = session.exec(\n",
    "                select(GeocodedLocation).where(\n",
    "                    GeocodedLocation.location_name == location\n",
    "                )\n",
    "            ).first()\n",
    "\n",
    "            if existing and not force_refresh:\n",
    "                logger.debug(f\"Skipping already geocoded: {location}\")\n",
    "                stats[\"skipped\"] += 1\n",
    "                continue\n",
    "\n",
    "            # 1. Query nominatim\n",
    "            candidates = geocode_location(location, session)\n",
    "\n",
    "            # Determine selection method\n",
    "            candidate_count = len(candidates)\n",
    "            max_dist = calculate_max_distance(candidates)\n",
    "\n",
    "            if candidate_count == 0:\n",
    "                # No results found\n",
    "                selection_method = constants.SELECTION_NO_RESULTS\n",
    "                needs_review = True\n",
    "                selected_candidate_id = None\n",
    "                stats[\"no_results\"] += 1\n",
    "                logger.warning(f\"  → No results (needs review)\")\n",
    "\n",
    "            # 4. Automatically accept single answers\n",
    "            elif candidate_count == 1:\n",
    "                selection_method = constants.SELECTION_AUTO_SINGLE\n",
    "                needs_review = False\n",
    "                selected_candidate_id = candidates[0].id\n",
    "                stats[\"auto_single\"] += 1\n",
    "                logger.info(\n",
    "                    f\"  → Auto-selected single result: {candidates[0].display_name}\"\n",
    "                )\n",
    "\n",
    "            # 3. Automatically select 'best' candidate\n",
    "            else:\n",
    "                # 5. Common patterns\n",
    "                swedish_match = auto_select_swedish_location(\n",
    "                    location, candidates\n",
    "                )\n",
    "                if swedish_match:\n",
    "                    # Swedish rule matched - auto-select\n",
    "                    selection_method = constants.SELECTION_AUTO_THRESHOLD\n",
    "                    needs_review = False\n",
    "                    selected_candidate_id = swedish_match.id\n",
    "                    stats[\"auto_threshold\"] += 1\n",
    "\n",
    "                # 9. Check if a position can be selected based on max distance\n",
    "                elif max_dist <= constants.GEOCODE_DISTANCE_THRESHOLD_KM:\n",
    "                    # All results within threshold - auto-select first\n",
    "                    selection_method = constants.SELECTION_AUTO_THRESHOLD\n",
    "                    needs_review = False\n",
    "                    selected_candidate_id = candidates[0].id\n",
    "                    stats[\"auto_threshold\"] += 1\n",
    "                    logger.info(\n",
    "                        f\"  → Auto-selected ({candidate_count} within {max_dist:.1f}km): {candidates[0].display_name}\"\n",
    "                    )\n",
    "\n",
    "                # 10. Queue up for human review\n",
    "                else:\n",
    "                    # Results too far apart - needs human review\n",
    "                    selection_method = constants.SELECTION_AMBIGUOUS\n",
    "                    needs_review = True\n",
    "                    selected_candidate_id = None\n",
    "                    stats[\"ambiguous\"] += 1\n",
    "                    logger.info(\n",
    "                        f\"  → Ambiguous ({candidate_count} candidates, max distance: {max_dist:.1f}km) - needs review\"\n",
    "                    )\n",
    "\n",
    "            # 2. Store suggestions\n",
    "            # Create or update GeocodedLocation\n",
    "            if existing and force_refresh:\n",
    "                # Update existing\n",
    "                existing.candidate_id = selected_candidate_id\n",
    "                existing.selection_method = selection_method\n",
    "                existing.needs_review = needs_review\n",
    "                existing.max_distance_km = max_dist\n",
    "                existing.candidate_count = candidate_count\n",
    "                existing.updated_at = datetime.utcnow()\n",
    "            else:\n",
    "                # Create new\n",
    "                geocoded_loc = GeocodedLocation(\n",
    "                    location_name=location,\n",
    "                    candidate_id=selected_candidate_id,\n",
    "                    selection_method=selection_method,\n",
    "                    needs_review=needs_review,\n",
    "                    max_distance_km=max_dist,\n",
    "                    candidate_count=candidate_count,\n",
    "                )\n",
    "                session.add(geocoded_loc)\n",
    "\n",
    "            session.commit()\n",
    "\n",
    "        # Populate VideoLocation bridge table\n",
    "        populate_video_locations(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### A Flying Symbol of Modernity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-sefyr-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/img11.png\", width=800),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-sefyr-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"During the mid 1930s Swedish Film Industry joined the \"\n",
    "          \"newspaper _Stockholm-Tidningen_ and purchased an airplane \"\n",
    "          \"—SE-FYR. The small aircraft was used extensively within \"\n",
    "          \"newsreel film production, both as a way to reach regional \"\n",
    "          \"locations in Sweden, as well as for aerial cinematography. \"\n",
    "          \"Illustrations from Svensk Flyghistorisk Förening.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "It did not come as a total surprise that _SF’s Weekly Review_ favoured the\n",
    "capital. Location data from SweScribe reveals a persistent\n",
    "over-representation of the Stockholm region. Yet, given SF’s metropolitan base,\n",
    "it raises questions if there were any attempts made to address this form of\n",
    "over-representation. The corpus contain repeated\n",
    "references to an airplane named Sefyr—or SE-FYR—jointly owned by SF and \n",
    "_Stockholms-Tidningen_; the aircraft was acquired in 1934. Sefyr was\n",
    "dispatched whenever important events occurred at distances from the capital,\n",
    "and required rapid coverage  by both news outlets. \n",
    "This prompted us to investigate whether Sefyr\n",
    "might have functioned as an infrastructural response to the geographic\n",
    "concentration visible in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "3m0ns": [
       {
        "id": "22783102/ZWKH378T",
        "source": "zotero"
       }
      ],
      "eyvnd": [
       {
        "id": "22783102/YQMWCYSZ",
        "source": "zotero"
       }
      ],
      "qppci": [
       {
        "id": "22783102/ERJVIH9J",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "There is no prior academic inquiry on Sefyr’s function in SF’s newsreels.\n",
    "However, the company’s twenty-fifth anniversary book described the aircraft’s\n",
    "role within newsreel production [ref? @Raspenskog].\n",
    "Besides the fact that the airplane \"always\n",
    "lent something of the allure of speed and the wide open spaces,\" its merits as\n",
    "an express carrier of news were habitually emphasised. Momentum and tempo–chief\n",
    "characteristics of modernity–were often associated with Sefyr. One vivid\n",
    "example was the marriage of the Swedish Princess Ingrid to the Danish Prince\n",
    "Frederik in late May 1935. Stockholm cinemas were packed with audiences who\n",
    "wanted to see daily audiovisual reports surrounding the wedding, which took\n",
    "place in the capital. The SF-newsreel department had even promised coverage of\n",
    "the princely couple’s arrival in Copenhagen aboard the Danish royal yacht:\n",
    "\"There was nothing for it but to advertise it. // <-this is phrased weirdly// \n",
    "Without reservation. Sefyr was the guarantor.\" \n",
    "In fact, Sefyr’s \"popular pilot,\" Åke Söderberg, arrived in\n",
    "Copenhagen the day before to make preparations, together with a reporter and a\n",
    "cameraman. As soon as the team had shot their material from both air and land,\n",
    "the airplane took off for Stockholm with the reels. Sefyr landed in Stockholm\n",
    "at 18:40; the reels were then developed and edited, and a few hours later the\n",
    "sequences were shown to audiences by the end of that evening’s last screenings\n",
    "in Stockholm\n",
    "<cite id=\"3m0ns\"><a href=\"#zotero%7C22783102%2FZWKH378T\">(Skoglund 1944)</a></cite>\n",
    "Moreover, in December 1936, _Stockholms-Tidningen_ proudly proclaimed with a\n",
    "large header in Aftonbladet the aircraft’s faithful service: \"the only\n",
    "newspaper in the Nordic countries with its own news aircraft ... Sefyr will\n",
    "guarantee the best film material also in 1937\"\n",
    "<cite id=\"eyvnd\"><a href=\"#zotero%7C22783102%2FYQMWCYSZ\">(Aftonbladet 1936)</a></cite>\n",
    "In a similar vein, readers were reassured that \"wherever something happens,\n",
    "someone from our wide circle of colleagues is always there to relay the news\n",
    "back to us by telephone, car or airplane\"\n",
    "<cite id=\"qppci\"><a href=\"#zotero%7C22783102%2FERJVIH9J\">(Aftonbladet 1936a)</a></cite>.\n",
    "Sefyr was, hence, not merely a tool for speeding up news\n",
    "distribution. It also formed part of a broader self-image of a technologically\n",
    "well-equipped, mobile and tempo-prone news organisation—a flying symbol of\n",
    "journalistic modernity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Within the Journal Digital corpus, a\n",
    "[search for 'Sefyr'](https://modern36.github.io/jdc_reader/#q=sefyr){:target=\"_blank\"}\n",
    "yields 19 hits across 12 video transcriptions, all dating from the \n",
    "period 1934–36. Sefyr was first mentioned in passing in a\n",
    "1934 newsreel where the narrator spoke of it as a successor to another\n",
    "SF-airplane. Sefyr then debuted in February 1935, which was reported in another\n",
    "newsreel (SF855B); as the airplane flew over SF’s studios in the outskirts of\n",
    "Stockholm on its maiden flight, carrying the directors of the two owning\n",
    "companies, the narrator proclaimed: \n",
    " >Surely our engine noise interrupts the\n",
    "final scene \\[below\\] but we dare to indulge ourselves on this first day with\n",
    "Sefyr.\n",
    "\n",
    "Given the celebratory meta-reporting, the airplane appears to have\n",
    "functioned both as a media-infrastructural solution and as well as a media\n",
    "event (in itself) -— a technological novelty that SF and _Stockholms-Tidningen_\n",
    "could foreground to visualise modern, mobile news-gathering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-lucia-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/vid4.gif\") if local else Video(\"./media/vid4.mp4\"),\n",
    "  width=1000,\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"tags\": [\n",
    "        [\"figure-lucia-*\",],\n",
    "      ],\n",
    "      \"object\": {\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"SF's Weekly Review in December 1935 displayed the Sefyr \"\n",
    "          \"aircraft, in which the ten finalists of \"\n",
    "          \"_Stockholms-Tidningen's_ Saint Lucy's Day pageant were \"\n",
    "          \"flown from Bromma airfield in Stockholm.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "By the end of 1935, Sefyr had been further integrated into promotional\n",
    "activities beyond journalistic duties. Sometimes these were rather curious (to\n",
    "say the least): in one newsreel Sefyr was depicted flying all ten (young women)\n",
    "finalists of _Stockholms-Tidningen’s_ Saint Lucy’s Day pageant, with the narrator\n",
    "playfully referring to the aircraft as \"the winged steed Sefyr\". He is the one\n",
    "who is going to ride off with that lovely cargo\". While the shivering\n",
    "contestants \"brave the biting cold wind,\" the sequence devoted considerable\n",
    "attention to displaying the young women before the camera, transforming a\n",
    "straightforward competition announcement into an elaborate publicity stunt.\n",
    "Observing two of the finalists, the narrator remarked that \"number nine on the\n",
    "left and number eight on the right have apparently really fallen in love with\n",
    "Sefyr,\" before adding that \"Sefyr is a popular machine in the best sense of the\n",
    "word.\" This sequence makes apparent what the deployment signaled: Sefyr did not\n",
    "serve merely as a piece of journalistic equipment, but also as a promotional\n",
    "asset, and a recognisable attraction in its own right; a celebrity status\n",
    "lending modernity and excitement to events sponsored by two media companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-advert-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/img12.png\", width=1000),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-advert-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          'Boys! Do You want the big or the small SEFYR?\" '\n",
    "          \"Advertisement in _Dagens Nyheter_ during autumn 1937 for \"\n",
    "          \"the Sefyr model airplane, available for purchase at \"\n",
    "          \"_Nordiska Kompaniet_ department store.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics",
     "anchor-geolocating"
    ]
   },
   "source": [
    "### Geolocating [ del ]\n",
    "\n",
    "For manual classification, we extracted the top thirty most-mentioned locations\n",
    "per year for 1930–1965, yielding 352 unique locations. We then generated a\n",
    "classification template and manually classified each location by type—city,\n",
    "region, country—assigning hierarchical parent locations where appropriate; such\n",
    "as Södermalm (Stockholm neighborhood) → Stockholm, and Göteborg →\n",
    "Västergötland. This parent-child structure enabled aggregation without\n",
    "modifying source data. The final location data was generated by summing\n",
    "mentions per location per year, applying parent-child aggregation (e.g.,\n",
    "neighbourhood → city → region), filtering by classification type, and ranking\n",
    "to produce annual top-ten lists. This five-stage pipeline transformed the noisy\n",
    "NER output into reliable, structured data suitable for historical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Moreover, all foreign locations were aggregated into a single category,\n",
    "Foreign. For Swedish locations, we classified cities and towns into their\n",
    "respective historical regions (landskap), with one exception: Stockholm. The\n",
    "capital presents a unique case for several reasons. First, the city straddles\n",
    "two regions, Uppland and Södermanland, making regional classification\n",
    "ambiguous. Second, SF-newsreel voice-over frequently referenced localities\n",
    "within the Greater Stockholm metropolitan area—such as Lidingö—that, while\n",
    "formally a distinct municipality and town, function as an integrated part of\n",
    "the capital. When the voice-over mentioned Lidingö, the viewer would understand\n",
    "this as a reference to Stockholm rather than to a separate town or municipality\n",
    "in Uppland. We therefore classified Stockholm and its surrounding localities\n",
    "under Stockholm County (Stockholms län). Treating Stockholm as a distinct\n",
    "regional category also serves an analytical purpose: since SF and its newsreel\n",
    "production was headquartered in Stockholm, we wished to examine whether this\n",
    "might have resulted in a discernible capital-centricity in the geographic\n",
    "coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "We also retained certain historical regions that, while lacking formal\n",
    "administrative boundaries, carry significant cultural and economic meaning.\n",
    "Bergslagen, the traditional mining district spanning parts of five regions,\n",
    "appears frequently in the newsreels as a coherent entity, typically in\n",
    "connection with industrial reporting. Collapsing Bergslagen into its\n",
    "constituent provinces would obscure this discursive unity, and lose\n",
    "analytically valuable information about how the newsreels conceptualised\n",
    "Swedish geography. Similarly, we retained the north of Sweden, Norrland, as a\n",
    "category, given its frequent appearance in the material as a distinct region in\n",
    "its own right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-STHLM-share-*"
    ]
   },
   "outputs": [],
   "source": [
    "def create_proportion_line_chart(data):\n",
    "  \"\"\"\n",
    "  Plotly line chart showing Stockholm's percentage over time.\n",
    "\n",
    "  Args:\n",
    "      data: DataFrame with columns\n",
    "       [year, region, mentions, total_mentions, percentage]\n",
    "      OR dict from calculate_proportions with keys\n",
    "      ['years', 'stockholm_pct', ...]\n",
    "\n",
    "  Returns:\n",
    "      plotly.graph_objects.Figure\n",
    "  \"\"\"\n",
    "  # Handle dict vs DataFrame\n",
    "  if isinstance(data, dict):\n",
    "    # Dict format from calculate_proportions\n",
    "    years = data[\"years\"]\n",
    "    percentages = data[\"stockholm_pct\"]\n",
    "  elif isinstance(data, pd.DataFrame):\n",
    "    # Handle different DataFrame formats\n",
    "    if \"region\" in data.columns:\n",
    "      # Format from load_stockholm_data\n",
    "      stockholm_df = data[data[\"region\"] == \"Stockholm\"].sort_values(\n",
    "        \"year\"\n",
    "      )\n",
    "      years = stockholm_df[\"year\"]\n",
    "      percentages = stockholm_df[\"percentage\"]\n",
    "    elif \"stockholm_pct\" in data.columns:\n",
    "      # DataFrame with stockholm_pct column\n",
    "      data = (\n",
    "        data.sort_values(\"year\") if \"year\" in data.columns else data\n",
    "      )\n",
    "      years = data[\"year\"] if \"year\" in data.columns else data.index\n",
    "      percentages = data[\"stockholm_pct\"]\n",
    "    else:\n",
    "      # Assume Stockholm-only data with year and percentage columns\n",
    "      data = data.sort_values(\"year\")\n",
    "      years = data[\"year\"]\n",
    "      percentages = data[\"percentage\"]\n",
    "  else:\n",
    "    raise ValueError(\"data must be either a dict or pandas DataFrame\")\n",
    "\n",
    "  # Calculate mean percentage\n",
    "  mean_pct = (\n",
    "    percentages.mean()\n",
    "    if hasattr(percentages, \"mean\")\n",
    "    else sum(percentages) / len(percentages)\n",
    "  )\n",
    "\n",
    "  # Create figure\n",
    "  fig = go.Figure()\n",
    "\n",
    "  # Add filled area\n",
    "  fig.add_trace(\n",
    "    go.Scatter(\n",
    "      x=years,\n",
    "      y=percentages,\n",
    "      fill=\"tozeroy\",\n",
    "      fillcolor=\"rgba(46, 134, 171, 0.3)\",\n",
    "      line=dict(color=\"#2E86AB\", width=3),\n",
    "      mode=\"lines+markers+text\",\n",
    "      marker=dict(size=8),\n",
    "      text=[f\"{pct:.1f}%\" for pct in percentages],\n",
    "      textposition=\"top center\",\n",
    "      textfont=dict(color=\"#2E86AB\", size=10),\n",
    "      name=\"Stockholm\",\n",
    "      hovertemplate=\"Year: %{x}<br>Percentage: %{y:.1f}%<extra></extra>\",\n",
    "    )\n",
    "  )\n",
    "\n",
    "  # Add average line\n",
    "  fig.add_hline(\n",
    "    y=mean_pct,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"red\",\n",
    "    line_width=2,\n",
    "    opacity=0.5,\n",
    "    annotation_text=f\"Average: {mean_pct:.1f}%\",\n",
    "    annotation_position=\"right\",\n",
    "  )\n",
    "\n",
    "  # Update layout\n",
    "  year_min = int(min(years))\n",
    "  year_max = int(max(years))\n",
    "  pct_max = (\n",
    "    max(percentages)\n",
    "    if isinstance(percentages, list)\n",
    "    else percentages.max()\n",
    "  )\n",
    "\n",
    "  fig.update_layout(\n",
    "    title=f\"Stockholm's Share of Regional Mentions ({year_min}-{year_max})\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"Percentage of Total Mentions (%)\",\n",
    "    yaxis=dict(range=[0, pct_max * 1.15]),\n",
    "    hovermode=\"x unified\",\n",
    "    showlegend=False,\n",
    "  )\n",
    "\n",
    "  if not local:\n",
    "    return fig\n",
    "\n",
    "  file = root / \"media\" / \"STHLM-share.png\"\n",
    "\n",
    "  fig.write_image(file)\n",
    "\n",
    "  return Image(file)\n",
    "\n",
    "\n",
    "def load_top_n_data(csv_file, start_year=None, end_year=None):\n",
    "  \"\"\"\n",
    "  Load top-N mention data from CSV.\n",
    "\n",
    "  Returns:\n",
    "      dict: {year: {location: mentions}}\n",
    "  \"\"\"\n",
    "  data_by_year = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "  with open(csv_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "      year = int(row[\"year\"])\n",
    "      if start_year is not None and year < start_year:\n",
    "        continue\n",
    "      if end_year is not None and year > end_year:\n",
    "        continue\n",
    "\n",
    "      location = row[\"location\"]\n",
    "      mentions = int(row[\"mentions\"])\n",
    "      data_by_year[year][location] += mentions\n",
    "\n",
    "  return data_by_year\n",
    "\n",
    "\n",
    "def calculate_proportions(data_by_year):\n",
    "  \"\"\"\n",
    "  Calculate Stockholm's proportion and other categories.\n",
    "\n",
    "  Returns:\n",
    "      dict: {\n",
    "          'years': [...],\n",
    "          'stockholm_pct': [...],\n",
    "          'stockholm_mentions': [...],\n",
    "          'other_mentions': [...],\n",
    "          'total_mentions': [...]\n",
    "      }\n",
    "  \"\"\"\n",
    "  years = sorted(data_by_year.keys())\n",
    "  stockholm_pct = []\n",
    "  stockholm_mentions = []\n",
    "  other_mentions = []\n",
    "  total_mentions = []\n",
    "\n",
    "  for year in years:\n",
    "    locations = data_by_year[year]\n",
    "    stockholm = locations.get(\"Stockholm\", 0)\n",
    "    total = sum(locations.values())\n",
    "    other = total - stockholm\n",
    "\n",
    "    stockholm_mentions.append(stockholm)\n",
    "    other_mentions.append(other)\n",
    "    total_mentions.append(total)\n",
    "\n",
    "    if total > 0:\n",
    "      pct = (stockholm / total) * 100\n",
    "    else:\n",
    "      pct = 0\n",
    "\n",
    "    stockholm_pct.append(pct)\n",
    "\n",
    "  return {\n",
    "    \"years\": years,\n",
    "    \"stockholm_pct\": stockholm_pct,\n",
    "    \"stockholm_mentions\": stockholm_mentions,\n",
    "    \"other_mentions\": other_mentions,\n",
    "    \"total_mentions\": total_mentions,\n",
    "  }\n",
    "\n",
    "\n",
    "display(\n",
    "  create_proportion_line_chart(\n",
    "    calculate_proportions(\n",
    "      load_top_n_data(\n",
    "        data / \"top10_regions_by_year_1930-1964.csv\", 1930, 1964\n",
    "      )\n",
    "    ),\n",
    "  ),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-STHLM-share-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"Stockholm's share of total location mentions \"\n",
    "          \"within the Journal Digital Corpus, 1930-1964.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Gazing on Lappland—from Stockholm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As is evident from the chart above, \n",
    "there were few observable declines in\n",
    "Stockholm’s proportional representation in the SF-newsreels during the 1930s.\n",
    "Only in 1936 did the representation of Stockholm decrease, a fact that\n",
    "interestingly coincided with the usage of the airplane Sefyr. It prompted\n",
    "further inquiry into a potential causality. In order to further investigate the\n",
    "representation of Sweden in _SF’s Weekly Review_ we visualised the ten most\n",
    "mentioned regions per year 1933–1939, starting two years before and ending two\n",
    "years after the beforementioned decline—or rather the introduction of Sefyr.\n",
    "However, zooming in on the data did not present evidence to link Sefyr to any\n",
    "representational pattern. It did, however, bring to light another apparent\n",
    "pattern: how certain peripheral regions were represented, not as ordinary parts\n",
    "of Sweden, but as exotic and almost foreign. Lappland offered the most vivid\n",
    "example. Sweden’s largest and northernmost region—historically, also with the\n",
    "lowest population density—was actually the fifth most mentioned domestic region\n",
    "in SF-newsreels produced in 1935. What brought this remote periphery into such\n",
    "sudden visibility? The answer was not due to the flying capabilities of Sefyr,\n",
    "but a broader cultural fascination with the north as a space of leisure and\n",
    "national renewal. Lappland makes up a part of Norrland, the northern of the\n",
    "three lands (_landsdelar_) of Sweden. The mere fact that Norrland was mentioned\n",
    "106 times in the entire corpus was in itself revealing. In contrast, the other\n",
    "two lands, Svealand and Götaland, were only mentioned by name two times each\n",
    "throughout the corpus. It should be noted, however, that the term Norrland is\n",
    "semantically correct, but is nevertheless commonly used as a sweeping\n",
    "designation that reduces a large number of northern regions—together accounting\n",
    "for almost two-thirds of Sweden’s area—into a single, largely undifferentiated\n",
    "category. A linguistic pattern that suggests an urban gaze perceiving the\n",
    "northern parts of Sweden as a distant, homogenous other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-Regions-share-*"
    ]
   },
   "outputs": [],
   "source": [
    "def create_percentage_stacked_bars(data_by_year, regions):\n",
    "  \"\"\"\n",
    "  Create 100% stacked Plotly bar chart showing distribution.\n",
    "\n",
    "  Shows top 10 domestic Swedish regions, excluding Foreign.\n",
    "  Returns a Plotly Figure object.\n",
    "\n",
    "  Args:\n",
    "      data_by_year: Dict of {year: {location: mentions}}\n",
    "      regions: List of all region names\n",
    "\n",
    "  Returns:\n",
    "      plotly.graph_objects.Figure\n",
    "  \"\"\"\n",
    "  years = sorted(data_by_year.keys())\n",
    "\n",
    "  # Filter out \"Foreign\" from regions\n",
    "  domestic_regions = [r for r in regions if r != \"Foreign\"]\n",
    "\n",
    "  # Build percentage data (calculated from total including Foreign)\n",
    "  percentages = defaultdict(list)\n",
    "  for year in years:\n",
    "    # Calculate total INCLUDING Foreign\n",
    "    total = sum(data_by_year[year].values())\n",
    "    for region in regions:  # All regions including Foreign\n",
    "      mentions = data_by_year[year].get(region, 0)\n",
    "      pct = (mentions / total * 100) if total > 0 else 0\n",
    "      percentages[region].append(pct)\n",
    "\n",
    "  # Use Plotly's built-in color palettes combined for maximum distinguishability\n",
    "  # Combine multiple qualitative color scales for better differentiation\n",
    "  all_colors = colors.qualitative.Safe + colors.qualitative.Antique\n",
    "\n",
    "  # Determine which regions are top 10 in each year\n",
    "  top10_by_year = {}\n",
    "  for year in years:\n",
    "    year_data = {\n",
    "      region: mentions\n",
    "      for region, mentions in data_by_year[year].items()\n",
    "      if region != \"Foreign\"\n",
    "    }\n",
    "    top10_this_year = sorted(\n",
    "      year_data.items(), key=lambda x: x[1], reverse=True\n",
    "    )[:10]\n",
    "    top10_by_year[year] = {region for region, _ in top10_this_year}\n",
    "\n",
    "  # Get all regions that appear in top 10 at least once\n",
    "  all_top10_regions = set()\n",
    "  for regions_set in top10_by_year.values():\n",
    "    all_top10_regions.update(regions_set)\n",
    "\n",
    "  # Calculate total mentions for each region across all years for sorting\n",
    "  region_totals = defaultdict(int)\n",
    "  for year_data in data_by_year.values():\n",
    "    for region, mentions in year_data.items():\n",
    "      if region != \"Foreign\" and region in all_top10_regions:\n",
    "        region_totals[region] += mentions\n",
    "\n",
    "  # Sort regions by total mentions (descending)\n",
    "  sorted_by_total = sorted(\n",
    "    region_totals.items(), key=lambda x: x[1], reverse=False\n",
    "  )\n",
    "\n",
    "  # Reverse the order so most abundant is at bottom (just below Foreign at top)\n",
    "  # Stack from bottom to top: least common, ..., 3rd, 2nd, 1st (then Foreign on top)\n",
    "  ordered_regions = [r for r, _ in reversed(sorted_by_total)]\n",
    "\n",
    "  # Create figure\n",
    "  fig = go.Figure()\n",
    "\n",
    "  # Track cumulative heights for positioning\n",
    "  cumulative = {year: 0.0 for year in years}\n",
    "  region_positions = defaultdict(list)\n",
    "\n",
    "  # Add bars for top 10 regions in custom order\n",
    "  color_idx = 0\n",
    "  for region in ordered_regions:\n",
    "    # For each year, only show bar if region is in top 10 AND >= 0.5%\n",
    "    visible_percentages = []\n",
    "    hover_texts = []\n",
    "\n",
    "    for j, year in enumerate(years):\n",
    "      pct = percentages[region][j]\n",
    "      mentions = data_by_year[year].get(region, 0)\n",
    "\n",
    "      # Get rank for this year\n",
    "      year_data = {\n",
    "        r: m for r, m in data_by_year[year].items() if r != \"Foreign\"\n",
    "      }\n",
    "      sorted_regions = sorted(\n",
    "        year_data.items(), key=lambda x: x[1], reverse=True\n",
    "      )\n",
    "      rank = next(\n",
    "        (\n",
    "          i + 1\n",
    "          for i, (r, _) in enumerate(sorted_regions)\n",
    "          if r == region\n",
    "        ),\n",
    "        None,\n",
    "      )\n",
    "\n",
    "      if region in top10_by_year[year] and pct >= 0.5:\n",
    "        visible_percentages.append(pct)\n",
    "        hover_texts.append(\n",
    "          f\"<b>{rank}. {region}</b><br>\"\n",
    "          f\"Percentage: {pct:.1f}%<br>\"\n",
    "          f\"Mentions: {mentions}\"\n",
    "        )\n",
    "      else:\n",
    "        visible_percentages.append(0)\n",
    "        hover_texts.append(\"\")\n",
    "\n",
    "    # Only add trace if region actually appears in the plot\n",
    "    if max(visible_percentages) > 0:\n",
    "      # Add bar trace with legend\n",
    "      fig.add_trace(\n",
    "        go.Bar(\n",
    "          name=region,\n",
    "          x=years,\n",
    "          y=visible_percentages,\n",
    "          marker=dict(\n",
    "            color=all_colors[color_idx % len(all_colors)],\n",
    "            line=dict(color=\"white\", width=0.5),\n",
    "          ),\n",
    "          showlegend=True,\n",
    "          hovertemplate=\"%{text}<extra></extra>\",\n",
    "          text=hover_texts,\n",
    "        )\n",
    "      )\n",
    "\n",
    "      # Track positions for reference (not used for labels anymore)\n",
    "      for j, year in enumerate(years):\n",
    "        if visible_percentages[j] >= 0.5:\n",
    "          midpoint = cumulative[year] + (visible_percentages[j] / 2)\n",
    "          region_positions[region].append(\n",
    "            (year, midpoint, visible_percentages[j])\n",
    "          )\n",
    "          cumulative[year] += visible_percentages[j]\n",
    "        else:\n",
    "          region_positions[region].append((year, 0, 0))\n",
    "\n",
    "      color_idx += 1\n",
    "\n",
    "  # Add Foreign bar at the top (only if it has visible values)\n",
    "  if \"Foreign\" in percentages and max(percentages[\"Foreign\"]) > 0:\n",
    "    foreign_hover_texts = []\n",
    "    for j, year in enumerate(years):\n",
    "      foreign_pct = percentages[\"Foreign\"][j]\n",
    "      foreign_mentions = data_by_year[year].get(\"Foreign\", 0)\n",
    "      foreign_hover_texts.append(\n",
    "        f\"<b>Foreign</b><br>\"\n",
    "        f\"Percentage: {foreign_pct:.1f}%<br>\"\n",
    "        f\"Mentions: {foreign_mentions}\"\n",
    "      )\n",
    "\n",
    "    fig.add_trace(\n",
    "      go.Bar(\n",
    "        name=\"Foreign\",\n",
    "        x=years,\n",
    "        y=percentages[\"Foreign\"],\n",
    "        marker=dict(\n",
    "          color=\"#CCCCCC\", line=dict(color=\"white\", width=0.5)\n",
    "        ),\n",
    "        showlegend=True,\n",
    "        hovertemplate=\"%{text}<extra></extra>\",\n",
    "        text=foreign_hover_texts,\n",
    "      )\n",
    "    )\n",
    "\n",
    "  # Add text annotations for total mentions only\n",
    "  annotations = []\n",
    "\n",
    "  # Add total mentions at top\n",
    "  for year in years:\n",
    "    total_mentions = sum(data_by_year[year].values())\n",
    "    annotations.append(\n",
    "      dict(\n",
    "        x=year,\n",
    "        y=103,\n",
    "        text=f\"n = {total_mentions}\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=11, color=\"black\", family=\"Arial Black\"),\n",
    "        yanchor=\"bottom\",\n",
    "      )\n",
    "    )\n",
    "\n",
    "  # Update layout\n",
    "  fig.update_layout(\n",
    "    title=dict(\n",
    "      text=(\n",
    "        \"Top 10 Domestic Regional Distribution - Percentage Share \"\n",
    "        \"(1933-1939)\"\n",
    "      ),\n",
    "      font=dict(size=18, family=\"Arial Black\"),\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "      title=dict(\n",
    "        text=\"Year\", font=dict(size=14, family=\"Arial Black\")\n",
    "      ),\n",
    "      tickmode=\"linear\",\n",
    "      dtick=1,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "      title=dict(\n",
    "        text=\"Percentage of Mentions (%)\",\n",
    "        font=dict(size=14, family=\"Arial Black\"),\n",
    "      ),\n",
    "      range=[0, 108],\n",
    "      gridcolor=\"rgba(128,128,128,0.3)\",\n",
    "    ),\n",
    "    barmode=\"stack\",\n",
    "    height=800,\n",
    "    width=1000,\n",
    "    annotations=annotations,\n",
    "    plot_bgcolor=\"white\",\n",
    "    paper_bgcolor=\"white\",\n",
    "    margin=dict(t=100, b=150, l=80, r=50),\n",
    "    legend=dict(\n",
    "      title=dict(\n",
    "        text=\"Region\", font=dict(size=12, family=\"Arial Black\")\n",
    "      ),\n",
    "      orientation=\"h\",\n",
    "      yanchor=\"top\",\n",
    "      y=-0.15,\n",
    "      xanchor=\"center\",\n",
    "      x=0.5,\n",
    "      font=dict(size=10),\n",
    "      traceorder=\"normal\",\n",
    "    ),\n",
    "  )\n",
    "\n",
    "  if not local:\n",
    "    return fig\n",
    "\n",
    "  file = root / \"media\" / \"regions-share.png\"\n",
    "\n",
    "  fig.write_image(file)\n",
    "\n",
    "  return Image(file)\n",
    "\n",
    "\n",
    "def load_regional_data_for_viz(csv_path: Path, start_year, end_year):\n",
    "  \"\"\"\n",
    "  Load and prepare regional data for visualization.\n",
    "\n",
    "  Returns:\n",
    "      tuple: (data_by_year dict, regions list, df)\n",
    "      - data_by_year: {year: {region: mentions}}\n",
    "      - regions: sorted list of all regions\n",
    "      - df: pandas DataFrame with columns [year, region, mentions]\n",
    "  \"\"\"\n",
    "  data_by_year = load_top_n_data(csv_path, start_year, end_year)\n",
    "\n",
    "  # Get all regions\n",
    "  all_regions = set()\n",
    "  for year_data in data_by_year.values():\n",
    "    all_regions.update(year_data.keys())\n",
    "  regions = sorted(all_regions)\n",
    "\n",
    "  # Create DataFrame for easier manipulation\n",
    "  rows = []\n",
    "  for year, region_data in data_by_year.items():\n",
    "    for region, mentions in region_data.items():\n",
    "      rows.append(\n",
    "        {\"year\": year, \"region\": region, \"mentions\": mentions}\n",
    "      )\n",
    "  df = pd.DataFrame(rows)\n",
    "\n",
    "  return data_by_year, regions, df\n",
    "\n",
    "\n",
    "display(\n",
    "  create_percentage_stacked_bars(\n",
    "    *load_regional_data_for_viz(\n",
    "      data / \"top10_regions_by_year_1930-1964.csv\", 1930, 1939\n",
    "    )[:2]\n",
    "  ),\n",
    "  width=1000,\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-Regions-share-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"Relative mentions of locations in swedish regions versus \"\n",
    "          \"foreign countries 1933-1939.\"\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "uwkmb": [
       {
        "id": "22783102/XYQCBCR3",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Norrland as a filmic other can also be revealed by a close reading of newsreel\n",
    "transcriptions mentioning Lappland. The region’s first appearance in the corpus\n",
    "occurred in 1930 (SF2789), when the Swedish Prince Wilhelm (1884–1965) read a\n",
    "self-composed prose poem about the Lapplandian nature, entitled _As the boat\n",
    "glides_ (_Medan båten glider_). In the poem, Lappland is portrayed through a\n",
    "distinctly romantic lens, formed as an exotic counterpart to modern\n",
    "civilisation. Prince Wilhelm—later a prolific documentary filmmaker and\n",
    "director—described the northern nature in colourful terms: mountains,\n",
    "waterfalls and wildlife. Alongside this sublime treatment of nature, the poem\n",
    "centres on Gottfrid, a local homesteader who guides the narrator on fishing\n",
    "trips. Gottfrid is characterised as a \"calm, steady, and honest\" man; a\n",
    "representative of the Norrbottnians’ fine, healthy stock\". The last phrase was\n",
    "not incidental; prince Wilhelm’s language was clearly linked to a broader\n",
    "discourse of racial vitalism prevalent in 1930s Sweden, in which the rural and\n",
    "peripheral populations—untouched by urban degeneration—were imagined as\n",
    "repositories of national vigour. The framing in the newsreels, hence, echoed\n",
    "contemporary debates around racial biology, which frequently idealised the\n",
    "Nordic peasant as a biological and moral ideal\n",
    "<cite id=\"uwkmb\"><a href=\"#zotero%7C22783102%2FXYQCBCR3\">(Broberg and Tydén 2005)</a></cite>.\n",
    "Furthermore, the poem was read by a prince—a figure of national continuity—lent\n",
    "these sentiments an authoritative, almost official, character. The wilderness\n",
    "of Lappland was not merely scenic, but regenerative: a space where the modern\n",
    "Swede might reconnect with an imagined ancestral vitality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "figure-wilhelm-*"
    ]
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  Image(\"./media/img13.png\", width=800),\n",
    "  metadata={\n",
    "    \"jdh\": {\n",
    "      \"module\": \"object\",\n",
    "      \"object\": {\n",
    "        \"tags\": [\"figure-wilhelm-*\"],\n",
    "        \"type\": \"image\",\n",
    "        \"source\": [\n",
    "          \"Royalty and exotism—a popular combination. In the film \"\n",
    "          \"_As the boat glides_ (_Medan båten glider_) from 1931, \"\n",
    "          \"the Swedish Prince Wilhelm read a prose poem celebrating \"\n",
    "          \"the Lapplandian nature, or as the subtitle of the film \"\n",
    "          'stated: \"an atmospheric image of Lapland\\'s sparkling '\n",
    "          'lakes and miles of desolate forests with their strange '\n",
    "          'and captivating mystery\".'\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "ta378": [
       {
        "id": "22783102/KLXX4FNU",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In another travel feature from 1934 (SF3188), Lappland again appears as an\n",
    "exotic and curious periphery of Sweden. The narrator frames the journey as an\n",
    "adventure \"towards the North,\" yet continually expresses how accessible it has\n",
    "become by buses, trains, tourist stations, and experienced \"Lapp guides\"\n",
    "(\"Lappar\" is a historically used derogatory term for the Sami; the people\n",
    "indigenous to the area). The natural environment is again described in an\n",
    "exotifying sense—\"eternal snowdrifts,\" \"wild landscapes,\" associations with the\n",
    "tropics at a suspension bridge, the \"feeling of superiority when one-eleventh\n",
    "of Sweden lies at one’s feet\"—while at the same time being tamed into a\n",
    "recreational landscape for hiking, excursions, and having coffee on a veranda\n",
    "in the midnight sun. The Sami appear primarily as a picturesque and reliable\n",
    "service staff within the tourist infrastructure, almost like elements of the\n",
    "scenery in a similar way as the natural landscape \n",
    "<cite id=\"ta378\"><a href=\"#zotero%7C22783102%2FKLXX4FNU\">(Nilsson, Rohdin, and Mörkenstam 2024)</a></cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Returning to our dataset, Lappland, as a geographical location, was not\n",
    "mentioned once in 1936 and 1937; and in 1938 and 1939, the region only appeared\n",
    "in passing. In one example from 1938, about the Swedes’ \"industriousness for\n",
    "generations,\" the voice-over laments: \"From Skåne in the south to Lappland in\n",
    "the north, our national heritage meets us. We live in the era of industrialism.\n",
    "Our country can boast a strong, well-organised industry where capable workers\n",
    "\\[...\\] understand how to create products of great national economic value\n",
    "through cooperation\" (SF3170A.1). In this newsreel, it is thus evident that\n",
    "Lappland was regarded as a fully integrated part of the Swedish industrial\n",
    "economy with strong nationalist overtones. The contrast between these\n",
    "representations during the 1930s is in many ways striking. In 1930 and\n",
    "1934–1935, Lappland appeared as a space apart—romantic, exotic, a destination\n",
    "for leisure and spiritual renewal. By 1938, the same region had been\n",
    "rhetorically absorbed into the national industrial project, its distinctiveness\n",
    "flattened into an allegory for Swedish territory as a whole. The shift suggests\n",
    "two parallel but not incompatible framings: Lappland as an escape from\n",
    "industrial modernity, and Lappland as proof of industrial modernity’s reach. In\n",
    "the first, the region’s value lay in its perceived distance from the modern; in\n",
    "the second, that distance had been overcome, and the north was now legible as\n",
    "part of a unified, productive nation. Tourism and industrialism were thus both\n",
    "articulations of the same modernisation project evident in _SF’s Weekly\n",
    "Review_—one offering recovery from its stresses, the other celebrating its\n",
    "triumphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "atz0c": [
       {
        "id": "22783102/NEKZIEHT",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If the peak in interest for Lappland in _SF’s Weekly Review_ stood out in 1935\n",
    "it was perhaps due to an interest in the leisurely exploitation of the region.\n",
    "Scalable readings of the newsreel transcriptions, toward a background of\n",
    "previous historical research, gives evidence on how different geographic areas\n",
    "were represented. The 1930s was a formative period for mass tourism in Europe,\n",
    "largely facilitated by rapid infrastructural changes\n",
    "<cite id=\"atz0c\"><a href=\"#zotero%7C22783102%2FNEKZIEHT\">(Barton 2011)</a></cite>.\n",
    "By applying scalable reading of the Journal Digital collection, we have shown\n",
    "that this development was reflected in the case of Lappland in Swedish\n",
    "newsreels from the era. Newsreels mediated tourism not merely as a new\n",
    "practical possibility, but also as a cultural product of modern progress\n",
    "itself. Moreover, Sefyr exemplifies another dimension of how Swedish newsreels\n",
    "mediated modernity to their audiences: the technological conquest of distance,\n",
    "with the airplane serving as both practical infrastructure and promotional\n",
    "spectacle. Still, Sefyr’s flights were centripetal—bringing news back to\n",
    "Stockholm, reinforcing the capital as the hub through which national and\n",
    "international events were processed and distributed. A second, complementary\n",
    "dimension of this modern gaze moved in the opposite direction: centrifugal\n",
    "journeys outward from urban centres into Sweden’s peripheral regions, now made\n",
    "accessible through the same type of modern infrastructural developments that\n",
    "made rapid news delivery possible. If Sefyr symbolised the speed with which the\n",
    "modern press could collapse geographic distance, then the touristic\n",
    "representation of Lappland illustrated what that collapsed distance made\n",
    "available—not for journalists, but for ordinary Swedes seeking leisure and\n",
    "adventure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The applications and language models that the datalab at the National Library of Sweden has launched in recent years, have primarily been trained on older, digitized collections of audiovisual material. The various KB-Whisper models, for example, have been developed using some 50,000 hours of Swedish speech data—some of which comes from the digitized Journal Digital film collection. The main reason why the National Library is working with these types of models is that they will (or might) contribute to AI development within the Swedish public sector. Recently, the National Library even received a government mandate, and extra funding, to develop further and more advanced models. It is of course admirable that older moving image heritage data can be used for novel AI development. Moreover, some of these models, and especially AST applications, are naturally also of benefit for heritage institutions, since they can enhance metadata of elderly film or television collections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Then again, in this article we have also shown how such models, and AI-powered transmediation of newsreels, can open up new research venues that were previously inaccessible. Even if there are perhaps no particular or specific findings in our article, we have nevertheless demonstrated how signal archaeology and text extraction of intertitles, named entity recognition and geocoding, offer new and fascinating ways to analyse a major film collection at scale. We have converted both film and audio to text, which in addition to making this content humanly readable (as opposed to watchable) also make the Journal Digital collection (re)searchable in an unprecedented way. Text gleaned from newsreel intertitles (or voice-over commentary) does indeed increase the scholarly capacity of such media historical sources. It should also again be stressed that flash intertitles within silent films have for decades been a nuisance for film historians. Through the application stum this obstacle has at least to some extent been reduced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Moreover, we have used voice-over commentary transcribed into texts to create maps of mentioned locations in newsreels, and also shown how this enables a scalable geographical reading. By using a distant reading framework, we have moved from data-driven overviews of geographic frequency, to close readings of individual locations—and back again. This approach has allowed us to chart not only how certain places were made visible—and how often. But also in what narrative contexts they appeared, thereby reconstructing a Swedish cultural landscape formed in part by newsreel depiction, in a manner that would have been prohibitively difficult using qualitative or quantitative methods alone. Similarly, we have added a multimodal object-annotation to 2,319 films, and have shown that what is seen is often not what is heard. By examining the patterns of which object pairs are most often detected together across the Journal Digital collection, we have furthermore examined how a diegetic strategy of newsreels evolved in a non-linear fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The Journal Digital film collection offers a rich, multimodal window into Swedish 20th century history, which requires different angles of approach to be fully explored. We have investigated some of these, processing both audio and film with multiple pipelines. These pipelines are very different in nature, but they have two important elements in common: Firstly, the heavy lifting of these pipelines rely on existing, pre-trained AI-models and tools that were developed for different (and usually contemporary) materials—not old, historical newsreels. Secondly, the outputs from these pipelines require a moderate to a lot of post-processing before they are fit for analyses. It is therefore almost obvious that the code and applications we have developed for this article, have meant that we have critically scrutinized our own algorithmic toolboxes for the study of the past. By enriching films with metadata covering speech, intertitle texts, visible and audible objects, and geographical locations—all time-aligned—we have, finally, been able to breathe life into a collection that has, at least metaphorically, gathered dust within the confines of a digital archive. Within our article we have divided metadata use into three distinct tracks, audio-visual, intertitle-textual, and speech-geographical. As such, we have only explored a fraction of the available combinations of metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# References\n",
    "<!-- BIBLIOGRAPHY START -->\n",
    "<div class=\"csl-bib-body\">\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/YQMWCYSZ\"></i>Aftonbladet. 1936a. “Stockholms-Tidningen Enda Tidning i Norden Med Reportage-Flygmaskin.” <i>Aftonbladet</i>, December, 30.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/ERJVIH9J\"></i>———. 1936b. “Stockholms-Tidningen Skrives Av Unga Begåvningar Med Tidens Takt i Blodet!” <i>Aftonbladet</i>, December, 27.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/928EZRZ4\"></i>ALB. 1996. “Ledningsgrupp Minnesanteckningar.”</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/R86YMEXD\"></i>———. 1997. “Ledningsgrupp Minnesanteckningar.”</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/M63TBZ7V\"></i>———. 1998. “Det Digitala Journalfilmsarkivet, Application.”</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/BXDUCBBT\"></i>———. 1999. “IT-Insatser Och Ökad Tillgänglighet.”</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/KADI4AFW\"></i>Armaselu, Florentina, and Andreas Fickers, eds. 2024. <i>Zoomland: Exploring Scale in Digital History and Humanities</i>. De Gruyter. <a href=\"https://www.degruyter.com/document/doi/10.1515/9783111317779/html\">https://www.degruyter.com/document/doi/10.1515/9783111317779/html</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/NEKVNJJD\"></i>Arnheim, Rudolf. 1957. <i>Film as Art</i>. 2nd ed. Berkeley and Los Angeles: University of California Press.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/DSU6R48K\"></i>Asp, Jon. 2014. <i>Film För Folket: Om Folkets Hus Och Filmen</i>. Stockholm: Premiss.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/5U2K4DR4\"></i>Aspenskog, Robert, and Mathias Johansson. 2025. <i>Modern36/Swescribe: V0.1.0</i>. Zenodo. <a href=\"https://doi.org/10.5281/ZENODO.15576004\">https://doi.org/10.5281/ZENODO.15576004</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/5LZCK9F3\"></i>Aspenskog, Robert, Mathias Johansson, and Pelle Snickars. 2025. “Journal Digital Corpus: Swedish Newsreel Transcriptions.” <i>Journal of Open Humanities Data</i> 11 (August): 44. <a href=\"https://doi.org/10.5334/johd.344\">https://doi.org/10.5334/johd.344</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/89SWX3HE\"></i>Bain, Max, Jaesung Huh, Tengda Han, and Andrew Zisserman. 2023. “WhisperX: Time-Accurate Speech Transcription of Long-Form Audio.” In <i>INTERSPEECH 2023</i>, 4489–93. ISCA. <a href=\"https://doi.org/10.21437/Interspeech.2023-78\">https://doi.org/10.21437/Interspeech.2023-78</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/2IBV4AM6\"></i>Balázs, Béla. 2010. <i>Early Film Theory: Visible Man and The Spirit of Film</i>. Edited by Erica Carter. Translated by Rodney Livingstone. New York and Oxford: Berghahn Books.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/UVAHYVZ2\"></i>———. 2017. <i>Der Sichtbare Mensch Oder Die Kultur Des Films</i>. 5th ed. Frankfurt am Main: Suhrkamp.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/NEKZIEHT\"></i>Barton, Susan. 2011. <i>Working-Class Organisations and Popular Tourism, 1840–1940</i>. Manchester and New York: Manchester University Press.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/TEPVQNE3\"></i>Beck, Jay. 2011. “The Evolution of Sound in Cinema.” In <i>The Routledge Companion to Film History</i>, edited by William Howard Guynn, 1st ed., 64–76. London: Routledge.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/DW4S37Y5\"></i>Bergman, O. 1986. “Hon Ska Göra TV:S Guldgruva Lönsam.” <i>Dagens Nyheter</i>, November.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/PUAS8ZHL\"></i>Bhargav, Samarth, Nanne Van Noord, and Jaap Kamps. 2019. “Deep Learning as a Tool for Early Cinema Analysis.” In <i>Proceedings of the 1st Workshop on Structuring and Understanding of Multimedia heritAge Contents</i>, 61–68. Nice: ACM. <a href=\"https://doi.org/10.1145/3347317.3357240\">https://doi.org/10.1145/3347317.3357240</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/MFU9DVN9\"></i>Bradski, Gary. 2000. “The OpenCV Library.” <i>Dr. Dobb’s Journal of Software Tools</i>, no. 120: 122–25.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/XYQCBCR3\"></i>Broberg, Gunnar, and Mattias Tydén. 2005. <i>Oönskade i Folkhemmet: Rashygien Och Sterilisering i Sverige</i>. 2nd ed. Stockholm: Dialogos.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/6AUNIX6I\"></i>Brownell, B. A. 1972. “A Symbol of Modernity: Attitudes Toward the Automobile in Southern Cities in the 1920s.” <i>American Quarterly</i> 24 (1): 20–44. <a href=\"https://doi.org/10.2307/2711913\">https://doi.org/10.2307/2711913</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/685XZA23\"></i>Chambers, Ciara, Mats Jönsson, and Roel vande Winkel, eds. 2018. <i>Researching Newsreels: Local, National and Transnational Case Studies</i>. Cham: Palgrave Macmillan.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/8BSVNXZQ\"></i>Chaume, Frederic. 2020. “Dubbing.” In <i>The Palgrave Handbook of Audiovisual Translation and Media Accessibility</i>, edited by Łukasz Bogucki and Mikołaj Deckert, 103–32. Cham: Palgrave Macmillan.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/NLX2C8VR\"></i>Chion, Michel. 1994. <i>Audio-Vision: Sound on Screen</i>. Edited and translated by Claudia Gorbman. New York: Columbia University Press.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/JSI4ETR6\"></i>Dagend Nyheter. 1928. “Tonfilmen Fick En Fin Premiär i Konserthuset.” <i>Dagens Nyheter</i>, October, 21.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/FDPKQ7P8\"></i>Dahlstedt, Stellan. 1947. “Utvidgad Ljudavdelning Vid SF:S Ateljéer i Råsunda.” <i>AGA-Nyheter</i>, no. 1.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/3TIXWE3B\"></i>Dang, Sarah-Mai, Tim Van Der Heijden, and Christian Gosvig Olesen, eds. 2024. <i>Doing Digital Film History: Concepts, Tools, Practices</i>. Berlin: De Gruyter.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/JQZ27MNN\"></i>Dobringer, Anna, Silvester Stöger, and Karl Wratschko. 2013. “Changing Perspectives. DAS EINKÜCHENHAUS as an Example of Film Historiography and Contemporary Restoration.” In <i>Work/s in Progress: Digital Film Restoration within Archives</i>, edited by Kerstin Parth, Oliver Hanley, and Thomas Ballhausen, 121–33. Vienna: Synema.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/8P2FL3R2\"></i>Dupré La Tour, Claire. 2005. “Intertitles and Titles.” In <i>Encyclopedia of Early Cinema</i>, edited by Richard Abel, 326–31.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/PCBNCFMD\"></i>Eisenstein, Sergej, Vsevolod Pudovkin, and Grigori Alexandrov. 1994. “Statement on Sound.” In <i>The Film Factory: Russian and Soviet Cinema in Documents</i>, edited by Richard Taylor, 234. London: Routledge.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/VL4UHIWF\"></i>Eriksson, Maria. 2024. “Zur Bedeutung Des Skalierens Beim Upscaling Digitaler Bilder” 33 (1).</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/2RDITF4M\"></i>Eriksson, Maria, Tomas Skotare, and Pelle Snickars. 2022. “Understanding Gardar Sahlberg with Neural Nets: On Algorithmic Reuse of the Swedish SF Archive.” <i>Journal of Scandinavian Cinema</i> 12 (3): 225–47. <a href=\"https://doi.org/10.1386/jsca_00075_1\">https://doi.org/10.1386/jsca_00075_1</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/24HEASLG\"></i>———. 2024. “Tracking and Tracing Audiovisual Reuse: Introducing the Video Reuse Detector.” <i>Journal of Digital History</i> 3 (1). <a href=\"https://doi.org/10.1515/jdh-2024-0009\">https://doi.org/10.1515/jdh-2024-0009</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/WEZNWR96\"></i>Fickers, Andreas, and Frédéric Clavert. 2021. “On Pyramids, Prisms, and Scalable Reading.” <i>Journal of Digital History</i> 1 (1). <a href=\"https://doi.org/10.1515/jdh-2021-1008\">https://doi.org/10.1515/jdh-2021-1008</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/94IX6F2L\"></i>Furhammar, Leif. 2003. <i>Filmen i Sverige: En Historia i Tio Kapitel Och En Fortsättning</i>. 3rd ed. Stockholm: Dialogos i samarbete med Svenska filminstitutet.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/GVASD2H8\"></i>Gaines, J. M. 2024. “The DH Dilemma: Knowing More &#38; Knowing for Sure vs. Never Knowing At All.” In <i>Doing Digital Film History: Concepts, Tools, Practices</i>, edited by Sarah-Mai Dang, Tim Van Der Heijden, and Christian Gosvig Olesen, 17–46. Berlin: De Gruyter.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/X4KI9JPL\"></i>GeoNames. 2025. “GeoNames Geographical Database.” <a href=\"https://www.geonames.org/\">https://www.geonames.org/</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/BY6TRM9R\"></i>Gong, Yuan, Yu-An Chung, and James Glass. 2021. “AST: Audio Spectrogram Transformer.” In <i>Interspeech 2021</i>, 571–75. ISCA. <a href=\"https://doi.org/10.21437/Interspeech.2021-698\">https://doi.org/10.21437/Interspeech.2021-698</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/WHSQVQAB\"></i>Guyot, Patrice, Thierry Malon, Geoffrey Roman-Jimenez, Sylvie Chambon, Vincent Charvillat, Alain Crouzil, André Péninou, Julien Pinquier, Florence Sèdes, and Christine Sénac. 2019. “Audiovisual Annotation Procedure for Multi-View Field Recordings.” In <i>MultiMedia Modeling</i>, edited by Ioannis Kompatsiaris, Benoit Huet, Vasileios Mezaris, Cathal Gurrin, Wen-Huang Cheng, and Stefanos Vrochidis, 11295:399–410. Cham: Springer International Publishing. <a href=\"https://doi.org/10.1007/978-3-030-05710-7_33\">https://doi.org/10.1007/978-3-030-05710-7_33</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/2X3XHIU7\"></i>Habel, Ylva. 2002. <i>Modern Media, Modern Audiences: Mass Media and Social Engineering in the 1930s Swedish Welfare State</i>. Stockholm: Aura.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/TT5RIEE2\"></i>Johansson, Mathias. 2025. <i>Modern36/Stum: V0.2.0</i>. Zenodo. <a href=\"https://doi.org/10.5281/ZENODO.15582876\">https://doi.org/10.5281/ZENODO.15582876</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/PEB6LVXU\"></i>Johansson, Mathias, and Robert Askepskog. 2026. “Geographical Analysis of Journal Digital.” Zenodo. <a href=\"https://doi.org/10.5281/ZENODO.18131655\">https://doi.org/10.5281/ZENODO.18131655</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/I8MEJEFP\"></i>Johansson, Mathias, and Johan Malmstedt. 2026. “Audiovisual Analysis of Journal Digital.” Zenodo. <a href=\"https://doi.org/10.5281/ZENODO.18130784\">https://doi.org/10.5281/ZENODO.18130784</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/BPGKCGSS\"></i>KB Labb. 2022. “KB/Bert-Base-Swedish-Cased-Ner.” 2022. <a href=\"https://huggingface.co/KB/bert-base-swedish-cased-ner\">https://huggingface.co/KB/bert-base-swedish-cased-ner</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/EVKA7BG8\"></i>Korrapati, V. 2025. “Moondream 2 / Moondream: Tiny Vision-Language Model for Object Detection and Vision Tasks.” <a href=\"https://huggingface.co/moondream\">https://huggingface.co/moondream</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/K4N8PIGZ\"></i>Malmstedt, Johan. 2025. “Sound Out of Time: Signal Archaeology of Swedish Public Service Radio 1980–1999.” Doctoral dissertation, Umeå: Umeå University. <a href=\"https://urn.kb.se/resolve?urn=urn:nbn:se:umu:diva-236882\">https://urn.kb.se/resolve?urn=urn:nbn:se:umu:diva-236882</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/AGCZGSA8\"></i>Malmsten, Martin, Chris Haffenden, and Love Börjeson. 2022. “Hearing Voices at the National Library -- a Speech Corpus and Acoustic Model for the Swedish Language.” arXiv. <a href=\"https://doi.org/10.48550/ARXIV.2205.03026\">https://doi.org/10.48550/ARXIV.2205.03026</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/SSCKKMRE\"></i>Moretti, Franco. 2000. “Conjectures on World Literature.” <i>New Left Review</i>, January, 54–68. <a href=\"https://doi.org/10.64590/hxj\">https://doi.org/10.64590/hxj</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/KLXX4FNU\"></i>Nilsson, Ragnhild, Mats Rohdin, and Ulf Mörkenstam, eds. 2024. <i>Sápmi På Film Och TV</i>. Umeå: Várdduo, Centrum för samisk forskning.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/DVKUX2N4\"></i>Norrlander, S. 1964. “PM Med Plan Och Instruktion Rörande SF:S Journalarkiv.”</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/UK5SM8C2\"></i>Offert, Fabian. 2023. “On the Concept of History (in Foundation Models).” <i>IMAGE. Zeitschrift Für Interdisziplinäre Bildwissenschaft</i> 19 (1): 121–34. <a href=\"https://doi.org/10.25969/MEDIAREP/22316\">https://doi.org/10.25969/MEDIAREP/22316</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/H4XMMWYS\"></i>Oiva, Mila, Ksenia Mukhina, Vejune Zemaityte, Andres Karjus, Mikhail Tamm, Tillmann Ohm, Mark Mets, et al. 2024. “A Framework for the Analysis of Historical Newsreels.” <i>Humanities and Social Sciences Communications</i> 11 (1): 1–15. <a href=\"https://doi.org/10.1057/s41599-024-02886-w\">https://doi.org/10.1057/s41599-024-02886-w</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/6APYGVMY\"></i>Olsson, Jan. 2022. <i>The Life and Afterlife of Swedish Biograph: From Commercial Circulation to Archival Practices</i>. 1st ed. Madison: University of Wisconsin Press.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/NTI97CTV\"></i>Pronay, Nicholas. 1971. “British Newsreels in the 1930s: Audience and Producers.” <i>History</i> 56 (188): 411–17. <a href=\"https://doi.org/10.1111/j.1468-229X.1971.tb02124.x\">https://doi.org/10.1111/j.1468-229X.1971.tb02124.x</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/WQEJMM77\"></i>Reeves, Nicholas. 1986. <i>Official British Film Propaganda During the First World War</i>. London: Croom Helm.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/HDPCSX8E\"></i>Scott, Conner Rivers. 2024. “‘Propaganda for Things as They Are’? British Newsreels in Everyday Life, c.1920-c.1939.” Doctoral dissertation, Sheffield: University of Sheffield. <a href=\"https://etheses.whiterose.ac.uk/id/eprint/35332/\">https://etheses.whiterose.ac.uk/id/eprint/35332/</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/ZWKH378T\"></i>Skoglund, Gunnar. 1944. “Om Kortfilm Och Journalreportage.” In <i>Svensk Filmindustri Tjugufem År: En Bok Om Filmproduktion Och Biografrörelse / Utgiven till Jubileet Av Aktiebolaget Svensk Filmindustri</i>, edited by Bengt Idestam-Almquist, 149–60. Stockholm.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/AZ3BT53M\"></i>Smith, Ray. 2007. “An Overview of the Tesseract OCR Engine.” In <i>Ninth International Conference on Document Analysis and Recognition (ICDAR 2007) Vol 2</i>, 629–33. Curitiba, Parana, Brazil: IEEE. <a href=\"https://doi.org/10.1109/ICDAR.2007.4376991\">https://doi.org/10.1109/ICDAR.2007.4376991</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/583554VC\"></i>Snickars, Pelle. 2015. “Remarks on a Failed Film Archival Project.” <i>Journal of Scandinavian Cinema</i> 5 (1): 63–67. <a href=\"https://doi.org/10.1386/jsca.5.1.63_1\">https://doi.org/10.1386/jsca.5.1.63_1</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/BNUCIK7T\"></i>———. 2024. <i>Audiovisuella Arkiv: En Svensk Mediehistoria 1930–1990</i>. Lund: Mediehistoriskt arkiv.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/7HB6GAHN\"></i>Stjernholm, Emil, Maria Eriksson, and Fredrik Mohammadi Norén. 2025. “On the Historical Gaze of Generative AI: Visions of Scandinavia in Stable Diffusion.” <i>Scandinavian Journal of History</i> 50 (4): 458–88. <a href=\"https://doi.org/10.1080/03468755.2025.2511644\">https://doi.org/10.1080/03468755.2025.2511644</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/BQLCIUEW\"></i>Stjernholm, Emil, and Erik Florin Persson. 2019. “Ett Filmbolag i Det Allmännas Tjänst?: Svensk Filmindustri Och Skolfilmens Flytande Gränser.” In <i>Efterkrigstidens Samhällskontakter</i>, edited by Fredrik Norén and Emil Stjernholm, 41–72. Lund: Mediehistoriskt arkiv.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/TV37XT5P\"></i>Stjernholm, Emil, and Pelle Snickars. 2024. “Upscaling Swedish Biograph.” <i>Journal of Scandinavian Cinema</i> 14 (3): 181–97. <a href=\"https://doi.org/10.1386/jsca_00118_1\">https://doi.org/10.1386/jsca_00118_1</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/URY9RMYJ\"></i>Thompson, Emily. 2004. <i>The Soundscape of Modernity: Architectural Acoustics and the Culture of Listening in America, 1900–1933</i>. Cambridge: MIT Press.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/8XFJBPEC\"></i>Weitin, Thomas. 2017. “Scalable Reading.” <i>Zeitschrift Für Literaturwissenschaft Und Linguistik</i> 47 (1): 1–6. <a href=\"https://doi.org/10.1007/s41244-017-0048-4\">https://doi.org/10.1007/s41244-017-0048-4</a>.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/6VFT9YB8\"></i>Widenheim, Cecilia, ed. 2002. <i>Utopia &#38; Reality: Modernity in Sweden 1900–1960</i>. New Haven: Yale University Press.</div>\n",
    "  <div class=\"csl-entry\"><i id=\"zotero|22783102/DBCYMUBB\"></i>Zhou, Xinyu, Cong Yao, He Wen, Yuzhi Wang, Shuchang Zhou, Weiran He, and Jiajun Liang. 2017. “EAST: An Efficient and Accurate Scene Text Detector.” In <i>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 5551–60. Honolulu, HI: IEEE. <a href=\"https://doi.org/10.1109/CVPR.2017.283\">https://doi.org/10.1109/CVPR.2017.283</a>.</div>\n",
    "</div>\n",
    "<!-- BIBLIOGRAPHY END -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "citation-manager": {
   "items": {
    "zotero": {
     "22783102/24HEASLG": {
      "DOI": "10.1515/jdh-2024-0009",
      "URL": "https://www.degruyter.com/document/doi/10.1515/jdh-2024-0009/html",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Eriksson",
        "given": "Maria"
       },
       {
        "family": "Skotare",
        "given": "Tomas"
       },
       {
        "family": "Snickars",
        "given": "Pelle"
       }
      ],
      "container-title": "Journal of Digital History",
      "id": "22783102/24HEASLG",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         2024,
         6
        ]
       ]
      },
      "language": "en",
      "shortTitle": "Tracking and tracing audiovisual reuse",
      "system_id": "zotero|22783102/24HEASLG",
      "title": "Tracking and tracing audiovisual reuse: Introducing the Video Reuse Detector",
      "type": "article-journal",
      "volume": "3"
     },
     "22783102/2IBV4AM6": {
      "ISBN": "978-1-84545-660-3",
      "author": [
       {
        "family": "Balázs",
        "given": "Béla"
       }
      ],
      "editor": [
       {
        "family": "Carter",
        "given": "Erica"
       }
      ],
      "event-place": "New York and Oxford",
      "id": "22783102/2IBV4AM6",
      "issued": {
       "date-parts": [
        [
         2010
        ]
       ]
      },
      "publisher": "Berghahn Books",
      "publisher-place": "New York and Oxford",
      "shortTitle": "Early Film Theory",
      "system_id": "zotero|22783102/2IBV4AM6",
      "title": "Early Film Theory: Visible Man and The Spirit of Film",
      "translator": [
       {
        "family": "Livingstone",
        "given": "Rodney"
       }
      ],
      "type": "book"
     },
     "22783102/2RDITF4M": {
      "DOI": "10.1386/jsca_00075_1",
      "URL": "https://intellectdiscover.com/content/journals/10.1386/jsca_00075_1",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Eriksson",
        "given": "Maria"
       },
       {
        "family": "Skotare",
        "given": "Tomas"
       },
       {
        "family": "Snickars",
        "given": "Pelle"
       }
      ],
      "container-title": "Journal of Scandinavian Cinema",
      "id": "22783102/2RDITF4M",
      "issue": "3",
      "issued": {
       "date-parts": [
        [
         2022,
         9
        ]
       ]
      },
      "language": "en",
      "page": "225–247",
      "shortTitle": "Understanding Gardar Sahlberg with neural nets",
      "system_id": "zotero|22783102/2RDITF4M",
      "title": "Understanding Gardar Sahlberg with neural nets: On algorithmic reuse of the Swedish SF archive",
      "type": "article-journal",
      "volume": "12"
     },
     "22783102/2X3XHIU7": {
      "ISBN": "978-91-628-5507-9",
      "author": [
       {
        "family": "Habel",
        "given": "Ylva"
       }
      ],
      "event-place": "Stockholm",
      "id": "22783102/2X3XHIU7",
      "issued": {
       "date-parts": [
        [
         2002
        ]
       ]
      },
      "publisher": "Aura",
      "publisher-place": "Stockholm",
      "shortTitle": "Modern Media, Modern Audiences",
      "system_id": "zotero|22783102/2X3XHIU7",
      "title": "Modern Media, Modern Audiences: Mass Media and Social Engineering in the 1930s Swedish Welfare State",
      "type": "book"
     },
     "22783102/3TIXWE3B": {
      "ISBN": "978-3-11-108248-6",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         19
        ]
       ]
      },
      "editor": [
       {
        "family": "Dang",
        "given": "Sarah-Mai"
       },
       {
        "family": "Van Der Heijden",
        "given": "Tim"
       },
       {
        "family": "Olesen",
        "given": "Christian Gosvig"
       }
      ],
      "event-place": "Berlin",
      "id": "22783102/3TIXWE3B",
      "issued": {
       "date-parts": [
        [
         2024
        ]
       ]
      },
      "publisher": "De Gruyter",
      "publisher-place": "Berlin",
      "shortTitle": "Doing Digital Film History",
      "system_id": "zotero|22783102/3TIXWE3B",
      "title": "Doing Digital Film History: Concepts, Tools, Practices",
      "type": "book"
     },
     "22783102/583554VC": {
      "DOI": "10.1386/jsca.5.1.63_1",
      "URL": "https://intellectdiscover.com/content/journals/10.1386/jsca.5.1.63_1",
      "abstract": "Abstract This brief article assesses an ongoing infrastructural research project focusing on filmarkivet.se, a website devoted to historical Swedish non-fiction film. As a collaboration between film researchers and film heritage institutions, the project has to date failed to overcome conflicting archival interests. Film scholars in general need open online archives and contextual resources, while some heritage institutions seek to give access solely to a curated filmic past. While cooperation between the heritage sector and scholars is regularly envisioned as being mutually beneficial, it also faces difficulties that need to be addressed and overcome.",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         26
        ]
       ]
      },
      "author": [
       {
        "family": "Snickars",
        "given": "Pelle"
       }
      ],
      "container-title": "Journal of Scandinavian Cinema",
      "id": "22783102/583554VC",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         2015,
         3,
         1
        ]
       ]
      },
      "page": "63–67",
      "system_id": "zotero|22783102/583554VC",
      "title": "Remarks on a Failed Film Archival Project",
      "type": "article-journal",
      "volume": "5"
     },
     "22783102/5LZCK9F3": {
      "DOI": "10.5334/johd.344",
      "URL": "http://openhumanitiesdata.metajnl.com/articles/10.5334/johd.344/",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         19
        ]
       ]
      },
      "author": [
       {
        "family": "Aspenskog",
        "given": "Robert"
       },
       {
        "family": "Johansson",
        "given": "Mathias"
       },
       {
        "family": "Snickars",
        "given": "Pelle"
       }
      ],
      "container-title": "Journal of Open Humanities Data",
      "id": "22783102/5LZCK9F3",
      "issued": {
       "date-parts": [
        [
         2025,
         8
        ]
       ]
      },
      "page": "44",
      "shortTitle": "Journal Digital Corpus",
      "system_id": "zotero|22783102/5LZCK9F3",
      "title": "Journal Digital Corpus: Swedish Newsreel Transcriptions",
      "type": "article-journal",
      "volume": "11"
     },
     "22783102/5U2K4DR4": {
      "URL": "https://zenodo.org/doi/10.5281/zenodo.15576004",
      "abstract": "Full Changelog: https://github.com/Modern36/swescribe/commits/v0.1.0",
      "accessed": {
       "date-parts": [
        [
         2026,
         1,
         2
        ]
       ]
      },
      "author": [
       {
        "family": "Aspenskog",
        "given": "Robert"
       },
       {
        "family": "Johansson",
        "given": "Mathias"
       }
      ],
      "id": "22783102/5U2K4DR4",
      "issued": {
       "date-parts": [
        [
         2025,
         6,
         2
        ]
       ]
      },
      "note": "DOI: 10.5281/ZENODO.15576004",
      "publisher": "Zenodo",
      "shortTitle": "Modern36/swescribe",
      "system_id": "zotero|22783102/5U2K4DR4",
      "title": "Modern36/swescribe: v0.1.0",
      "type": "book"
     },
     "22783102/685XZA23": {
      "ISBN": "978-3-319-91920-1",
      "editor": [
       {
        "family": "Chambers",
        "given": "Ciara"
       },
       {
        "family": "Jönsson",
        "given": "Mats"
       },
       {
        "family": "Winkel",
        "given": "Roel vande"
       }
      ],
      "event-place": "Cham",
      "id": "22783102/685XZA23",
      "issued": {
       "date-parts": [
        [
         2018
        ]
       ]
      },
      "language": "eng",
      "publisher": "Palgrave Macmillan",
      "publisher-place": "Cham",
      "shortTitle": "Researching Newsreels",
      "system_id": "zotero|22783102/685XZA23",
      "title": "Researching Newsreels: Local, National and Transnational Case Studies",
      "type": "book"
     },
     "22783102/6APYGVMY": {
      "ISBN": "978-0-299-33990-6",
      "author": [
       {
        "family": "Olsson",
        "given": "Jan"
       }
      ],
      "edition": "1",
      "event-place": "Madison",
      "id": "22783102/6APYGVMY",
      "issued": {
       "date-parts": [
        [
         2022
        ]
       ]
      },
      "language": "eng",
      "publisher": "University of Wisconsin Press",
      "publisher-place": "Madison",
      "shortTitle": "The Life and Afterlife of Swedish Biograph",
      "system_id": "zotero|22783102/6APYGVMY",
      "title": "The Life and Afterlife of Swedish Biograph: From Commercial Circulation to Archival Practices",
      "type": "book"
     },
     "22783102/6AUNIX6I": {
      "DOI": "10.2307/2711913",
      "URL": "https://www.jstor.org/stable/2711913?origin=crossref",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Brownell",
        "given": "B. A."
       }
      ],
      "container-title": "American Quarterly",
      "id": "22783102/6AUNIX6I",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         1972
        ]
       ]
      },
      "page": "20–44",
      "shortTitle": "A Symbol of Modernity",
      "system_id": "zotero|22783102/6AUNIX6I",
      "title": "A Symbol of Modernity: Attitudes Toward the Automobile in Southern Cities in the 1920s",
      "type": "article-journal",
      "volume": "24"
     },
     "22783102/6VFT9YB8": {
      "ISBN": "978-0-300-09359-9",
      "editor": [
       {
        "family": "Widenheim",
        "given": "Cecilia"
       }
      ],
      "event-place": "New Haven",
      "id": "22783102/6VFT9YB8",
      "issued": {
       "date-parts": [
        [
         2002
        ]
       ]
      },
      "language": "eng",
      "publisher": "Yale University Press",
      "publisher-place": "New Haven",
      "shortTitle": "Utopia & Reality",
      "system_id": "zotero|22783102/6VFT9YB8",
      "title": "Utopia & Reality: Modernity in Sweden 1900–1960",
      "type": "book"
     },
     "22783102/7HB6GAHN": {
      "DOI": "10.1080/03468755.2025.2511644",
      "URL": "https://www.tandfonline.com/doi/full/10.1080/03468755.2025.2511644",
      "author": [
       {
        "family": "Stjernholm",
        "given": "Emil"
       },
       {
        "family": "Eriksson",
        "given": "Maria"
       },
       {
        "family": "Mohammadi Norén",
        "given": "Fredrik"
       }
      ],
      "container-title": "Scandinavian Journal of History",
      "id": "22783102/7HB6GAHN",
      "issue": "4",
      "issued": {
       "date-parts": [
        [
         2025
        ]
       ]
      },
      "page": "458–488",
      "shortTitle": "On the Historical Gaze of Generative AI",
      "system_id": "zotero|22783102/7HB6GAHN",
      "title": "On the Historical Gaze of Generative AI: Visions of Scandinavia in Stable Diffusion",
      "type": "article-journal",
      "volume": "50"
     },
     "22783102/89SWX3HE": {
      "DOI": "10.21437/Interspeech.2023-78",
      "URL": "https://www.isca-archive.org/interspeech_2023/bain23_interspeech.html",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         27
        ]
       ]
      },
      "author": [
       {
        "family": "Bain",
        "given": "Max"
       },
       {
        "family": "Huh",
        "given": "Jaesung"
       },
       {
        "family": "Han",
        "given": "Tengda"
       },
       {
        "family": "Zisserman",
        "given": "Andrew"
       }
      ],
      "container-title": "INTERSPEECH 2023",
      "event": "INTERSPEECH 2023",
      "id": "22783102/89SWX3HE",
      "issued": {
       "date-parts": [
        [
         2023,
         8,
         20
        ]
       ]
      },
      "language": "en",
      "page": "4489-4493",
      "publisher": "ISCA",
      "shortTitle": "WhisperX",
      "system_id": "zotero|22783102/89SWX3HE",
      "title": "WhisperX: Time-Accurate Speech Transcription of Long-Form Audio",
      "type": "paper-conference"
     },
     "22783102/8BSVNXZQ": {
      "ISBN": "978-3-030-42104-5",
      "abstract": "Intro – Contents – Notes on Contributors – List of Figures – List of Tables – 1: Capturing AVT and MA: Rationale, Facets and Objectives – References – Part I: Audiovisual Translation and Media Accessibility Within and Beyond Translation Studies – 2: An Excursus on Audiovisual Translation – References – 3: Audiovisual Translation through the Ages – 1 Introduction – 2 What Is AVT – 3 AVT through the Ages – 3.1 Silent Movies, Intertitles and Film Explainers – 3.2 Early Talkies and the Birth of the Main AVT Modalities – 3.3 Multilingual Films – 3.4 Dubbing – 3.5 Subtitling – 3.6 AVT and Accessibility: SDH and AD – 3.7 Audio Description – 3.8 Subtitles for the Deaf and Hard of Hearing Viewers – 3.9 AVT and the Internet: Fansubbing and Non-professional Subtitling, Crowdsourcing, Fandubbing – 4 Taking Stock: Current and New Trajectories – References – 4: Media Accessibility Within and Beyond Audiovisual Translation – 1 Introduction – 2 Theoretical Foundations: Accessibility and Human Rights – 3 Media Accessibility: Accounts and Definitions – 4 Media Accessibility: Epistemological and Methodological Shifts – 5 A First Classification of Media Accessibility Modalities and Services – 5.1 Translation-based – 5.2 Nontranslation-based – 6 Theoretical and Pedagogical Implications – 7 Future Prospects: Towards Accessibility Studies – 8 Suggested Reading – References – 5: Multimodality and Intersemiotic Translation – 1 Introduction – 2 Definitions – 3 A Historical View – 4 Theoretical Foundations – 5 Research on Multimodality and AVT – 6 Intersemiotic Translation – 7 Audio Description – 8 Tactile Exploration – 9 Subtitles for the Deaf and Hard of Hearing – 10 Conclusions – References – Filmography – Part II: Modes of Audiovisual Translation and Media Accessibility – 6: Dubbing",
      "author": [
       {
        "family": "Chaume",
        "given": "Frederic"
       }
      ],
      "container-title": "The Palgrave Handbook of Audiovisual Translation and Media Accessibility",
      "editor": [
       {
        "family": "Bogucki",
        "given": "Łukasz"
       },
       {
        "family": "Deckert",
        "given": "Mikołaj"
       }
      ],
      "event-place": "Cham",
      "id": "22783102/8BSVNXZQ",
      "issued": {
       "date-parts": [
        [
         2020
        ]
       ]
      },
      "language": "eng",
      "page": "103–132",
      "publisher": "Palgrave Macmillan",
      "publisher-place": "Cham",
      "system_id": "zotero|22783102/8BSVNXZQ",
      "title": "Dubbing",
      "type": "chapter"
     },
     "22783102/8P2FL3R2": {
      "author": [
       {
        "family": "Dupré La Tour",
        "given": "Claire"
       }
      ],
      "container-title": "Encyclopedia of Early Cinema",
      "editor": [
       {
        "family": "Abel",
        "given": "Richard"
       }
      ],
      "id": "22783102/8P2FL3R2",
      "issued": {
       "date-parts": [
        [
         2005
        ]
       ]
      },
      "page": "326-331",
      "system_id": "zotero|22783102/8P2FL3R2",
      "title": "Intertitles and Titles",
      "type": "chapter"
     },
     "22783102/8XFJBPEC": {
      "DOI": "10.1007/s41244-017-0048-4",
      "URL": "http://link.springer.com/10.1007/s41244-017-0048-4",
      "author": [
       {
        "family": "Weitin",
        "given": "Thomas"
       }
      ],
      "container-title": "Zeitschrift für Literaturwissenschaft und Linguistik",
      "id": "22783102/8XFJBPEC",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         2017
        ]
       ]
      },
      "page": "1–6",
      "system_id": "zotero|22783102/8XFJBPEC",
      "title": "Scalable Reading",
      "type": "article-journal",
      "volume": "47"
     },
     "22783102/928EZRZ4": {
      "author": [
       {
        "family": "ALB",
        "given": ""
       }
      ],
      "id": "22783102/928EZRZ4",
      "issued": {
       "date-parts": [
        [
         1996,
         11
        ]
       ]
      },
      "system_id": "zotero|22783102/928EZRZ4",
      "title": "Ledningsgrupp minnesanteckningar",
      "type": "article"
     },
     "22783102/94IX6F2L": {
      "ISBN": "978-91-7504-158-2",
      "author": [
       {
        "family": "Furhammar",
        "given": "Leif"
       }
      ],
      "edition": "3",
      "event-place": "Stockholm",
      "id": "22783102/94IX6F2L",
      "issued": {
       "date-parts": [
        [
         2003
        ]
       ]
      },
      "publisher": "Dialogos i samarbete med Svenska filminstitutet",
      "publisher-place": "Stockholm",
      "shortTitle": "Filmen i Sverige",
      "system_id": "zotero|22783102/94IX6F2L",
      "title": "Filmen i Sverige: En historia i tio kapitel och en fortsättning",
      "type": "book"
     },
     "22783102/AGCZGSA8": {
      "DOI": "10.48550/ARXIV.2205.03026",
      "URL": "https://arxiv.org/abs/2205.03026",
      "abstract": "This paper explains our work in developing new acoustic models for automated speech recognition (ASR) at KBLab, the infrastructure for data-driven research at the National Library of Sweden (KB). We evaluate different approaches for a viable speech-to-text pipeline for audiovisual resources in Swedish, using the wav2vec 2.0 architecture in combination with speech corpuses created from KB's collections. These approaches include pretraining an acoustic model for Swedish from the ground up, and fine-tuning existing monolingual and multilingual models. The collections-based corpuses we use have been sampled from millions of hours of speech, with a conscious attempt to balance regional dialects to produce a more representative, and thus more democratic, model. The acoustic model this enabled, \"VoxRex\", outperforms existing models for Swedish ASR. We also evaluate combining this model with various pretrained language models, which further enhanced performance. We conclude by highlighting the potential of such technology for cultural heritage institutions with vast collections of previously unlabelled audiovisual data. Our models are released for further exploration and research here: https://huggingface.co/KBLab.",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         27
        ]
       ]
      },
      "author": [
       {
        "family": "Malmsten",
        "given": "Martin"
       },
       {
        "family": "Haffenden",
        "given": "Chris"
       },
       {
        "family": "Börjeson",
        "given": "Love"
       }
      ],
      "id": "22783102/AGCZGSA8",
      "issued": {
       "date-parts": [
        [
         2022
        ]
       ]
      },
      "publisher": "arXiv",
      "system_id": "zotero|22783102/AGCZGSA8",
      "title": "Hearing voices at the National Library -- a speech corpus and acoustic model for the Swedish language",
      "type": "article"
     },
     "22783102/AZ3BT53M": {
      "DOI": "10.1109/ICDAR.2007.4376991",
      "ISBN": "978-0-7695-2822-9",
      "URL": "http://ieeexplore.ieee.org/document/4376991/",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Smith",
        "given": "Ray"
       }
      ],
      "container-title": "Ninth International Conference on Document Analysis and Recognition (ICDAR 2007) Vol 2",
      "event-place": "Curitiba, Parana, Brazil",
      "id": "22783102/AZ3BT53M",
      "issued": {
       "date-parts": [
        [
         2007
        ]
       ]
      },
      "page": "629–633",
      "publisher": "IEEE",
      "publisher-place": "Curitiba, Parana, Brazil",
      "system_id": "zotero|22783102/AZ3BT53M",
      "title": "An Overview of the Tesseract OCR Engine",
      "type": "paper-conference"
     },
     "22783102/BNUCIK7T": {
      "ISBN": "978-91-985802-8-0",
      "author": [
       {
        "family": "Snickars",
        "given": "Pelle"
       }
      ],
      "event-place": "Lund",
      "id": "22783102/BNUCIK7T",
      "issued": {
       "date-parts": [
        [
         2024
        ]
       ]
      },
      "publisher": "Mediehistoriskt arkiv",
      "publisher-place": "Lund",
      "shortTitle": "Audiovisuella arkiv",
      "system_id": "zotero|22783102/BNUCIK7T",
      "title": "Audiovisuella arkiv: En svensk mediehistoria 1930–1990",
      "type": "book"
     },
     "22783102/BPGKCGSS": {
      "URL": "https://huggingface.co/KB/bert-base-swedish-cased-ner",
      "accessed": {
       "date-parts": [
        [
         2025,
         6,
         5
        ]
       ]
      },
      "author": [
       {
        "family": "KB Labb",
        "given": ""
       }
      ],
      "id": "22783102/BPGKCGSS",
      "issued": {
       "date-parts": [
        [
         2022
        ]
       ]
      },
      "system_id": "zotero|22783102/BPGKCGSS",
      "title": "KB/Bert-Base-Swedish-Cased-Ner",
      "type": "webpage"
     },
     "22783102/BQLCIUEW": {
      "ISBN": "978-91-985045-6-9",
      "author": [
       {
        "family": "Stjernholm",
        "given": "Emil"
       },
       {
        "family": "Florin Persson",
        "given": "Erik"
       }
      ],
      "container-title": "Efterkrigstidens samhällskontakter",
      "editor": [
       {
        "family": "Norén",
        "given": "Fredrik"
       },
       {
        "family": "Stjernholm",
        "given": "Emil"
       }
      ],
      "event-place": "Lund",
      "id": "22783102/BQLCIUEW",
      "issued": {
       "date-parts": [
        [
         2019
        ]
       ]
      },
      "page": "41–72",
      "publisher": "Mediehistoriskt arkiv",
      "publisher-place": "Lund",
      "shortTitle": "Ett filmbolag i det allmännas tjänst?",
      "system_id": "zotero|22783102/BQLCIUEW",
      "title": "Ett filmbolag i det allmännas tjänst?: Svensk Filmindustri och skolfilmens flytande gränser",
      "type": "chapter"
     },
     "22783102/BXDUCBBT": {
      "author": [
       {
        "family": "ALB",
        "given": ""
       }
      ],
      "id": "22783102/BXDUCBBT",
      "issued": {
       "date-parts": [
        [
         1999,
         6
        ]
       ]
      },
      "system_id": "zotero|22783102/BXDUCBBT",
      "title": "IT-insatser och ökad tillgänglighet",
      "type": "article"
     },
     "22783102/BY6TRM9R": {
      "DOI": "10.21437/Interspeech.2021-698",
      "URL": "https://www.isca-archive.org/interspeech_2021/gong21b_interspeech.html",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Gong",
        "given": "Yuan"
       },
       {
        "family": "Chung",
        "given": "Yu-An"
       },
       {
        "family": "Glass",
        "given": "James"
       }
      ],
      "container-title": "Interspeech 2021",
      "id": "22783102/BY6TRM9R",
      "issued": {
       "date-parts": [
        [
         2021,
         8
        ]
       ]
      },
      "language": "en",
      "page": "571–575",
      "publisher": "ISCA",
      "shortTitle": "AST",
      "system_id": "zotero|22783102/BY6TRM9R",
      "title": "AST: Audio Spectrogram Transformer",
      "type": "paper-conference"
     },
     "22783102/DBCYMUBB": {
      "DOI": "10.1109/CVPR.2017.283",
      "URL": "http://ieeexplore.ieee.org/document/8099766/",
      "abstract": "Previous approaches for scene text detection have already achieved promising performances across various benchmarks. However, they usually fall short when dealing with challenging scenarios, even when equipped with deep neural network models, because the overall performance is determined by the interplay of multiple stages and components in the pipelines. In this work, we propose a simple yet powerful pipeline that yields fast and accurate text detection in natural scenes. The pipeline directly predicts words or text lines of arbitrary orientations and quadrilateral shapes in full images, eliminating unnecessary intermediate steps (e.g., candidate aggregation and word partitioning), with a single neural network. The simplicity of our pipeline allows concentrating efforts on designing loss functions and neural network architecture. Experiments on standard datasets including ICDAR 2015, COCO-Text and MSRA-TD500 demonstrate that the proposed algorithm signiﬁcantly outperforms state-of-the-art methods in terms of both accuracy and efﬁciency. On the ICDAR 2015 dataset, the proposed algorithm achieves an F-score of 0.7820 at 13.2fps at 720p resolution.",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Zhou",
        "given": "Xinyu"
       },
       {
        "family": "Yao",
        "given": "Cong"
       },
       {
        "family": "Wen",
        "given": "He"
       },
       {
        "family": "Wang",
        "given": "Yuzhi"
       },
       {
        "family": "Zhou",
        "given": "Shuchang"
       },
       {
        "family": "He",
        "given": "Weiran"
       },
       {
        "family": "Liang",
        "given": "Jiajun"
       }
      ],
      "container-title": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
      "event-place": "Honolulu, HI",
      "id": "22783102/DBCYMUBB",
      "issued": {
       "date-parts": [
        [
         2017
        ]
       ]
      },
      "page": "5551–5560",
      "publisher": "IEEE",
      "publisher-place": "Honolulu, HI",
      "shortTitle": "EAST",
      "system_id": "zotero|22783102/DBCYMUBB",
      "title": "EAST: An Efficient and Accurate Scene Text Detector",
      "type": "paper-conference"
     },
     "22783102/DSU6R48K": {
      "ISBN": "978-91-86743-26-0",
      "author": [
       {
        "family": "Asp",
        "given": "Jon"
       }
      ],
      "event-place": "Stockholm",
      "id": "22783102/DSU6R48K",
      "issued": {
       "date-parts": [
        [
         2014
        ]
       ]
      },
      "publisher": "Premiss",
      "publisher-place": "Stockholm",
      "shortTitle": "Film för folket",
      "system_id": "zotero|22783102/DSU6R48K",
      "title": "Film för folket: Om Folkets Hus och filmen",
      "type": "book"
     },
     "22783102/DVKUX2N4": {
      "author": [
       {
        "family": "Norrlander",
        "given": "S"
       }
      ],
      "id": "22783102/DVKUX2N4",
      "issued": {
       "date-parts": [
        [
         1964,
         4
        ]
       ]
      },
      "system_id": "zotero|22783102/DVKUX2N4",
      "title": "PM med plan och instruktion rörande SF:s journalarkiv",
      "type": "article"
     },
     "22783102/DW4S37Y5": {
      "author": [
       {
        "family": "Bergman",
        "given": "O"
       }
      ],
      "container-title": "Dagens Nyheter",
      "id": "22783102/DW4S37Y5",
      "issued": {
       "date-parts": [
        [
         1986,
         11
        ]
       ]
      },
      "system_id": "zotero|22783102/DW4S37Y5",
      "title": "Hon ska göra TV:s guldgruva lönsam",
      "type": "article-journal"
     },
     "22783102/ERJVIH9J": {
      "author": [
       {
        "family": "Aftonbladet",
        "given": ""
       }
      ],
      "container-title": "Aftonbladet",
      "id": "22783102/ERJVIH9J",
      "issued": {
       "date-parts": [
        [
         1936,
         12,
         26
        ]
       ]
      },
      "page": "27",
      "system_id": "zotero|22783102/ERJVIH9J",
      "title": "Stockholms-Tidningen skrives av unga begåvningar med tidens takt i blodet!",
      "type": "article-journal"
     },
     "22783102/EVKA7BG8": {
      "URL": "https://huggingface.co/moondream",
      "author": [
       {
        "family": "Korrapati",
        "given": "V"
       }
      ],
      "id": "22783102/EVKA7BG8",
      "issued": {
       "date-parts": [
        [
         2025
        ]
       ]
      },
      "shortTitle": "Moondream 2",
      "system_id": "zotero|22783102/EVKA7BG8",
      "title": "Moondream 2 / Moondream: Tiny vision-language model for object detection and vision tasks",
      "type": "article"
     },
     "22783102/FDPKQ7P8": {
      "author": [
       {
        "family": "Dahlstedt",
        "given": "Stellan"
       }
      ],
      "container-title": "AGA-nyheter",
      "id": "22783102/FDPKQ7P8",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         1947
        ]
       ]
      },
      "system_id": "zotero|22783102/FDPKQ7P8",
      "title": "Utvidgad ljudavdelning vid SF:s ateljéer i Råsunda",
      "type": "article-journal"
     },
     "22783102/GVASD2H8": {
      "ISBN": "978-3-11-108248-6",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         19
        ]
       ]
      },
      "author": [
       {
        "family": "Gaines",
        "given": "J. M."
       }
      ],
      "container-title": "Doing Digital Film History: Concepts, Tools, Practices",
      "editor": [
       {
        "family": "Dang",
        "given": "Sarah-Mai"
       },
       {
        "family": "Van Der Heijden",
        "given": "Tim"
       },
       {
        "family": "Olesen",
        "given": "Christian Gosvig"
       }
      ],
      "event-place": "Berlin",
      "id": "22783102/GVASD2H8",
      "issued": {
       "date-parts": [
        [
         2024
        ]
       ]
      },
      "page": "17–46",
      "publisher": "De Gruyter",
      "publisher-place": "Berlin",
      "system_id": "zotero|22783102/GVASD2H8",
      "title": "The DH Dilemma: Knowing More & Knowing for Sure vs. Never Knowing At All",
      "type": "chapter"
     },
     "22783102/H4XMMWYS": {
      "DOI": "10.1057/s41599-024-02886-w",
      "URL": "https://www.nature.com/articles/s41599-024-02886-w",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Oiva",
        "given": "Mila"
       },
       {
        "family": "Mukhina",
        "given": "Ksenia"
       },
       {
        "family": "Zemaityte",
        "given": "Vejune"
       },
       {
        "family": "Karjus",
        "given": "Andres"
       },
       {
        "family": "Tamm",
        "given": "Mikhail"
       },
       {
        "family": "Ohm",
        "given": "Tillmann"
       },
       {
        "family": "Mets",
        "given": "Mark"
       },
       {
        "family": "Chávez Heras",
        "given": "Daniel"
       },
       {
        "family": "Canet Sola",
        "given": "Mar"
       },
       {
        "family": "Juht",
        "given": "Helena Hanna"
       },
       {
        "family": "Schich",
        "given": "Maximilian"
       }
      ],
      "container-title": "Humanities and Social Sciences Communications",
      "id": "22783102/H4XMMWYS",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         2024,
         4
        ]
       ]
      },
      "language": "en",
      "page": "1–15",
      "system_id": "zotero|22783102/H4XMMWYS",
      "title": "A Framework for the Analysis of Historical Newsreels",
      "type": "article-journal",
      "volume": "11"
     },
     "22783102/HDPCSX8E": {
      "URL": "https://etheses.whiterose.ac.uk/id/eprint/35332/",
      "author": [
       {
        "family": "Scott",
        "given": "Conner Rivers"
       }
      ],
      "event-place": "Sheffield",
      "genre": "Doctoral dissertation",
      "id": "22783102/HDPCSX8E",
      "issued": {
       "date-parts": [
        [
         2024
        ]
       ]
      },
      "publisher": "University of Sheffield",
      "publisher-place": "Sheffield",
      "system_id": "zotero|22783102/HDPCSX8E",
      "title": "‘Propaganda for things as they are’? British Newsreels in Everyday Life, c.1920-c.1939.",
      "type": "thesis"
     },
     "22783102/I8MEJEFP": {
      "DOI": "10.5281/ZENODO.18130784",
      "URL": "https://zenodo.org/doi/10.5281/zenodo.18130784",
      "abstract": "Automated extraction and analysis of audio-visual co-occurrences in video data\n\nusing deep learning models.\n\n \n\n## Overview\n\n \n\nThis project analyzes temporal co-occurrences of audio and visual features in\n\nvideos:\n\n- Audio extraction : Uses MIT's Audio Spectrogram Transformer (AST) to\n\nclassify audio content\n\n- Visual extraction : Uses Moondream vision model for object detection in\n\nframes\n\n- Pairing analysis : Identifies audio-visual co-occurrences with temporal\n\nalignment\n\n- Temporal analysis : Tracks changes in audio-visual patterns across years\n\n \n\n## Structure\n\n \n\n- src.zip  : The source code for the library\n\n- results.zip  : The .csv outputs\n\n- moon_results.tar.gz : Results from the Visual extraction pipeline\n\n- audio_results.tar.gz : Results forom the Audio extraction pipeline",
      "accessed": {
       "date-parts": [
        [
         2026,
         1,
         2
        ]
       ]
      },
      "author": [
       {
        "family": "Johansson",
        "given": "Mathias"
       },
       {
        "family": "Malmstedt",
        "given": "Johan"
       }
      ],
      "id": "22783102/I8MEJEFP",
      "issued": {
       "date-parts": [
        [
         2026,
         1,
         2
        ]
       ]
      },
      "publisher": "Zenodo",
      "system_id": "zotero|22783102/I8MEJEFP",
      "title": "Audiovisual Analysis of Journal Digital",
      "type": "article"
     },
     "22783102/JQZ27MNN": {
      "ISBN": "978-3-901644-51-1",
      "author": [
       {
        "family": "Dobringer",
        "given": "Anna"
       },
       {
        "family": "Stöger",
        "given": "Silvester"
       },
       {
        "family": "Wratschko",
        "given": "Karl"
       }
      ],
      "container-title": "Work/s in Progress: Digital Film Restoration within Archives",
      "editor": [
       {
        "family": "Parth",
        "given": "Kerstin"
       },
       {
        "family": "Hanley",
        "given": "Oliver"
       },
       {
        "family": "Ballhausen",
        "given": "Thomas"
       }
      ],
      "event-place": "Vienna",
      "id": "22783102/JQZ27MNN",
      "issued": {
       "date-parts": [
        [
         2013
        ]
       ]
      },
      "language": "eng",
      "page": "121–133",
      "publisher": "Synema",
      "publisher-place": "Vienna",
      "shortTitle": "Changing Perspectives",
      "system_id": "zotero|22783102/JQZ27MNN",
      "title": "Changing Perspectives. DAS EINKÜCHENHAUS as an Example of Film Historiography and Contemporary Restoration",
      "type": "chapter"
     },
     "22783102/JSI4ETR6": {
      "author": [
       {
        "family": "Dagend Nyheter",
        "given": ""
       }
      ],
      "container-title": "Dagens Nyheter",
      "id": "22783102/JSI4ETR6",
      "issued": {
       "date-parts": [
        [
         1928,
         10,
         14
        ]
       ]
      },
      "page": "21",
      "system_id": "zotero|22783102/JSI4ETR6",
      "title": "Tonfilmen fick en fin premiär i Konserthuset",
      "type": "article-journal"
     },
     "22783102/K4N8PIGZ": {
      "URL": "https://urn.kb.se/resolve?urn=urn:nbn:se:umu:diva-236882",
      "author": [
       {
        "family": "Malmstedt",
        "given": "Johan"
       }
      ],
      "event-place": "Umeå",
      "genre": "Doctoral dissertation",
      "id": "22783102/K4N8PIGZ",
      "issued": {
       "date-parts": [
        [
         2025
        ]
       ]
      },
      "publisher": "Umeå University",
      "publisher-place": "Umeå",
      "system_id": "zotero|22783102/K4N8PIGZ",
      "title": "Sound Out of Time: Signal Archaeology of Swedish Public Service Radio 1980–1999",
      "type": "thesis"
     },
     "22783102/KADI4AFW": {
      "ISBN": "978-3-11-131777-9",
      "URL": "https://www.degruyter.com/document/doi/10.1515/9783111317779/html",
      "editor": [
       {
        "family": "Armaselu",
        "given": "Florentina"
       },
       {
        "family": "Fickers",
        "given": "Andreas"
       }
      ],
      "id": "22783102/KADI4AFW",
      "issued": {
       "date-parts": [
        [
         2024
        ]
       ]
      },
      "publisher": "De Gruyter",
      "shortTitle": "Zoomland",
      "system_id": "zotero|22783102/KADI4AFW",
      "title": "Zoomland: Exploring Scale in Digital History and Humanities",
      "type": "book"
     },
     "22783102/KLXX4FNU": {
      "ISBN": "978-91-8070-132-7",
      "editor": [
       {
        "family": "Nilsson",
        "given": "Ragnhild"
       },
       {
        "family": "Rohdin",
        "given": "Mats"
       },
       {
        "family": "Mörkenstam",
        "given": "Ulf"
       }
      ],
      "event-place": "Umeå",
      "id": "22783102/KLXX4FNU",
      "issued": {
       "date-parts": [
        [
         2024
        ]
       ]
      },
      "publisher": "Várdduo, Centrum för samisk forskning",
      "publisher-place": "Umeå",
      "system_id": "zotero|22783102/KLXX4FNU",
      "title": "Sápmi på film och TV",
      "type": "book"
     },
     "22783102/M63TBZ7V": {
      "author": [
       {
        "family": "ALB",
        "given": ""
       }
      ],
      "id": "22783102/M63TBZ7V",
      "issued": {
       "date-parts": [
        [
         1998,
         7
        ]
       ]
      },
      "system_id": "zotero|22783102/M63TBZ7V",
      "title": "Det digitala journalfilmsarkivet, application",
      "type": "article"
     },
     "22783102/MFU9DVN9": {
      "author": [
       {
        "family": "Bradski",
        "given": "Gary"
       }
      ],
      "container-title": "Dr. Dobb’s Journal of Software Tools",
      "id": "22783102/MFU9DVN9",
      "issue": "120",
      "issued": {
       "date-parts": [
        [
         2000
        ]
       ]
      },
      "page": "122–125",
      "system_id": "zotero|22783102/MFU9DVN9",
      "title": "The OpenCV Library",
      "type": "article-journal"
     },
     "22783102/NEKVNJJD": {
      "ISBN": "978-0-520-24837-3",
      "author": [
       {
        "family": "Arnheim",
        "given": "Rudolf"
       }
      ],
      "edition": "2",
      "event-place": "Berkeley and Los Angeles",
      "id": "22783102/NEKVNJJD",
      "issued": {
       "date-parts": [
        [
         1957
        ]
       ]
      },
      "language": "eng",
      "publisher": "University of California Press",
      "publisher-place": "Berkeley and Los Angeles",
      "system_id": "zotero|22783102/NEKVNJJD",
      "title": "Film as Art",
      "type": "book"
     },
     "22783102/NEKZIEHT": {
      "ISBN": "978-0-7190-6591-0",
      "author": [
       {
        "family": "Barton",
        "given": "Susan"
       }
      ],
      "event-place": "Manchester and New York",
      "id": "22783102/NEKZIEHT",
      "issued": {
       "date-parts": [
        [
         2011
        ]
       ]
      },
      "language": "en",
      "publisher": "Manchester University Press",
      "publisher-place": "Manchester and New York",
      "shortTitle": "Working-Class Organisations and Popular Tourism",
      "system_id": "zotero|22783102/NEKZIEHT",
      "title": "Working-Class Organisations and Popular Tourism, 1840–1940",
      "type": "book"
     },
     "22783102/NLX2C8VR": {
      "ISBN": "0-231-07898-6",
      "author": [
       {
        "family": "Chion",
        "given": "Michel"
       }
      ],
      "editor": [
       {
        "family": "Gorbman",
        "given": "Claudia"
       }
      ],
      "event-place": "New York",
      "id": "22783102/NLX2C8VR",
      "issued": {
       "date-parts": [
        [
         1994
        ]
       ]
      },
      "language": "eng",
      "publisher": "Columbia University Press",
      "publisher-place": "New York",
      "shortTitle": "Audio-vision",
      "system_id": "zotero|22783102/NLX2C8VR",
      "title": "Audio-Vision: Sound on Screen",
      "translator": [
       {
        "family": "Gorbman",
        "given": "Claudia"
       }
      ],
      "type": "book"
     },
     "22783102/NTI97CTV": {
      "DOI": "10.1111/j.1468-229X.1971.tb02124.x",
      "URL": "https://onlinelibrary.wiley.com/doi/10.1111/j.1468-229X.1971.tb02124.x",
      "author": [
       {
        "family": "Pronay",
        "given": "Nicholas"
       }
      ],
      "container-title": "History",
      "id": "22783102/NTI97CTV",
      "issue": "188",
      "issued": {
       "date-parts": [
        [
         1971
        ]
       ]
      },
      "page": "411–417",
      "shortTitle": "British Newsreels in the 1930s",
      "system_id": "zotero|22783102/NTI97CTV",
      "title": "British Newsreels in the 1930s: Audience and Producers",
      "type": "article-journal",
      "volume": "56"
     },
     "22783102/PCBNCFMD": {
      "ISBN": "0-415-05298-X",
      "author": [
       {
        "family": "Eisenstein",
        "given": "Sergej"
       },
       {
        "family": "Pudovkin",
        "given": "Vsevolod"
       },
       {
        "family": "Alexandrov",
        "given": "Grigori"
       }
      ],
      "container-title": "The Film Factory: Russian and Soviet Cinema in Documents",
      "editor": [
       {
        "family": "Taylor",
        "given": "Richard"
       }
      ],
      "event-place": "London",
      "id": "22783102/PCBNCFMD",
      "issued": {
       "date-parts": [
        [
         1994
        ]
       ]
      },
      "page": "234",
      "publisher": "Routledge",
      "publisher-place": "London",
      "system_id": "zotero|22783102/PCBNCFMD",
      "title": "Statement on Sound",
      "type": "chapter"
     },
     "22783102/PEB6LVXU": {
      "DOI": "10.5281/ZENODO.18131655",
      "URL": "https://zenodo.org/doi/10.5281/zenodo.18131655",
      "abstract": "This project performs geographical analysis of Swedish newsreels from the\n\nJournal Digital corpus (1930-1965) using Named Entity Recognition (NER),\n\ngeolocation validation, and geocoding. The pipeline extracts location mentions\n\nfrom video subtitles, validates them against the GeoNames gazetteer, and\n\nconverts them to geographic coordinates using Nominatim. Results include\n\nvalidated location datasets, temporal analysis of geographic mentions, regional\n\ndistribution statistics, and JSON exports for spatial visualization. The\n\nproject provides tools for preprocessing NER data, analyzing location patterns\n\nover time, and generating interactive visualizations of geographic coverage in\n\nSwedish newsreel production.",
      "accessed": {
       "date-parts": [
        [
         2026,
         1,
         2
        ]
       ]
      },
      "author": [
       {
        "family": "Johansson",
        "given": "Mathias"
       },
       {
        "family": "Askepskog",
        "given": "Robert"
       }
      ],
      "id": "22783102/PEB6LVXU",
      "issued": {
       "date-parts": [
        [
         2026,
         1,
         2
        ]
       ]
      },
      "publisher": "Zenodo",
      "system_id": "zotero|22783102/PEB6LVXU",
      "title": "Geographical Analysis of Journal Digital",
      "type": "article"
     },
     "22783102/PUAS8ZHL": {
      "DOI": "10.1145/3347317.3357240",
      "ISBN": "978-1-4503-6910-7",
      "URL": "https://dl.acm.org/doi/10.1145/3347317.3357240",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         19
        ]
       ]
      },
      "author": [
       {
        "family": "Bhargav",
        "given": "Samarth"
       },
       {
        "family": "Van Noord",
        "given": "Nanne"
       },
       {
        "family": "Kamps",
        "given": "Jaap"
       }
      ],
      "container-title": "Proceedings of the 1st Workshop on Structuring and Understanding of Multimedia heritAge Contents",
      "event-place": "Nice",
      "id": "22783102/PUAS8ZHL",
      "issued": {
       "date-parts": [
        [
         2019,
         10
        ]
       ]
      },
      "language": "en",
      "page": "61–68",
      "publisher": "ACM",
      "publisher-place": "Nice",
      "system_id": "zotero|22783102/PUAS8ZHL",
      "title": "Deep Learning as a Tool for Early Cinema Analysis",
      "type": "paper-conference"
     },
     "22783102/R86YMEXD": {
      "author": [
       {
        "family": "ALB",
        "given": ""
       }
      ],
      "id": "22783102/R86YMEXD",
      "issued": {
       "date-parts": [
        [
         1997,
         8
        ]
       ]
      },
      "system_id": "zotero|22783102/R86YMEXD",
      "title": "Ledningsgrupp minnesanteckningar",
      "type": "article"
     },
     "22783102/SSCKKMRE": {
      "DOI": "10.64590/hxj",
      "URL": "https://newleftreview.org/issues/ii1/articles/franco-moretti-conjectures-on-world-literature",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Moretti",
        "given": "Franco"
       }
      ],
      "container-title": "New Left Review",
      "id": "22783102/SSCKKMRE",
      "issued": {
       "date-parts": [
        [
         2000,
         1
        ]
       ]
      },
      "page": "54–68",
      "system_id": "zotero|22783102/SSCKKMRE",
      "title": "Conjectures on World Literature",
      "type": "article-journal"
     },
     "22783102/TEPVQNE3": {
      "ISBN": "978-0-415-77657-8",
      "author": [
       {
        "family": "Beck",
        "given": "Jay"
       }
      ],
      "container-title": "The Routledge Companion to Film History",
      "edition": "1",
      "editor": [
       {
        "family": "Guynn",
        "given": "William Howard"
       }
      ],
      "event-place": "London",
      "id": "22783102/TEPVQNE3",
      "issued": {
       "date-parts": [
        [
         2011
        ]
       ]
      },
      "language": "en",
      "page": "64–76",
      "publisher": "Routledge",
      "publisher-place": "London",
      "system_id": "zotero|22783102/TEPVQNE3",
      "title": "The Evolution of Sound in Cinema",
      "type": "chapter"
     },
     "22783102/TT5RIEE2": {
      "URL": "https://zenodo.org/doi/10.5281/zenodo.15582876",
      "abstract": "What's Changed\n\n\n\nadd PyPI publishing status badge by @mathjoha in https://github.com/Modern36/stum/pull/2\n\nAdd Zenodo badge by @mathjoha in https://github.com/Modern36/stum/pull/3\n\nupdate and loosen pinned versions by @mathjoha in https://github.com/Modern36/stum/pull/4\n\nPipeline by @mathjoha in https://github.com/Modern36/stum/pull/5\n\n\nFull Changelog: https://github.com/Modern36/stum/compare/v0.1.1...v0.2.0",
      "accessed": {
       "date-parts": [
        [
         2026,
         1,
         2
        ]
       ]
      },
      "author": [
       {
        "family": "Johansson",
        "given": "Mathias"
       }
      ],
      "id": "22783102/TT5RIEE2",
      "issued": {
       "date-parts": [
        [
         2025,
         6,
         3
        ]
       ]
      },
      "note": "DOI: 10.5281/ZENODO.15582876",
      "publisher": "Zenodo",
      "shortTitle": "Modern36/stum",
      "system_id": "zotero|22783102/TT5RIEE2",
      "title": "Modern36/stum: v0.2.0",
      "type": "book"
     },
     "22783102/TV37XT5P": {
      "DOI": "10.1386/jsca_00118_1",
      "URL": "https://intellectdiscover.com/content/journals/10.1386/jsca_00118_1",
      "abstract": "Following a boom of user-friendly artificial intelligence tools in recent years, AI-enhanced (or manipulated) films have been framed as a serious threat to film archives. The purpose of this article is to trace and critically evaluate how AI artists use algorithmic upscaling to modify early cinema, more particularly surviving films of the film company Swedish Biograph, and how fragments of this company’s cinematic past circulate online today.",
      "author": [
       {
        "family": "Stjernholm",
        "given": "Emil"
       },
       {
        "family": "Snickars",
        "given": "Pelle"
       }
      ],
      "container-title": "Journal of Scandinavian Cinema",
      "id": "22783102/TV37XT5P",
      "issue": "3",
      "issued": {
       "date-parts": [
        [
         2024,
         9
        ]
       ]
      },
      "page": "181–197",
      "system_id": "zotero|22783102/TV37XT5P",
      "title": "Upscaling Swedish Biograph",
      "type": "article-journal",
      "volume": "14"
     },
     "22783102/UK5SM8C2": {
      "DOI": "10.25969/MEDIAREP/22316",
      "URL": "https://mediarep.org/entities/article/fcc4a926-1e5d-4434-a55e-cf779477cf67",
      "author": [
       {
        "family": "Offert",
        "given": "Fabian"
       }
      ],
      "container-title": "IMAGE. Zeitschrift für interdisziplinäre Bildwissenschaft",
      "id": "22783102/UK5SM8C2",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         2023
        ]
       ]
      },
      "page": "121–134",
      "system_id": "zotero|22783102/UK5SM8C2",
      "title": "On the Concept of History (in Foundation Models)",
      "type": "article-journal",
      "volume": "19"
     },
     "22783102/URY9RMYJ": {
      "ISBN": "0-262-70106-5",
      "author": [
       {
        "family": "Thompson",
        "given": "Emily"
       }
      ],
      "event-place": "Cambridge",
      "id": "22783102/URY9RMYJ",
      "issued": {
       "date-parts": [
        [
         2004
        ]
       ]
      },
      "publisher": "MIT Press",
      "publisher-place": "Cambridge",
      "shortTitle": "The Soundscape of Modernity",
      "system_id": "zotero|22783102/URY9RMYJ",
      "title": "The Soundscape of Modernity: Architectural Acoustics and the Culture of Listening in America, 1900–1933",
      "type": "book"
     },
     "22783102/UVAHYVZ2": {
      "ISBN": "978-3-518-29136-8",
      "author": [
       {
        "family": "Balázs",
        "given": "Béla"
       }
      ],
      "edition": "5",
      "event-place": "Frankfurt am Main",
      "id": "22783102/UVAHYVZ2",
      "issued": {
       "date-parts": [
        [
         2017
        ]
       ]
      },
      "publisher": "Suhrkamp",
      "publisher-place": "Frankfurt am Main",
      "system_id": "zotero|22783102/UVAHYVZ2",
      "title": "Der sichtbare Mensch oder die Kultur des Films",
      "type": "book"
     },
     "22783102/VL4UHIWF": {
      "author": [
       {
        "family": "Eriksson",
        "given": "Maria"
       }
      ],
      "id": "22783102/VL4UHIWF",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         2024
        ]
       ]
      },
      "system_id": "zotero|22783102/VL4UHIWF",
      "title": "Zur Bedeutung des Skalierens beim Upscaling digitaler Bilder",
      "type": "article-journal",
      "volume": "33"
     },
     "22783102/WEZNWR96": {
      "DOI": "10.1515/jdh-2021-1008",
      "URL": "https://www.degruyter.com/document/doi/10.1515/jdh-2021-1008/html",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Fickers",
        "given": "Andreas"
       },
       {
        "family": "Clavert",
        "given": "Frédéric"
       }
      ],
      "container-title": "Journal of Digital History",
      "id": "22783102/WEZNWR96",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         2021,
         9
        ]
       ]
      },
      "language": "en",
      "system_id": "zotero|22783102/WEZNWR96",
      "title": "On pyramids, prisms, and scalable reading",
      "type": "article-journal",
      "volume": "1"
     },
     "22783102/WHSQVQAB": {
      "ISBN": "978-3-030-05709-1 978-3-030-05710-7",
      "URL": "http://link.springer.com/10.1007/978-3-030-05710-7_33",
      "accessed": {
       "date-parts": [
        [
         2025,
         12,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Guyot",
        "given": "Patrice"
       },
       {
        "family": "Malon",
        "given": "Thierry"
       },
       {
        "family": "Roman-Jimenez",
        "given": "Geoffrey"
       },
       {
        "family": "Chambon",
        "given": "Sylvie"
       },
       {
        "family": "Charvillat",
        "given": "Vincent"
       },
       {
        "family": "Crouzil",
        "given": "Alain"
       },
       {
        "family": "Péninou",
        "given": "André"
       },
       {
        "family": "Pinquier",
        "given": "Julien"
       },
       {
        "family": "Sèdes",
        "given": "Florence"
       },
       {
        "family": "Sénac",
        "given": "Christine"
       }
      ],
      "container-title": "MultiMedia Modeling",
      "editor": [
       {
        "family": "Kompatsiaris",
        "given": "Ioannis"
       },
       {
        "family": "Huet",
        "given": "Benoit"
       },
       {
        "family": "Mezaris",
        "given": "Vasileios"
       },
       {
        "family": "Gurrin",
        "given": "Cathal"
       },
       {
        "family": "Cheng",
        "given": "Wen-Huang"
       },
       {
        "family": "Vrochidis",
        "given": "Stefanos"
       }
      ],
      "event-place": "Cham",
      "id": "22783102/WHSQVQAB",
      "issued": {
       "date-parts": [
        [
         2019
        ]
       ]
      },
      "language": "en",
      "note": "DOI: 10.1007/978-3-030-05710-7_33",
      "page": "399–410",
      "publisher": "Springer International Publishing",
      "publisher-place": "Cham",
      "system_id": "zotero|22783102/WHSQVQAB",
      "title": "Audiovisual Annotation Procedure for Multi-View Field Recordings",
      "type": "chapter",
      "volume": "11295"
     },
     "22783102/WQEJMM77": {
      "ISBN": "978-0-7099-4225-2",
      "author": [
       {
        "family": "Reeves",
        "given": "Nicholas"
       }
      ],
      "event-place": "London",
      "id": "22783102/WQEJMM77",
      "issued": {
       "date-parts": [
        [
         1986
        ]
       ]
      },
      "publisher": "Croom Helm",
      "publisher-place": "London",
      "system_id": "zotero|22783102/WQEJMM77",
      "title": "Official British Film Propaganda During the First World War",
      "type": "book"
     },
     "22783102/X4KI9JPL": {
      "URL": "https://www.geonames.org/",
      "author": [
       {
        "family": "GeoNames",
        "given": ""
       }
      ],
      "id": "22783102/X4KI9JPL",
      "issued": {
       "date-parts": [
        [
         2025
        ]
       ]
      },
      "system_id": "zotero|22783102/X4KI9JPL",
      "title": "GeoNames Geographical Database",
      "type": "article"
     },
     "22783102/XYQCBCR3": {
      "ISBN": "978-91-7504-183-4",
      "author": [
       {
        "family": "Broberg",
        "given": "Gunnar"
       },
       {
        "family": "Tydén",
        "given": "Mattias"
       }
      ],
      "edition": "2",
      "event-place": "Stockholm",
      "id": "22783102/XYQCBCR3",
      "issued": {
       "date-parts": [
        [
         2005
        ]
       ]
      },
      "publisher": "Dialogos",
      "publisher-place": "Stockholm",
      "shortTitle": "Oönskade i folkhemmet",
      "system_id": "zotero|22783102/XYQCBCR3",
      "title": "Oönskade i folkhemmet: Rashygien och sterilisering i Sverige",
      "type": "book"
     },
     "22783102/YQMWCYSZ": {
      "author": [
       {
        "family": "Aftonbladet",
        "given": ""
       }
      ],
      "container-title": "Aftonbladet",
      "id": "22783102/YQMWCYSZ",
      "issued": {
       "date-parts": [
        [
         1936,
         12,
         26
        ]
       ]
      },
      "page": "30",
      "system_id": "zotero|22783102/YQMWCYSZ",
      "title": "Stockholms-Tidningen enda tidning i Norden med reportage-flygmaskin",
      "type": "article-journal"
     },
     "22783102/ZWKH378T": {
      "author": [
       {
        "family": "Skoglund",
        "given": "Gunnar"
       }
      ],
      "container-title": "Svensk Filmindustri tjugufem år: En bok om filmproduktion och biografrörelse / utgiven till jubileet av Aktiebolaget Svensk Filmindustri",
      "editor": [
       {
        "family": "Idestam-Almquist",
        "given": "Bengt"
       }
      ],
      "event-place": "Stockholm",
      "id": "22783102/ZWKH378T",
      "issued": {
       "date-parts": [
        [
         1944
        ]
       ]
      },
      "page": "149–160",
      "publisher-place": "Stockholm",
      "system_id": "zotero|22783102/ZWKH378T",
      "title": "Om kortfilm och journalreportage",
      "type": "chapter"
     }
    }
   },
   "style": "chicago-author-date.csl"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
